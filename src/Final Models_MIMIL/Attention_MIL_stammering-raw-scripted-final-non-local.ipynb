{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import math\n",
    "\n",
    "seed = 1000\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(seed)\n",
    "\n",
    "#2021,2636,7928,1000,4271\n",
    "\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    \n",
    "    \n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, X1,Y):\n",
    "        self.X1 = X1\n",
    "        self.Y = Y\n",
    "    def __len__(self):        \n",
    "        return len(self.X1)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.X1[index]\n",
    "        y = self.Y[index]\n",
    "        return x,y\n",
    "\n",
    "#from model import Attention, GatedAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negetive pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def readFeatures(path):\n",
    "    features=np.array([])\n",
    "    start=0\n",
    "    for file in os.listdir(path):\n",
    "        d = os.path.join(path, file)\n",
    "        datafile=d+\"/features.npy\"\n",
    "        try:\n",
    "            temp=np.load(datafile)\n",
    "#             print(datafile)\n",
    "#             print(temp.shape)\n",
    "            if(start==0):\n",
    "                features=temp\n",
    "                if(d[-10]=='S'):\n",
    "                    label=np.ones(len(temp))\n",
    "                else:\n",
    "                    label=np.zeros(len(temp))\n",
    "                start=1\n",
    "            else:\n",
    "                features=np.vstack((features,temp))\n",
    "                if(d[-10]=='S'):\n",
    "                    label=np.append(label,np.ones(len(temp)))\n",
    "                else:\n",
    "                    label=np.append(label,np.zeros(len(temp)))\n",
    "        except IOError:\n",
    "            print('file not in Scripted')\n",
    "\n",
    "            \n",
    "    return features,label\n",
    "\n",
    "def load_data(path,mode):\n",
    "    if mode == \"test\":\n",
    "        xTest,yTest=readFeatures(path+\"/\"+mode)\n",
    "        xTest = xTest.reshape(len(xTest),1,19,24)\n",
    "        return Dataset(xTest,yTest)\n",
    "        \n",
    "    elif mode == \"train\":\n",
    "        xTrain,yTrain=readFeatures(path+\"/\"+mode)\n",
    "        xTrain = xTrain.reshape(len(xTrain),1,19,24)\n",
    "        return Dataset(xTrain,yTrain)\n",
    "        \n",
    "    elif mode == \"val\":\n",
    "        xVal,yVal=readFeatures(path+\"/\"+mode)\n",
    "        xVal = xVal.reshape(len(xVal),1,19,24)\n",
    "        return Dataset(xVal,yVal)\n",
    "    else:\n",
    "        print(\"Mode not defined\")\n",
    "        return\n",
    "\n",
    "traindataset = load_data(\"../Participant_wise\",'train')\n",
    "testdataset = load_data('../Participant_wise','test')\n",
    "valdataset = load_data('../Participant_wise','val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stammering(data_utils.Dataset):\n",
    "    def __init__(self, target_number=1, mean_bag_length=5, var_bag_length=2, num_bag=150, seed=2021, train=\"train\"):\n",
    "        self.target_number = target_number\n",
    "        self.mean_bag_length = mean_bag_length\n",
    "        self.var_bag_length = var_bag_length\n",
    "        self.num_bag = num_bag\n",
    "        self.train = train\n",
    "        self.r = np.random.RandomState(seed)\n",
    "\n",
    "        if self.train==\"train\":\n",
    "            self.train_bags_list, self.train_labels_list = self._create_bags()\n",
    "        elif self.train==\"val\":\n",
    "            self.val_bags_list, self.val_labels_list = self._create_bags()\n",
    "        else:\n",
    "            self.test_bags_list, self.test_labels_list = self._create_bags()\n",
    "\n",
    "    def _create_bags(self):\n",
    "        if self.train==\"train\":\n",
    "            print(\"train\")\n",
    "            loader = data_utils.DataLoader(traindataset,\n",
    "                                           batch_size=1,\n",
    "                                           shuffle=True)\n",
    "        elif self.train==\"val\":\n",
    "            print(\"val\")\n",
    "            loader = data_utils.DataLoader(valdataset,\n",
    "                                           batch_size=1,\n",
    "                                           shuffle=True)\n",
    "        else:\n",
    "            loader = data_utils.DataLoader(testdataset,\n",
    "                                           batch_size=1,\n",
    "                                           shuffle=True)\n",
    "            \n",
    "        bags_list = []\n",
    "        labels_list = []\n",
    "        for (batch_data, batch_labels) in loader:\n",
    "            #print(batch_data.shape)\n",
    "            bags_list.append(batch_data.reshape(19,1,24))\n",
    "            temp = torch.as_tensor(np.array([batch_labels for x in range(19)]))\n",
    "            labels_list.append(temp)\n",
    "            \n",
    "               \n",
    "        #print(bags_list)\n",
    "        #print(labels_list)\n",
    "        return bags_list, labels_list\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train==\"train\":\n",
    "            return len(self.train_labels_list)\n",
    "        elif self.train==\"val\":\n",
    "            return len(self.val_labels_list)\n",
    "        else:\n",
    "            return len(self.test_labels_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train==\"train\":\n",
    "            bag = self.train_bags_list[index]\n",
    "            label = [max(self.train_labels_list[index]), self.train_labels_list[index]]\n",
    "        elif self.train==\"val\":\n",
    "            bag = self.val_bags_list[index]\n",
    "            label = [max(self.val_labels_list[index]), self.val_labels_list[index]]\n",
    "        else:\n",
    "            bag = self.test_bags_list[index]\n",
    "            label = [max(self.test_labels_list[index]), self.test_labels_list[index]]\n",
    "\n",
    "        return bag, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "val\n"
     ]
    }
   ],
   "source": [
    "train_loader = data_utils.DataLoader(Stammering(train=\"train\"),batch_size=1,worker_init_fn=seed_worker,shuffle=True)\n",
    "test_loader = data_utils.DataLoader(Stammering(train=\"test\"),batch_size=1,worker_init_fn=seed_worker,shuffle=True)\n",
    "val_loader = data_utils.DataLoader(Stammering(train=\"val\"),batch_size=1,worker_init_fn=seed_worker,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HR 32 acc 63\n",
    "\n",
    "HR 64 ACC 46\n",
    "\n",
    "HR 32 EDA 32 ACC 89\n",
    "\n",
    "HR 32 EDA 16 RSPR 32 ACC 84\n",
    "\n",
    "hr 32 eda 32 rspr 32 acc 71\n",
    "\n",
    "hr 32 eda 32 rspr 16 rspa 32 a 90\n",
    "\n",
    "hr 64 eda 32 rspr 16 rspa 32 a 77\n",
    "\n",
    "hr 32 eda 64 rspr 16 rspa 32 a 0\n",
    "\n",
    "hr 128 eda 64 rspr 16 rspa 32 a 67\n",
    "\n",
    "hr 32 eda 32 rspr 16 rspa 32 d 256 a 24\n",
    "\n",
    "hr 32 eda 32 rspr 32 rspa 16 d 256 a 98\n",
    "\n",
    "same l 256\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _NonLocalBlockND(nn.Module):\n",
    "    def __init__(self, in_channels, inter_channels=None, dimension=3, sub_sample=True, bn_layer=True):\n",
    "        super(_NonLocalBlockND, self).__init__()\n",
    "\n",
    "        assert dimension in [1, 2, 3]\n",
    "\n",
    "        self.dimension = dimension\n",
    "        self.sub_sample = sub_sample\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.inter_channels = inter_channels\n",
    "\n",
    "        if self.inter_channels is None:\n",
    "            self.inter_channels = in_channels // 2\n",
    "            if self.inter_channels == 0:\n",
    "                self.inter_channels = 1\n",
    "\n",
    "        if dimension == 3:\n",
    "            conv_nd = nn.Conv3d\n",
    "            max_pool_layer = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "            bn = nn.BatchNorm3d\n",
    "        elif dimension == 2:\n",
    "            conv_nd = nn.Conv2d\n",
    "            max_pool_layer = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "            bn = nn.BatchNorm2d\n",
    "        else:\n",
    "            conv_nd = nn.Conv1d\n",
    "            max_pool_layer = nn.MaxPool1d(kernel_size=(2))\n",
    "            bn = nn.BatchNorm1d\n",
    "\n",
    "        self.g = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                         kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        if bn_layer:\n",
    "            self.W = nn.Sequential(\n",
    "                conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                        kernel_size=1, stride=1, padding=0),\n",
    "                bn(self.in_channels)\n",
    "            )\n",
    "            nn.init.constant(self.W[1].weight, 0)\n",
    "            nn.init.constant(self.W[1].bias, 0)\n",
    "        else:\n",
    "            self.W = conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                             kernel_size=1, stride=1, padding=0)\n",
    "            nn.init.constant(self.W.weight, 0)\n",
    "            nn.init.constant(self.W.bias, 0)\n",
    "\n",
    "        self.theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                             kernel_size=1, stride=1, padding=0)\n",
    "        self.phi = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                           kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        if sub_sample:\n",
    "            self.g = nn.Sequential(self.g, max_pool_layer)\n",
    "            self.phi = nn.Sequential(self.phi, max_pool_layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x: (b, c, t, h, w)\n",
    "        :return:\n",
    "        '''\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
    "        g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n",
    "        theta_x = theta_x.permute(0, 2, 1)\n",
    "        phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
    "        f = torch.matmul(theta_x, phi_x)\n",
    "        f_div_C = F.softmax(f, dim=-1)\n",
    "\n",
    "        y = torch.matmul(f_div_C, g_x)\n",
    "        y = y.permute(0, 2, 1).contiguous()\n",
    "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
    "        W_y = self.W(y)\n",
    "        z = W_y + x\n",
    "\n",
    "        return z\n",
    "\n",
    "\n",
    "class NONLocalBlock1D(_NonLocalBlockND):\n",
    "    def __init__(self, in_channels, inter_channels=None, sub_sample=True, bn_layer=True):\n",
    "        super(NONLocalBlock1D, self).__init__(in_channels,\n",
    "                                              inter_channels=inter_channels,\n",
    "                                              dimension=1, sub_sample=sub_sample,\n",
    "                                              bn_layer=bn_layer)\n",
    "class NONLocalBlock2D(_NonLocalBlockND):\n",
    "    def __init__(self, in_channels, inter_channels=None, sub_sample=True, bn_layer=True):\n",
    "        super(NONLocalBlock2D, self).__init__(in_channels,\n",
    "                                              inter_channels=inter_channels,\n",
    "                                              dimension=2, sub_sample=sub_sample,\n",
    "                                              bn_layer=bn_layer)\n",
    "\n",
    "# class NonLocalBlock(nn.Module):\n",
    "#     def __init__(self, channel):\n",
    "#         super(NonLocalBlock, self).__init__()\n",
    "#         self.inter_channel = channel\n",
    "#         self.conv_phi = nn.Conv2d(in_channels=channel, out_channels=self.inter_channel, kernel_size=1, stride=1,padding=0, bias=False)\n",
    "#         self.conv_theta = nn.Conv2d(in_channels=channel, out_channels=self.inter_channel, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "#         self.conv_g = nn.Conv2d(in_channels=channel, out_channels=self.inter_channel, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "#         self.conv_mask = nn.Conv2d(in_channels=self.inter_channel, out_channels=channel, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # [N, C, H , W]\n",
    "#         b, c, h, w = x.size()\n",
    "#         # [N, C/2, H * W]\n",
    "# #         print(b, c, h, w)\n",
    "# #         print(self.conv_phi(x).view(b, c, -1).shape)\n",
    "#         x_phi = self.conv_phi(x).view(b, c, -1)\n",
    "#         # [N, H * W, C/2]\n",
    "#         x_theta = self.conv_theta(x).view(b, c, -1).permute(0, 2, 1).contiguous()\n",
    "#         x_g = self.conv_g(x).view(b, c, -1).permute(0, 2, 1).contiguous()\n",
    "#         # [N, H * W, H * W]\n",
    "#         mul_theta_phi = torch.matmul(x_theta, x_phi)\n",
    "#         mul_theta_phi = self.softmax(mul_theta_phi)\n",
    "#         # [N, H * W, C/2]\n",
    "#         mul_theta_phi_g = torch.matmul(mul_theta_phi, x_g)\n",
    "#         # [N, C/2, H, W]\n",
    "#         mul_theta_phi_g = mul_theta_phi_g.permute(0,2,1).contiguous().view(b,self.inter_channel, h, w)\n",
    "#         # [N, C, H , W]\n",
    "#         mask = self.conv_mask(mul_theta_phi_g)\n",
    "#         out = mask + x\n",
    "#         return out\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.L = 256\n",
    "        self.D = 128\n",
    "        self.K = 1\n",
    "        self.non_local_size=4\n",
    "        \n",
    "        self.lossfn=nn.MSELoss()\n",
    "\n",
    "        self.nl=NONLocalBlock1D(4)\n",
    "        \n",
    "        self.attention_transform_M = nn.Sequential( #only use for \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.L*self.K*4, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512,self.K)\n",
    "        )\n",
    "\n",
    "        self.feature_extractor_HR = nn.Sequential(\n",
    "            nn.Linear(6,self.D),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.feature_extractor_EDA = nn.Sequential(\n",
    "            nn.Linear(6,self.D),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.feature_extractor_RSPR= nn.Sequential(\n",
    "            nn.Linear(6,self.D),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.feature_extractor_RSPA= nn.Sequential(\n",
    "            nn.Linear(6,self.D),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.feature_transform_HR = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.BatchNorm1d(self.D, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True),\n",
    "            nn.Linear(self.D, self.L)\n",
    "        )\n",
    "        \n",
    "        self.attention_transform_HR = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.D, self.L),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.L,self.K)\n",
    "        )\n",
    "        \n",
    "        self.feature_transform_EDA = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.BatchNorm1d(self.D, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True),\n",
    "            nn.Linear(self.D, self.L)\n",
    "        )\n",
    "        \n",
    "        self.attention_transform_EDA = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.D, self.L),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.L,self.K)\n",
    "        )\n",
    "        \n",
    "        self.feature_transform_RSPA = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.BatchNorm1d(self.D, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True),\n",
    "            nn.Linear(self.D, self.L)\n",
    "        )\n",
    "        \n",
    "        self.attention_transform_RSPA = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.D, self.L),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.L,self.K)\n",
    "        )\n",
    "        \n",
    "        self.feature_transform_RSPR = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.BatchNorm1d(self.D, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True),\n",
    "            nn.Linear(self.D, self.L)\n",
    "        )\n",
    "        \n",
    "        self.attention_transform_RSPR = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.D, self.L),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.L,self.K)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.L*self.K*4, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def attention_pooling(self,feature_embed_HR,feature_embed_EDA,feature_embed_RSPA,feature_embed_RSPR):\n",
    "        \n",
    "        #HR\n",
    "        feature_transform_HR = self.feature_transform_HR(feature_embed_HR)\n",
    "        \n",
    "        A_t_hr = self.attention_transform_HR(feature_embed_HR)\n",
    "        \n",
    "        A_t_hr = torch.transpose(A_t_hr, 1, 0)\n",
    "        \n",
    "        A_t_hr = F.softmax(A_t_hr, dim=1)\n",
    "\n",
    "        M_hr = torch.mm(A_t_hr, feature_transform_HR)\n",
    "        \n",
    "        #EDA\n",
    "        \n",
    "        feature_transform_EDA = self.feature_transform_HR(feature_embed_EDA)\n",
    "        \n",
    "        A_t_eda = self.attention_transform_EDA(feature_embed_EDA)\n",
    "        \n",
    "        A_t_eda = torch.transpose(A_t_eda, 1, 0)\n",
    "        \n",
    "        A_t_eda = F.softmax(A_t_eda, dim=1)\n",
    "\n",
    "        M_eda = torch.mm(A_t_eda, feature_transform_EDA)\n",
    "        \n",
    "        #RSPA\n",
    "\n",
    "        feature_transform_RSPA = self.feature_transform_RSPA(feature_embed_RSPA)\n",
    "        \n",
    "        A_t_rspa = self.attention_transform_RSPA(feature_embed_RSPA)\n",
    "        \n",
    "        A_t_rspa = torch.transpose(A_t_rspa, 1, 0)\n",
    "        \n",
    "        A_t_rspa = F.softmax(A_t_rspa, dim=1)\n",
    "\n",
    "        M_rspa = torch.mm(A_t_rspa, feature_transform_RSPA)\n",
    "        \n",
    "        #RSPR\n",
    "\n",
    "        feature_transform_RSPR = self.feature_transform_RSPR(feature_embed_RSPR)\n",
    "        \n",
    "        A_t_rspr = self.attention_transform_RSPR(feature_embed_RSPR)\n",
    "        \n",
    "        A_t_rspr = torch.transpose(A_t_rspr, 1, 0)\n",
    "        \n",
    "        A_t_rspr = F.softmax(A_t_rspr, dim=1)\n",
    "\n",
    "        M_rspr = torch.mm(A_t_rspr, feature_transform_RSPR)\n",
    "        \n",
    "        M=torch.cat((M_hr,M_eda,M_rspa,M_rspr),dim=0)\n",
    "        \n",
    "        return M\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        x=x.squeeze(0)\n",
    "        \n",
    "        #HR\n",
    "        \n",
    "        feature_embed_HR= self.feature_extractor_HR(x[:,:,:6])\n",
    "        \n",
    "\n",
    "        \n",
    "        #EDA\n",
    "        \n",
    "        feature_embed_EDA= self.feature_extractor_EDA(x[:,:,6:12])\n",
    "        \n",
    "        \n",
    "        #RSPA\n",
    "        \n",
    "        feature_embed_RSPA= self.feature_extractor_RSPA(x[:,:,12:18])\n",
    "        \n",
    "        \n",
    "        #RSPR\n",
    "        \n",
    "        feature_embed_RSPR= self.feature_extractor_RSPR(x[:,:,18:24])\n",
    "        \n",
    "        \n",
    "        \n",
    "        M = self.attention_pooling(feature_embed_HR,feature_embed_EDA,feature_embed_RSPA,feature_embed_RSPR)\n",
    "        \n",
    "#         print(M.shape)\n",
    "        \n",
    "        M = M.reshape(1,4,self.L)\n",
    "        \n",
    "#         print(M.shape)\n",
    "        \n",
    "        M = self.nl(M) \n",
    "        \n",
    "#         print(\"---->\",M.shape)\n",
    "        \n",
    "        M=M.reshape(M.size(0),-1)\n",
    "        \n",
    "#         print(M.shape)\n",
    "\n",
    "        Y_prob = self.classifier(M)        \n",
    "        \n",
    "        Y_hat = torch.ge(Y_prob, 0.5).float()\n",
    "\n",
    "        return Y_prob, Y_hat\n",
    "\n",
    "\n",
    "\n",
    "    # AUXILIARY METHODS\n",
    "    def calculate_classification_error(self, X, Y):\n",
    "        Y = Y.float()\n",
    "        _, Y_hat = self.forward(X)\n",
    "        error = 1. - Y_hat.eq(Y).cpu().float().mean().item()\n",
    "\n",
    "        return error, Y_hat\n",
    "\n",
    "    def calculate_objective(self, X, Y):\n",
    "        Y = Y.float()\n",
    "        Y_prob, _ = self.forward(X)\n",
    "        Y_prob = torch.clamp(Y_prob, min=1e-5, max=1. - 1e-5)\n",
    "        loss=self.lossfn(Y_prob.squeeze(1),Y)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    }
   ],
   "source": [
    "model = Attention()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
    "# model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# summary(model.cuda(),(1,24))\n",
    "# best_state=model.state_dict()\n",
    "# torch.save(best_state, \"best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0\n",
      "Train : Loss: 0.2493, Train error: 0.4651, Train acc : 0.3908629441624366\n",
      "Val acc :0.576923076923077\n",
      "Best validation accuracy  0\n",
      "test acc :0.6896551724137931\n",
      "EPOCH  1\n",
      "Train : Loss: 0.2433, Train error: 0.4186, Train acc : 0.329192546583851\n",
      "Val acc :0.5426356589147286\n",
      "Best validation accuracy  0\n",
      "test acc :0.8088235294117648\n",
      "EPOCH  2\n",
      "Train : Loss: 0.2387, Train error: 0.3934, Train acc : 0.4727272727272727\n",
      "Val acc :0.45378151260504196\n",
      "Best validation accuracy  0\n",
      "test acc :0.873015873015873\n",
      "EPOCH  3\n",
      "Train : Loss: 0.2337, Train error: 0.3760, Train acc : 0.529126213592233\n",
      "Val acc :0.5\n",
      "Best validation accuracy  0\n",
      "test acc :0.8615384615384615\n",
      "EPOCH  4\n",
      "Train : Loss: 0.2258, Train error: 0.3837, Train acc : 0.5263157894736842\n",
      "Val acc :0.40336134453781514\n",
      "Best validation accuracy  0\n",
      "test acc :0.9310344827586207\n",
      "EPOCH  5\n",
      "Train : Loss: 0.2185, Train error: 0.3450, Train acc : 0.5990990990990991\n",
      "Val acc :0.6097560975609757\n",
      "Best validation accuracy  0\n",
      "test acc :0.8529411764705882\n",
      "EPOCH  6\n",
      "Train : Loss: 0.2156, Train error: 0.3488, Train acc : 0.5927601809954751\n",
      "Val acc :0.380952380952381\n",
      "Best validation accuracy  0\n",
      "test acc :0.9824561403508771\n",
      "EPOCH  7\n",
      "Train : Loss: 0.2143, Train error: 0.3488, Train acc : 0.5945945945945947\n",
      "Val acc :0.6432748538011696\n",
      "Best validation accuracy  0\n",
      "test acc :0.8382352941176471\n",
      "EPOCH  8\n",
      "Train : Loss: 0.2088, Train error: 0.3256, Train acc : 0.6199095022624433\n",
      "Val acc :0.3636363636363637\n",
      "Best validation accuracy  0\n",
      "test acc :0.9357798165137614\n",
      "EPOCH  9\n",
      "Train : Loss: 0.2075, Train error: 0.3275, Train acc : 0.6167800453514739\n",
      "Val acc :0.6463414634146342\n",
      "Best validation accuracy  0\n",
      "test acc :0.8592592592592593\n",
      "EPOCH  10\n",
      "Train : Loss: 0.2027, Train error: 0.3198, Train acc : 0.617169373549884\n",
      "Val acc :0.3738317757009346\n",
      "Best validation accuracy  0\n",
      "test acc :0.9824561403508771\n",
      "EPOCH  11\n",
      "Train : Loss: 0.2019, Train error: 0.3140, Train acc : 0.6301369863013698\n",
      "Val acc :0.5921052631578948\n",
      "Best validation accuracy  0\n",
      "test acc :0.9491525423728815\n",
      "EPOCH  12\n",
      "Train : Loss: 0.2003, Train error: 0.3159, Train acc : 0.6287015945330297\n",
      "Val acc :0.4918032786885246\n",
      "Best validation accuracy  0\n",
      "test acc :0.9734513274336283\n",
      "EPOCH  13\n",
      "Train : Loss: 0.1961, Train error: 0.3023, Train acc : 0.6563876651982378\n",
      "Val acc :0.6588235294117647\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.8421052631578948\n",
      "EPOCH  14\n",
      "Train : Loss: 0.1926, Train error: 0.3043, Train acc : 0.6487695749440716\n",
      "Val acc :0.6628571428571429\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.8467153284671534\n",
      "EPOCH  15\n",
      "Train : Loss: 0.1921, Train error: 0.3004, Train acc : 0.6578366445916115\n",
      "Val acc :0.5076923076923077\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.9824561403508771\n",
      "EPOCH  16\n",
      "Train : Loss: 0.1859, Train error: 0.2888, Train acc : 0.6739606126914661\n",
      "Val acc :0.5507246376811594\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :1.0\n",
      "EPOCH  17\n",
      "Train : Loss: 0.1800, Train error: 0.2791, Train acc : 0.6756756756756757\n",
      "Val acc :0.6551724137931034\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.8467153284671534\n",
      "EPOCH  18\n",
      "Train : Loss: 0.1782, Train error: 0.2752, Train acc : 0.6926406926406927\n",
      "Val acc :0.6511627906976745\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.888888888888889\n",
      "EPOCH  19\n",
      "Train : Loss: 0.1703, Train error: 0.2481, Train acc : 0.719298245614035\n",
      "Val acc :0.3669724770642202\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.9391304347826087\n",
      "EPOCH  20\n",
      "Train : Loss: 0.1727, Train error: 0.2597, Train acc : 0.7161016949152543\n",
      "Val acc :0.38888888888888884\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :1.0\n",
      "EPOCH  21\n",
      "Train : Loss: 0.1780, Train error: 0.2946, Train acc : 0.6513761467889907\n",
      "Val acc :0.46551724137931033\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.9824561403508771\n",
      "EPOCH  22\n",
      "Train : Loss: 0.1649, Train error: 0.2422, Train acc : 0.7311827956989247\n",
      "Val acc :0.37735849056603776\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.9824561403508771\n",
      "EPOCH  23\n",
      "Train : Loss: 0.1649, Train error: 0.2461, Train acc : 0.7292110874200427\n",
      "Val acc :0.43902439024390244\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.9734513274336283\n",
      "EPOCH  24\n",
      "Train : Loss: 0.1646, Train error: 0.2481, Train acc : 0.7253218884120173\n",
      "Val acc :0.39252336448598135\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :1.0\n",
      "EPOCH  25\n",
      "Train : Loss: 0.1676, Train error: 0.2384, Train acc : 0.7377398720682302\n",
      "Val acc :0.4166666666666667\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.9734513274336283\n",
      "EPOCH  26\n",
      "Train : Loss: 0.1655, Train error: 0.2558, Train acc : 0.7191489361702127\n",
      "Val acc :0.380952380952381\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.8400000000000001\n",
      "EPOCH  27\n",
      "Train : Loss: 0.1536, Train error: 0.2287, Train acc : 0.7445887445887446\n",
      "Val acc :0.5454545454545455\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.9430894308943091\n",
      "EPOCH  28\n",
      "Train : Loss: 0.1555, Train error: 0.2326, Train acc : 0.7424892703862662\n",
      "Val acc :0.39252336448598135\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.8761904761904762\n",
      "EPOCH  29\n",
      "Train : Loss: 0.1518, Train error: 0.2248, Train acc : 0.7478260869565216\n",
      "Val acc :0.49523809523809526\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.9549549549549551\n",
      "EPOCH  30\n",
      "Train : Loss: 0.1542, Train error: 0.2171, Train acc : 0.7575757575757576\n",
      "Val acc :0.37735849056603776\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.8431372549019609\n",
      "EPOCH  31\n",
      "Train : Loss: 0.1524, Train error: 0.2171, Train acc : 0.7586206896551726\n",
      "Val acc :0.5294117647058824\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.9914529914529915\n",
      "EPOCH  32\n",
      "Train : Loss: 0.1424, Train error: 0.1899, Train acc : 0.7949790794979078\n",
      "Val acc :0.6238532110091743\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.5\n",
      "EPOCH  33\n",
      "Train : Loss: 0.1444, Train error: 0.1996, Train acc : 0.7794432548179872\n",
      "Val acc :0.3738317757009346\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.49350649350649356\n",
      "EPOCH  34\n",
      "Train : Loss: 0.1478, Train error: 0.2171, Train acc : 0.7575757575757576\n",
      "Val acc :0.37735849056603776\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :1.0\n",
      "EPOCH  35\n",
      "Train : Loss: 0.1322, Train error: 0.1802, Train acc : 0.8025477707006369\n",
      "Val acc :0.37735849056603776\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.8400000000000001\n",
      "EPOCH  36\n",
      "Train : Loss: 0.1439, Train error: 0.1880, Train acc : 0.789587852494577\n",
      "Val acc :0.6065573770491803\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.5227272727272728\n",
      "EPOCH  37\n",
      "Train : Loss: 0.1406, Train error: 0.2035, Train acc : 0.7789473684210527\n",
      "Val acc :0.5210084033613445\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.8928571428571429\n",
      "EPOCH  38\n",
      "Train : Loss: 0.1304, Train error: 0.1880, Train acc : 0.7904967602591793\n",
      "Val acc :0.38461538461538464\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.4324324324324324\n",
      "EPOCH  39\n",
      "Train : Loss: 0.1209, Train error: 0.1860, Train acc : 0.7931034482758621\n",
      "Val acc :0.5\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.9661016949152542\n",
      "EPOCH  40\n",
      "Train : Loss: 0.1330, Train error: 0.1957, Train acc : 0.7818574514038875\n",
      "Val acc :0.38983050847457634\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :1.0\n",
      "EPOCH  41\n",
      "Train : Loss: 0.1322, Train error: 0.1919, Train acc : 0.7861771058315334\n",
      "Val acc :0.37735849056603776\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.8737864077669902\n",
      "EPOCH  42\n",
      "Train : Loss: 0.1394, Train error: 0.1996, Train acc : 0.7822410147991543\n",
      "Val acc :0.37735849056603776\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.8400000000000001\n",
      "EPOCH  43\n",
      "Train : Loss: 0.1193, Train error: 0.1589, Train acc : 0.8232758620689655\n",
      "Val acc :0.37735849056603776\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.4324324324324324\n",
      "EPOCH  44\n",
      "Train : Loss: 0.1254, Train error: 0.1744, Train acc : 0.8109243697478992\n",
      "Val acc :0.4444444444444445\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.15873015873015872\n",
      "EPOCH  45\n",
      "Train : Loss: 0.1287, Train error: 0.1705, Train acc : 0.8127659574468085\n",
      "Val acc :0.37735849056603776\n",
      "Best validation accuracy  0.6588235294117647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc :0.4736842105263158\n",
      "EPOCH  46\n",
      "Train : Loss: 0.1146, Train error: 0.1628, Train acc : 0.8220338983050848\n",
      "Val acc :0.380952380952381\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.4533333333333333\n",
      "EPOCH  47\n",
      "Train : Loss: 0.1278, Train error: 0.1860, Train acc : 0.7974683544303797\n",
      "Val acc :0.380952380952381\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.4109589041095891\n",
      "EPOCH  48\n",
      "Train : Loss: 0.1200, Train error: 0.1434, Train acc : 0.841880341880342\n",
      "Val acc :0.40366972477064217\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.7252747252747253\n",
      "EPOCH  49\n",
      "Train : Loss: 0.1158, Train error: 0.1686, Train acc : 0.8120950323974082\n",
      "Val acc :0.46511627906976755\n",
      "Best validation accuracy  0.6588235294117647\n",
      "test acc :0.09836065573770492\n"
     ]
    }
   ],
   "source": [
    "best_model = \"./saved_models/best_model_MIL_raw_MH_fir\"\n",
    "train_acc = []\n",
    "modelname=[]\n",
    "val_acc = []\n",
    "best_acc = 0\n",
    "for epoch in range(0, 50): #13- 2021\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    train_error = 0.\n",
    "    y =[]\n",
    "    ypred = []\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        bag_label = label[0]\n",
    "        data, bag_label = data.cuda(), bag_label.cuda()\n",
    "        data, bag_label = Variable(data), Variable(bag_label)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.calculate_objective(data.float(), bag_label.float())\n",
    "        train_loss += loss.item()\n",
    "        error,y_pred = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "        train_error += error\n",
    "        y_pred=y_pred.squeeze(1)\n",
    "        ypred.extend(y_pred.tolist())\n",
    "        y.extend(bag_label.tolist())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    trainacc = f1_score(y,ypred)\n",
    "    train_loss /= len(train_loader)\n",
    "    train_error /= len(train_loader)\n",
    "    print(\"EPOCH \",epoch)\n",
    "    print('Train : Loss: {:.4f}, Train error: {:.4f}, Train acc : {}'.format(train_loss, \n",
    "                                                                                train_error,trainacc))\n",
    "    y =[]\n",
    "    ypred = []\n",
    "    model.eval()\n",
    "    for batch_idx, (data, label) in enumerate(val_loader):\n",
    "        bag_label = label[0]\n",
    "        data, bag_label = data.cuda(), bag_label.cuda()\n",
    "        data, bag_label = Variable(data), Variable(bag_label)\n",
    "        error, y_pred = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "        y_pred=y_pred.squeeze(1)\n",
    "        ypred.extend(y_pred.tolist())\n",
    "        y.extend(bag_label.tolist())\n",
    "    valacc = f1_score(y,ypred)\n",
    "    print('Val acc :{}'.format(valacc))\n",
    "    if (valacc>=best_acc and trainacc>0.65):\n",
    "        print(\"---------State saved---------\")\n",
    "        best_acc = valacc\n",
    "        best_state=model.state_dict()\n",
    "        torch.save(best_state, best_model+'_epoch_'+str(epoch)+\".pth\")\n",
    "        modelname.append(best_model+'_epoch_'+str(epoch)+\".pth\")\n",
    "    print('Best validation accuracy ',best_acc)\n",
    "\n",
    "    y =[]\n",
    "    ypred = []\n",
    "    for batch_idx, (data, label) in enumerate(test_loader):\n",
    "        bag_label = label[0]\n",
    "        data, bag_label = data.cuda(), bag_label.cuda()\n",
    "        data, bag_label = Variable(data), Variable(bag_label)\n",
    "        error, y_pred = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "        y_pred=y_pred.squeeze(1)\n",
    "        ypred.extend(y_pred.tolist())\n",
    "        y.extend(bag_label.tolist())\n",
    "    valacc = f1_score(y,ypred)\n",
    "    print('test acc :{}'.format(valacc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8220338983050848 0.8421052631578948 0.7466666666666667 0.9655172413793104 0.8244252873563218 0.6833333333333333\n",
      "./saved_models/best_model_MIL_raw_MH_fir_epoch_13.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8220338983050848 0.8421052631578948 0.7466666666666667 0.9655172413793104 0.8244252873563218 0.6833333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "device = torch.device(\"cuda\")\n",
    "model=Attention()\n",
    "# best_state=torch.load(\"../best-models/Attention_MIL_best(stress)_F1_91.pth\")\n",
    "best_state=torch.load(modelname[-1])\n",
    "model.load_state_dict(best_state)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "test_loss = 0.\n",
    "correct = 0\n",
    "total = 0\n",
    "y =[]\n",
    "ypred = []\n",
    "test_error = 0.\n",
    "for batch_idx, (data, label) in enumerate(test_loader):\n",
    "    bag_label = label[0]\n",
    "    instance_labels = label[1]\n",
    "    data, bag_label = data.cuda(), bag_label.cuda()\n",
    "    data, bag_label = Variable(data), Variable(bag_label)\n",
    "    loss = model.calculate_objective(data.float(), bag_label.float())\n",
    "    test_loss += loss.item()\n",
    "    error, predicted_label = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "    test_error += error\n",
    "    predicted_label=predicted_label.squeeze(1)\n",
    "    ypred.extend(predicted_label.tolist())\n",
    "    y.extend(bag_label.tolist())\n",
    "    \n",
    "acc=accuracy_score(y,ypred)\n",
    "# print(y,ypred)\n",
    "tn, fp, fn, tp = confusion_matrix(y,ypred).ravel()\n",
    "f1score=f1_score(y,ypred)\n",
    "precision=precision_score(y,ypred)\n",
    "recall=recall_score(y,ypred)\n",
    "roc=roc_auc_score(y,ypred)\n",
    "specificity=tn/(tn+fp)\n",
    "print(acc,f1score,precision,recall,roc,specificity)\n",
    "\n",
    "for i in modelname:\n",
    "    print(i)\n",
    "    model=Attention()\n",
    "    # best_state=torch.load(\"../best-models/Attention_MIL_best(stress)_F1_91.pth\")\n",
    "    best_state=torch.load(i)\n",
    "    model.load_state_dict(best_state)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y =[]\n",
    "    ypred = []\n",
    "    test_error = 0.\n",
    "    for batch_idx, (data, label) in enumerate(test_loader):\n",
    "        bag_label = label[0]\n",
    "        instance_labels = label[1]\n",
    "        data, bag_label = data.cuda(), bag_label.cuda()\n",
    "        data, bag_label = Variable(data), Variable(bag_label)\n",
    "        loss = model.calculate_objective(data.float(), bag_label.float())\n",
    "        test_loss += loss.item()\n",
    "        error, predicted_label = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "        test_error += error\n",
    "        predicted_label=predicted_label.squeeze(1)\n",
    "        ypred.extend(predicted_label.tolist())\n",
    "        y.extend(bag_label.tolist())\n",
    "\n",
    "    acc=accuracy_score(y,ypred)\n",
    "    # print(y,ypred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y,ypred).ravel()\n",
    "    f1score=f1_score(y,ypred)\n",
    "    precision=precision_score(y,ypred)\n",
    "    recall=recall_score(y,ypred)\n",
    "    roc=roc_auc_score(y,ypred)\n",
    "    specificity=tn/(tn+fp)\n",
    "    print(acc,f1score,precision,recall,roc,specificity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8305084745762712 0.8484848484848485 0.7567567567567568 0.9655172413793104 0.8327586206896551 0.7\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model=Attention()\n",
    "best_state=torch.load(modelname[-1])\n",
    "model.load_state_dict(best_state)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "testdataset = load_data('../Participant_wise_win-1','test')\n",
    "test_loader = data_utils.DataLoader(Stammering(train=\"test\"),worker_init_fn=seed_worker,batch_size=1,shuffle=True)\n",
    "attn_weights=[]\n",
    "test_loss = 0.\n",
    "correct = 0\n",
    "total = 0\n",
    "y =[]\n",
    "ypred = []\n",
    "test_error = 0.\n",
    "for batch_idx, (data, label) in enumerate(test_loader):\n",
    "    bag_label = label[0]\n",
    "    instance_labels = label[1]\n",
    "    data, bag_label = data.cuda(), bag_label.cuda()\n",
    "    data, bag_label = Variable(data), Variable(bag_label)\n",
    "    loss = model.calculate_objective(data.float(), bag_label.float())\n",
    "    test_loss += loss.item()\n",
    "    error, predicted_label = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "    test_error += error\n",
    "    predicted_label=predicted_label.squeeze(1)\n",
    "    ypred.extend(predicted_label.tolist())\n",
    "    y.extend(bag_label.tolist())\n",
    "acc=accuracy_score(y,ypred)\n",
    "tn, fp, fn, tp = confusion_matrix(y,ypred).ravel()\n",
    "f1score=f1_score(y,ypred)\n",
    "precision=precision_score(y,ypred)\n",
    "recall=recall_score(y,ypred)\n",
    "roc=roc_auc_score(y,ypred)\n",
    "specificity=tn/(tn+fp)\n",
    "# print(best_model)\n",
    "print(acc,f1score,precision,recall,roc,specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8135593220338984 0.835820895522388 0.7368421052631579 0.9655172413793104 0.8160919540229886 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model=Attention()\n",
    "best_state=torch.load(modelname[-1])\n",
    "model.load_state_dict(best_state)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "testdataset = load_data('../Participant_wise_win-2','test')\n",
    "test_loader = data_utils.DataLoader(Stammering(train=\"test\"),worker_init_fn=seed_worker,batch_size=1,shuffle=True)\n",
    "attn_weights=[]\n",
    "test_loss = 0.\n",
    "correct = 0\n",
    "total = 0\n",
    "y =[]\n",
    "ypred = []\n",
    "test_error = 0.\n",
    "for batch_idx, (data, label) in enumerate(test_loader):\n",
    "    bag_label = label[0]\n",
    "    instance_labels = label[1]\n",
    "    data, bag_label = data.cuda(), bag_label.cuda()\n",
    "    data, bag_label = Variable(data), Variable(bag_label)\n",
    "    loss = model.calculate_objective(data.float(), bag_label.float())\n",
    "    test_loss += loss.item()\n",
    "    error, predicted_label = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "    test_error += error\n",
    "    predicted_label=predicted_label.squeeze(1)\n",
    "    ypred.extend(predicted_label.tolist())\n",
    "    y.extend(bag_label.tolist())\n",
    "acc=accuracy_score(y,ypred)\n",
    "tn, fp, fn, tp = confusion_matrix(y,ypred).ravel()\n",
    "f1score=f1_score(y,ypred)\n",
    "precision=precision_score(y,ypred)\n",
    "recall=recall_score(y,ypred)\n",
    "roc=roc_auc_score(y,ypred)\n",
    "specificity=tn/(tn+fp)\n",
    "# print(best_model)\n",
    "print(acc,f1score,precision,recall,roc,specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./saved_models/best_model_MIL_raw_MH_fir_epoch_13.pth'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelname[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(66+94)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (physio)",
   "language": "python",
   "name": "physio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
