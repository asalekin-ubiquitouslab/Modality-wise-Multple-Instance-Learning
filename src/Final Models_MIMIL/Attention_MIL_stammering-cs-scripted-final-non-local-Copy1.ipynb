{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import math\n",
    "seed = 941027\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(seed)\n",
    "#2021,7620,736,534\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    \n",
    "    \n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, X1,Y):\n",
    "        self.X1 = X1\n",
    "        self.Y = Y\n",
    "    def __len__(self):        \n",
    "        return len(self.X1)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.X1[index]\n",
    "        y = self.Y[index]\n",
    "        return x,y\n",
    "\n",
    "#from model import Attention, GatedAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negetive pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def readFeatures(path):\n",
    "    features=np.array([])\n",
    "    start=0\n",
    "    for file in os.listdir(path):\n",
    "        d = os.path.join(path, file)\n",
    "        datafile=d+\"/features.npy\"\n",
    "        try:\n",
    "            temp=np.load(datafile)\n",
    "#             print(datafile)\n",
    "#             print(temp.shape)\n",
    "            if(start==0):\n",
    "                features=temp\n",
    "                if(d[-10]=='S'):\n",
    "                    label=np.ones(len(temp))\n",
    "                else:\n",
    "                    label=np.zeros(len(temp))\n",
    "                start=1\n",
    "            else:\n",
    "                features=np.vstack((features,temp))\n",
    "                if(d[-10]=='S'):\n",
    "                    label=np.append(label,np.ones(len(temp)))\n",
    "                else:\n",
    "                    label=np.append(label,np.zeros(len(temp)))\n",
    "        except IOError:\n",
    "            print('file not in Scripted')\n",
    "\n",
    "            \n",
    "    return features,label\n",
    "\n",
    "def load_data(path,mode):\n",
    "    if mode == \"test\":\n",
    "        xTest,yTest=readFeatures(path+\"/\"+mode)\n",
    "        xTest = xTest.reshape(len(xTest),1,19,8)\n",
    "        return Dataset(xTest,yTest)\n",
    "        \n",
    "    elif mode == \"train\":\n",
    "        xTrain,yTrain=readFeatures(path+\"/\"+mode)\n",
    "        xTrain = xTrain.reshape(len(xTrain),1,19,8)\n",
    "        return Dataset(xTrain,yTrain)\n",
    "        \n",
    "    elif mode == \"val\":\n",
    "        xVal,yVal=readFeatures(path+\"/\"+mode)\n",
    "        xVal = xVal.reshape(len(xVal),1,19,8)\n",
    "        return Dataset(xVal,yVal)\n",
    "    else:\n",
    "        print(\"Mode not defined\")\n",
    "        return\n",
    "\n",
    "traindataset = load_data(\"../Participant_wise_physio_change\",'train')\n",
    "testdataset = load_data(\"../Participant_wise_physio_change\",'test')\n",
    "valdataset = load_data(\"../Participant_wise_physio_change\",'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stammering(data_utils.Dataset):\n",
    "    def __init__(self, target_number=1, mean_bag_length=5, var_bag_length=2, num_bag=150, seed=2021, train=\"train\"):\n",
    "        self.target_number = target_number\n",
    "        self.mean_bag_length = mean_bag_length\n",
    "        self.var_bag_length = var_bag_length\n",
    "        self.num_bag = num_bag\n",
    "        self.train = train\n",
    "        self.r = np.random.RandomState(seed)\n",
    "\n",
    "        if self.train==\"train\":\n",
    "            self.train_bags_list, self.train_labels_list = self._create_bags()\n",
    "        elif self.train==\"val\":\n",
    "            self.val_bags_list, self.val_labels_list = self._create_bags()\n",
    "        else:\n",
    "            self.test_bags_list, self.test_labels_list = self._create_bags()\n",
    "\n",
    "    def _create_bags(self):\n",
    "        if self.train==\"train\":\n",
    "            print(\"train\")\n",
    "            loader = data_utils.DataLoader(traindataset,\n",
    "                                           batch_size=1,\n",
    "                                           shuffle=True)\n",
    "        elif self.train==\"val\":\n",
    "            print(\"val\")\n",
    "            loader = data_utils.DataLoader(valdataset,\n",
    "                                           batch_size=1,\n",
    "                                           shuffle=True)\n",
    "        else:\n",
    "            loader = data_utils.DataLoader(testdataset,\n",
    "                                           batch_size=1,\n",
    "                                           shuffle=True)\n",
    "            \n",
    "        bags_list = []\n",
    "        labels_list = []\n",
    "        for (batch_data, batch_labels) in loader:\n",
    "            #print(batch_data.shape)\n",
    "            bags_list.append(batch_data.reshape(19,1,8))\n",
    "            temp = torch.as_tensor(np.array([batch_labels for x in range(19)]))\n",
    "            labels_list.append(temp)\n",
    "            \n",
    "               \n",
    "        #print(bags_list)\n",
    "        #print(labels_list)\n",
    "        return bags_list, labels_list\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train==\"train\":\n",
    "            return len(self.train_labels_list)\n",
    "        elif self.train==\"val\":\n",
    "            return len(self.val_labels_list)\n",
    "        else:\n",
    "            return len(self.test_labels_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train==\"train\":\n",
    "            bag = self.train_bags_list[index]\n",
    "            label = [max(self.train_labels_list[index]), self.train_labels_list[index]]\n",
    "        elif self.train==\"val\":\n",
    "            bag = self.val_bags_list[index]\n",
    "            label = [max(self.val_labels_list[index]), self.val_labels_list[index]]\n",
    "        else:\n",
    "            bag = self.test_bags_list[index]\n",
    "            label = [max(self.test_labels_list[index]), self.test_labels_list[index]]\n",
    "\n",
    "        return bag, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "val\n"
     ]
    }
   ],
   "source": [
    "train_loader = data_utils.DataLoader(Stammering(train=\"train\"),batch_size=1,worker_init_fn=seed_worker,shuffle=True)\n",
    "test_loader = data_utils.DataLoader(Stammering(train=\"test\"),batch_size=1,worker_init_fn=seed_worker,shuffle=True)\n",
    "val_loader = data_utils.DataLoader(Stammering(train=\"val\"),batch_size=1,worker_init_fn=seed_worker,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HR 32 acc 58\n",
    "\n",
    "HR 64 ACC 53\n",
    "\n",
    "HR 32 EDA 32 acc 60\n",
    "\n",
    "HR 32 EDA 16 RSPR 32 A 57\n",
    "\n",
    "HR 32 EDA 32 RSPR 32 a 33\n",
    "\n",
    "hr 32 eda 32 rspr 16 rspa 32 a 37\n",
    "\n",
    "hr 64 eda 32 rspr 16 rsp 32 a 30\n",
    "\n",
    "hr 32 eda 64 rspr 16 rspr 32 a 0\n",
    "\n",
    "hr 64 eda 32 rspr 16 rspr 16 a 53\n",
    "\n",
    "hr 64 eda 64 16 16 a 32 \n",
    "\n",
    "hr 32 eda 32 rspr 16 rspa 16 d 256 acc 35\n",
    "\n",
    "\n",
    "hr 32 eda 32 rspr 32 rspa 16 d 256 acc 61\n",
    "\n",
    "same l 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _NonLocalBlockND(nn.Module):\n",
    "    def __init__(self, in_channels, inter_channels=None, dimension=3, sub_sample=True, bn_layer=True):\n",
    "        super(_NonLocalBlockND, self).__init__()\n",
    "\n",
    "        assert dimension in [1, 2, 3]\n",
    "\n",
    "        self.dimension = dimension\n",
    "        self.sub_sample = sub_sample\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.inter_channels = inter_channels\n",
    "\n",
    "        if self.inter_channels is None:\n",
    "            self.inter_channels = in_channels // 2\n",
    "            if self.inter_channels == 0:\n",
    "                self.inter_channels = 1\n",
    "\n",
    "        if dimension == 3:\n",
    "            conv_nd = nn.Conv3d\n",
    "            max_pool_layer = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "            bn = nn.BatchNorm3d\n",
    "        elif dimension == 2:\n",
    "            conv_nd = nn.Conv2d\n",
    "            max_pool_layer = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "            bn = nn.BatchNorm2d\n",
    "        else:\n",
    "            conv_nd = nn.Conv1d\n",
    "            max_pool_layer = nn.MaxPool1d(kernel_size=(2))\n",
    "            bn = nn.BatchNorm1d\n",
    "\n",
    "        self.g = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                         kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        if bn_layer:\n",
    "            self.W = nn.Sequential(\n",
    "                conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                        kernel_size=1, stride=1, padding=0),\n",
    "                bn(self.in_channels)\n",
    "            )\n",
    "            nn.init.constant(self.W[1].weight, 0)\n",
    "            nn.init.constant(self.W[1].bias, 0)\n",
    "        else:\n",
    "            self.W = conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                             kernel_size=1, stride=1, padding=0)\n",
    "            nn.init.constant(self.W.weight, 0)\n",
    "            nn.init.constant(self.W.bias, 0)\n",
    "\n",
    "        self.theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                             kernel_size=1, stride=1, padding=0)\n",
    "        self.phi = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                           kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        if sub_sample:\n",
    "            self.g = nn.Sequential(self.g, max_pool_layer)\n",
    "            self.phi = nn.Sequential(self.phi, max_pool_layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x: (b, c, t, h, w)\n",
    "        :return:\n",
    "        '''\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
    "        g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n",
    "        theta_x = theta_x.permute(0, 2, 1)\n",
    "        phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
    "        f = torch.matmul(theta_x, phi_x)\n",
    "        f_div_C = F.softmax(f, dim=-1)\n",
    "\n",
    "        y = torch.matmul(f_div_C, g_x)\n",
    "        y = y.permute(0, 2, 1).contiguous()\n",
    "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
    "        W_y = self.W(y)\n",
    "        z = W_y + x\n",
    "\n",
    "        return z\n",
    "\n",
    "\n",
    "class NONLocalBlock1D(_NonLocalBlockND):\n",
    "    def __init__(self, in_channels, inter_channels=None, sub_sample=False, bn_layer=True):\n",
    "        super(NONLocalBlock1D, self).__init__(in_channels,\n",
    "                                              inter_channels=inter_channels,\n",
    "                                              dimension=1, sub_sample=sub_sample,\n",
    "                                              bn_layer=bn_layer)\n",
    "class NONLocalBlock2D(_NonLocalBlockND):\n",
    "    def __init__(self, in_channels, inter_channels=None, sub_sample=True, bn_layer=True):\n",
    "        super(NONLocalBlock2D, self).__init__(in_channels,\n",
    "                                              inter_channels=inter_channels,\n",
    "                                              dimension=2, sub_sample=sub_sample,\n",
    "                                              bn_layer=bn_layer)\n",
    "\n",
    "# class NonLocalBlock(nn.Module):\n",
    "#     def __init__(self, channel):\n",
    "#         super(NonLocalBlock, self).__init__()\n",
    "#         self.inter_channel = channel\n",
    "#         self.conv_phi = nn.Conv2d(in_channels=channel, out_channels=self.inter_channel, kernel_size=1, stride=1,padding=0, bias=False)\n",
    "#         self.conv_theta = nn.Conv2d(in_channels=channel, out_channels=self.inter_channel, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "#         self.conv_g = nn.Conv2d(in_channels=channel, out_channels=self.inter_channel, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "#         self.conv_mask = nn.Conv2d(in_channels=self.inter_channel, out_channels=channel, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # [N, C, H , W]\n",
    "#         b, c, h, w = x.size()\n",
    "#         # [N, C/2, H * W]\n",
    "# #         print(b, c, h, w)\n",
    "# #         print(self.conv_phi(x).view(b, c, -1).shape)\n",
    "#         x_phi = self.conv_phi(x).view(b, c, -1)\n",
    "#         # [N, H * W, C/2]\n",
    "#         x_theta = self.conv_theta(x).view(b, c, -1).permute(0, 2, 1).contiguous()\n",
    "#         x_g = self.conv_g(x).view(b, c, -1).permute(0, 2, 1).contiguous()\n",
    "#         # [N, H * W, H * W]\n",
    "#         mul_theta_phi = torch.matmul(x_theta, x_phi)\n",
    "#         mul_theta_phi = self.softmax(mul_theta_phi)\n",
    "#         # [N, H * W, C/2]\n",
    "#         mul_theta_phi_g = torch.matmul(mul_theta_phi, x_g)\n",
    "#         # [N, C/2, H, W]\n",
    "#         mul_theta_phi_g = mul_theta_phi_g.permute(0,2,1).contiguous().view(b,self.inter_channel, h, w)\n",
    "#         # [N, C, H , W]\n",
    "#         mask = self.conv_mask(mul_theta_phi_g)\n",
    "#         out = mask + x\n",
    "#         return out\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.L = 128\n",
    "        self.D = 256\n",
    "        self.K = 1\n",
    "\n",
    "#         self.nl = NonLocalBlock(4)\n",
    "        self.nl=NONLocalBlock1D(4)\n",
    "\n",
    "        self.lossfn=nn.MSELoss()\n",
    "        \n",
    "        self.attention_transform_M = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.L*self.K*4, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512,self.K)\n",
    "        )\n",
    "\n",
    "        self.feature_extractor_HR = nn.Sequential(\n",
    "#             nn.Linear(2,64),\n",
    "#             nn.ReLU(),\n",
    "            nn.Linear(2,self.D),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.feature_extractor_EDA = nn.Sequential(\n",
    "#             nn.Linear(2,32),\n",
    "#             nn.ReLU(),\n",
    "            nn.Linear(2,self.D),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.feature_extractor_RSPR= nn.Sequential(\n",
    "#             nn.Linear(2,16),\n",
    "#             nn.ReLU(),\n",
    "            nn.Linear(2,self.D),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.feature_extractor_RSPA= nn.Sequential(\n",
    "#             nn.Linear(2,64),\n",
    "#             nn.ReLU(),\n",
    "            nn.Linear(2,self.D),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.feature_transform_HR = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm1d(self.D, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True),\n",
    "            nn.Linear(self.D, self.L)\n",
    "        )\n",
    "        \n",
    "        self.attention_transform_HR = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.D, self.L),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.L,self.K)\n",
    "        )\n",
    "        \n",
    "        self.feature_transform_EDA = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.BatchNorm1d(self.D, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True),\n",
    "            nn.Linear(self.D, self.L)\n",
    "        )\n",
    "        \n",
    "        self.attention_transform_EDA = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.D, self.L),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.L,self.K)\n",
    "        )\n",
    "        \n",
    "        self.feature_transform_RSPA = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.BatchNorm1d(self.D, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True),\n",
    "            nn.Linear(self.D, self.L)\n",
    "        )\n",
    "        \n",
    "        self.attention_transform_RSPA = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.D, self.L),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.L,self.K)\n",
    "        )\n",
    "        \n",
    "        self.feature_transform_RSPR = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm1d(self.D, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True),\n",
    "            nn.Linear(self.D, self.L)\n",
    "        )\n",
    "        \n",
    "        self.attention_transform_RSPR = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.D, self.L),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.L,self.K)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.L*self.K*4, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def attention_pooling(self,feature_embed_HR,feature_embed_EDA,feature_embed_RSPA,feature_embed_RSPR):\n",
    "        \n",
    "        #HR\n",
    "        feature_transform_HR = self.feature_transform_HR(feature_embed_HR)\n",
    "        \n",
    "        A_t_hr = self.attention_transform_HR(feature_embed_HR)\n",
    "        \n",
    "        A_t_hr = torch.transpose(A_t_hr, 1, 0)\n",
    "        \n",
    "        A_t_hr = F.softmax(A_t_hr, dim=1)\n",
    "\n",
    "        M_hr = torch.mm(A_t_hr, feature_transform_HR)\n",
    "        \n",
    "        #EDA\n",
    "        \n",
    "        feature_transform_EDA = self.feature_transform_HR(feature_embed_EDA)\n",
    "        \n",
    "        A_t_eda = self.attention_transform_EDA(feature_embed_EDA)\n",
    "        \n",
    "        A_t_eda = torch.transpose(A_t_eda, 1, 0)\n",
    "        \n",
    "        A_t_eda = F.softmax(A_t_eda, dim=1)\n",
    "\n",
    "        M_eda = torch.mm(A_t_eda, feature_transform_EDA)\n",
    "        \n",
    "        #RSPA\n",
    "\n",
    "        feature_transform_RSPA = self.feature_transform_RSPA(feature_embed_RSPA)\n",
    "        \n",
    "        A_t_rspa = self.attention_transform_RSPA(feature_embed_RSPA)\n",
    "        \n",
    "        A_t_rspa = torch.transpose(A_t_rspa, 1, 0)\n",
    "        \n",
    "        A_t_rspa = F.softmax(A_t_rspa, dim=1)\n",
    "\n",
    "        M_rspa = torch.mm(A_t_rspa, feature_transform_RSPA)\n",
    "        \n",
    "        #RSPR\n",
    "\n",
    "        feature_transform_RSPR = self.feature_transform_RSPR(feature_embed_RSPR)\n",
    "        \n",
    "        A_t_rspr = self.attention_transform_RSPR(feature_embed_RSPR)\n",
    "        \n",
    "        A_t_rspr = torch.transpose(A_t_rspr, 1, 0)\n",
    "        \n",
    "        A_t_rspr = F.softmax(A_t_rspr, dim=1)\n",
    "\n",
    "        M_rspr = torch.mm(A_t_rspr, feature_transform_RSPR)\n",
    "        \n",
    "        M=torch.cat((M_hr,M_eda,M_rspa,M_rspr),dim=1)\n",
    "        \n",
    "        return M\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        x=x.squeeze(0)\n",
    "        \n",
    "        #HR\n",
    "        \n",
    "        feature_embed_HR= self.feature_extractor_HR(x[:,:,:2])\n",
    "        \n",
    "\n",
    "        \n",
    "        #EDA\n",
    "        \n",
    "        feature_embed_EDA= self.feature_extractor_EDA(x[:,:,2:4])\n",
    "        \n",
    "        \n",
    "        #RSPA\n",
    "        \n",
    "        feature_embed_RSPA= self.feature_extractor_RSPA(x[:,:,4:6])\n",
    "        \n",
    "        \n",
    "        #RSPR\n",
    "        \n",
    "        feature_embed_RSPR= self.feature_extractor_RSPR(x[:,:,6:8])\n",
    "        \n",
    "        \n",
    "        \n",
    "        M = self.attention_pooling(feature_embed_HR,feature_embed_EDA,feature_embed_RSPA,feature_embed_RSPR)\n",
    "        \n",
    "#         print(M.shape)\n",
    "        \n",
    "        M = M.reshape(1,4,self.L)\n",
    "        \n",
    "#         print(M.shape)\n",
    "        \n",
    "        M = self.nl(M) \n",
    "        \n",
    "#         print(M.shape)\n",
    "        \n",
    "        M=M.reshape(M.size(0),-1)\n",
    "        \n",
    "#         print(M.shape)\n",
    "\n",
    "        Y_prob = self.classifier(M)        \n",
    "        \n",
    "        Y_hat = torch.ge(Y_prob, 0.5).float()\n",
    "\n",
    "        return Y_prob, Y_hat\n",
    "\n",
    "\n",
    "\n",
    "    # AUXILIARY METHODS\n",
    "    def calculate_classification_error(self, X, Y):\n",
    "        Y = Y.float()\n",
    "        _, Y_hat = self.forward(X)\n",
    "        error = 1. - Y_hat.eq(Y).cpu().float().mean().item()\n",
    "\n",
    "        return error, Y_hat\n",
    "\n",
    "    def calculate_objective(self, X, Y):\n",
    "        Y = Y.float()\n",
    "        Y_prob, _ = self.forward(X)\n",
    "        Y_prob = torch.clamp(Y_prob, min=1e-5, max=1. - 1e-5)\n",
    "        loss=self.lossfn(Y_prob.squeeze(1),Y)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# summary(model.cuda(),(1,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0\n",
      "Train : Loss: 0.2467, Train error: 0.4574, Train acc : 0.3723404255319149\n",
      "Val acc :0.5576923076923076\n",
      "Best validation accuracy  0\n",
      "test acc :0.0\n",
      "EPOCH  1\n",
      "Train : Loss: 0.2314, Train error: 0.3740, Train acc : 0.42042042042042044\n",
      "Val acc :0.6573426573426574\n",
      "Best validation accuracy  0\n",
      "test acc :0.5692307692307692\n",
      "EPOCH  2\n",
      "Train : Loss: 0.2237, Train error: 0.3740, Train acc : 0.4712328767123288\n",
      "Val acc :0.5901639344262296\n",
      "Best validation accuracy  0\n",
      "test acc :0.3736263736263736\n",
      "EPOCH  3\n",
      "Train : Loss: 0.2163, Train error: 0.3430, Train acc : 0.544987146529563\n",
      "Val acc :0.6928104575163399\n",
      "Best validation accuracy  0\n",
      "test acc :0.5789473684210527\n",
      "EPOCH  4\n",
      "Train : Loss: 0.2235, Train error: 0.3547, Train acc : 0.5246753246753247\n",
      "Val acc :0.6933333333333332\n",
      "Best validation accuracy  0\n",
      "test acc :0.6578947368421053\n",
      "EPOCH  5\n",
      "Train : Loss: 0.2196, Train error: 0.3624, Train acc : 0.519280205655527\n",
      "Val acc :0.6842105263157894\n",
      "Best validation accuracy  0\n",
      "test acc :0.6\n",
      "EPOCH  6\n",
      "Train : Loss: 0.2124, Train error: 0.3217, Train acc : 0.5489130434782609\n",
      "Val acc :0.588235294117647\n",
      "Best validation accuracy  0\n",
      "test acc :0.14705882352941177\n",
      "EPOCH  7\n",
      "Train : Loss: 0.2108, Train error: 0.3430, Train acc : 0.5280000000000001\n",
      "Val acc :0.6351351351351352\n",
      "Best validation accuracy  0\n",
      "test acc :0.6379310344827587\n",
      "EPOCH  8\n",
      "Train : Loss: 0.2084, Train error: 0.3314, Train acc : 0.5464190981432361\n",
      "Val acc :0.5409836065573771\n",
      "Best validation accuracy  0\n",
      "test acc :0.4523809523809524\n",
      "EPOCH  9\n",
      "Train : Loss: 0.2081, Train error: 0.3391, Train acc : 0.5333333333333333\n",
      "Val acc :0.6380368098159509\n",
      "Best validation accuracy  0\n",
      "test acc :0.618421052631579\n",
      "EPOCH  10\n",
      "Train : Loss: 0.2021, Train error: 0.3275, Train acc : 0.5847665847665848\n",
      "Val acc :0.6514285714285714\n",
      "Best validation accuracy  0\n",
      "test acc :0.763157894736842\n",
      "EPOCH  11\n",
      "Train : Loss: 0.2021, Train error: 0.3120, Train acc : 0.6082725060827251\n",
      "Val acc :0.6590909090909091\n",
      "Best validation accuracy  0\n",
      "test acc :0.7169811320754716\n",
      "EPOCH  12\n",
      "Train : Loss: 0.2041, Train error: 0.3256, Train acc : 0.5692307692307693\n",
      "Val acc :0.65359477124183\n",
      "Best validation accuracy  0\n",
      "test acc :0.7017543859649122\n",
      "EPOCH  13\n",
      "Train : Loss: 0.1976, Train error: 0.3217, Train acc : 0.5911330049261083\n",
      "Val acc :0.6436781609195403\n",
      "Best validation accuracy  0\n",
      "test acc :0.7183098591549295\n",
      "EPOCH  14\n",
      "Train : Loss: 0.1950, Train error: 0.2888, Train acc : 0.6460807600950118\n",
      "Val acc :0.6627218934911243\n",
      "Best validation accuracy  0\n",
      "test acc :0.6712328767123287\n",
      "EPOCH  15\n",
      "Train : Loss: 0.1938, Train error: 0.2984, Train acc : 0.6315789473684211\n",
      "Val acc :0.6826347305389221\n",
      "Best validation accuracy  0\n",
      "test acc :0.8031496062992126\n",
      "EPOCH  16\n",
      "Train : Loss: 0.1910, Train error: 0.2829, Train acc : 0.6572769953051643\n",
      "Val acc :0.6627218934911243\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.6627218934911243\n",
      "test acc :0.7972027972027971\n",
      "EPOCH  17\n",
      "Train : Loss: 0.1878, Train error: 0.2965, Train acc : 0.6482758620689655\n",
      "Val acc :0.6514285714285714\n",
      "Best validation accuracy  0.6627218934911243\n",
      "test acc :0.7073170731707317\n",
      "EPOCH  18\n",
      "Train : Loss: 0.1889, Train error: 0.2868, Train acc : 0.6407766990291263\n",
      "Val acc :0.6590909090909091\n",
      "Best validation accuracy  0.6627218934911243\n",
      "test acc :0.6987951807228916\n",
      "EPOCH  19\n",
      "Train : Loss: 0.1854, Train error: 0.2849, Train acc : 0.6474820143884893\n",
      "Val acc :0.6514285714285714\n",
      "Best validation accuracy  0.6627218934911243\n",
      "test acc :0.7160493827160493\n",
      "EPOCH  20\n",
      "Train : Loss: 0.1824, Train error: 0.2733, Train acc : 0.6650831353919239\n",
      "Val acc :0.6551724137931034\n",
      "Best validation accuracy  0.6627218934911243\n",
      "test acc :0.6705202312138728\n",
      "EPOCH  21\n",
      "Train : Loss: 0.1811, Train error: 0.2694, Train acc : 0.6789838337182448\n",
      "Val acc :0.6746987951807228\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.6746987951807228\n",
      "test acc :0.7313432835820897\n",
      "EPOCH  22\n",
      "Train : Loss: 0.1804, Train error: 0.2713, Train acc : 0.6788990825688075\n",
      "Val acc :0.6705882352941177\n",
      "Best validation accuracy  0.6746987951807228\n",
      "test acc :0.7891156462585034\n",
      "EPOCH  23\n",
      "Train : Loss: 0.1814, Train error: 0.2674, Train acc : 0.6714285714285715\n",
      "Val acc :0.6590909090909091\n",
      "Best validation accuracy  0.6746987951807228\n",
      "test acc :0.6863905325443787\n",
      "EPOCH  24\n",
      "Train : Loss: 0.1800, Train error: 0.2655, Train acc : 0.67458432304038\n",
      "Val acc :0.6589595375722543\n",
      "Best validation accuracy  0.6746987951807228\n",
      "test acc :0.7388535031847133\n",
      "EPOCH  25\n",
      "Train : Loss: 0.1764, Train error: 0.2519, Train acc : 0.7018348623853211\n",
      "Val acc :0.6628571428571429\n",
      "Best validation accuracy  0.6746987951807228\n",
      "test acc :0.6744186046511628\n",
      "EPOCH  26\n",
      "Train : Loss: 0.1787, Train error: 0.2578, Train acc : 0.6928406466512702\n",
      "Val acc :0.6705882352941177\n",
      "Best validation accuracy  0.6746987951807228\n",
      "test acc :0.7808219178082192\n",
      "EPOCH  27\n",
      "Train : Loss: 0.1755, Train error: 0.2733, Train acc : 0.6728538283062644\n",
      "Val acc :0.6274509803921569\n",
      "Best validation accuracy  0.6746987951807228\n",
      "test acc :0.7259259259259259\n",
      "EPOCH  28\n",
      "Train : Loss: 0.1747, Train error: 0.2674, Train acc : 0.6634146341463415\n",
      "Val acc :0.6829268292682926\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.6829268292682926\n",
      "test acc :0.7971014492753623\n",
      "EPOCH  29\n",
      "Train : Loss: 0.1731, Train error: 0.2616, Train acc : 0.6952595936794582\n",
      "Val acc :0.6582278481012658\n",
      "Best validation accuracy  0.6829268292682926\n",
      "test acc :0.6849315068493151\n",
      "EPOCH  30\n",
      "Train : Loss: 0.1685, Train error: 0.2481, Train acc : 0.7064220183486238\n",
      "Val acc :0.6744186046511628\n",
      "Best validation accuracy  0.6829268292682926\n",
      "test acc :0.6432748538011696\n",
      "EPOCH  31\n",
      "Train : Loss: 0.1654, Train error: 0.2500, Train acc : 0.7061503416856492\n",
      "Val acc :0.650887573964497\n",
      "Best validation accuracy  0.6829268292682926\n",
      "test acc :0.7272727272727274\n",
      "EPOCH  32\n",
      "Train : Loss: 0.1657, Train error: 0.2519, Train acc : 0.7136563876651981\n",
      "Val acc :0.6797385620915034\n",
      "Best validation accuracy  0.6829268292682926\n",
      "test acc :0.7586206896551724\n",
      "EPOCH  33\n",
      "Train : Loss: 0.1682, Train error: 0.2442, Train acc : 0.7200000000000001\n",
      "Val acc :0.6875\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.6875\n",
      "test acc :0.7768595041322314\n",
      "EPOCH  34\n",
      "Train : Loss: 0.1643, Train error: 0.2422, Train acc : 0.7252747252747253\n",
      "Val acc :0.6417910447761195\n",
      "Best validation accuracy  0.6875\n",
      "test acc :0.6355140186915887\n",
      "EPOCH  35\n",
      "Train : Loss: 0.1631, Train error: 0.2422, Train acc : 0.7165532879818595\n",
      "Val acc :0.6829268292682926\n",
      "Best validation accuracy  0.6875\n",
      "test acc :0.7883211678832116\n",
      "EPOCH  36\n",
      "Train : Loss: 0.1585, Train error: 0.2461, Train acc : 0.7196467991169977\n",
      "Val acc :0.691358024691358\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.691358024691358\n",
      "test acc :0.7903225806451614\n",
      "EPOCH  37\n",
      "Train : Loss: 0.1560, Train error: 0.2326, Train acc : 0.7413793103448276\n",
      "Val acc :0.65359477124183\n",
      "Best validation accuracy  0.691358024691358\n",
      "test acc :0.7731092436974789\n",
      "EPOCH  38\n",
      "Train : Loss: 0.1589, Train error: 0.2326, Train acc : 0.7402597402597402\n",
      "Val acc :0.6193548387096774\n",
      "Best validation accuracy  0.691358024691358\n",
      "test acc :0.736\n",
      "EPOCH  39\n",
      "Train : Loss: 0.1573, Train error: 0.2229, Train acc : 0.7438752783964365\n",
      "Val acc :0.6027397260273972\n",
      "Best validation accuracy  0.691358024691358\n",
      "test acc :0.7663551401869159\n",
      "EPOCH  40\n",
      "Train : Loss: 0.1550, Train error: 0.2364, Train acc : 0.7336244541484715\n",
      "Val acc :0.6258503401360546\n",
      "Best validation accuracy  0.691358024691358\n",
      "test acc :0.7289719626168225\n",
      "EPOCH  41\n",
      "Train : Loss: 0.1568, Train error: 0.2112, Train acc : 0.7625272331154686\n",
      "Val acc :0.6573426573426574\n",
      "Best validation accuracy  0.691358024691358\n",
      "test acc :0.6862745098039215\n",
      "EPOCH  42\n",
      "Train : Loss: 0.1572, Train error: 0.2267, Train acc : 0.7462039045553145\n",
      "Val acc :0.6301369863013699\n",
      "Best validation accuracy  0.691358024691358\n",
      "test acc :0.6728971962616822\n",
      "EPOCH  43\n",
      "Train : Loss: 0.1542, Train error: 0.2151, Train acc : 0.750561797752809\n",
      "Val acc :0.65\n",
      "Best validation accuracy  0.691358024691358\n",
      "test acc :0.7419354838709677\n",
      "EPOCH  44\n",
      "Train : Loss: 0.1492, Train error: 0.2229, Train acc : 0.7461368653421634\n",
      "Val acc :0.5467625899280575\n",
      "Best validation accuracy  0.691358024691358\n",
      "test acc :0.631578947368421\n",
      "EPOCH  45\n",
      "Train : Loss: 0.1461, Train error: 0.1977, Train acc : 0.7723214285714285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc :0.5734265734265734\n",
      "Best validation accuracy  0.691358024691358\n",
      "test acc :0.6324786324786326\n",
      "EPOCH  46\n",
      "Train : Loss: 0.1433, Train error: 0.2016, Train acc : 0.7709251101321586\n",
      "Val acc :0.5694444444444444\n",
      "Best validation accuracy  0.691358024691358\n",
      "test acc :0.7567567567567567\n",
      "EPOCH  47\n",
      "Train : Loss: 0.1459, Train error: 0.2171, Train acc : 0.752212389380531\n",
      "Val acc :0.5774647887323943\n",
      "Best validation accuracy  0.691358024691358\n",
      "test acc :0.6262626262626262\n",
      "EPOCH  48\n",
      "Train : Loss: 0.1471, Train error: 0.1996, Train acc : 0.7736263736263737\n",
      "Val acc :0.5844155844155844\n",
      "Best validation accuracy  0.691358024691358\n",
      "test acc :0.7731092436974789\n",
      "EPOCH  49\n",
      "Train : Loss: 0.1429, Train error: 0.1841, Train acc : 0.7884187082405345\n",
      "Val acc :0.5119999999999999\n",
      "Best validation accuracy  0.691358024691358\n",
      "test acc :0.717391304347826\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Attention()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
    "if torch.cuda.is_available():model.cuda()\n",
    "\n",
    "best_model = \"./saved_models/best_model_MIL_raw_cs_nl\"\n",
    "train_acc = []\n",
    "modelname=[]\n",
    "val_acc = []\n",
    "best_acc = 0\n",
    "for epoch in range(0, 50): #28-2021\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    train_error = 0.\n",
    "    y =[]\n",
    "    ypred = []\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        bag_label = label[0]\n",
    "        data, bag_label = data.cuda(), bag_label.cuda()\n",
    "        data, bag_label = Variable(data), Variable(bag_label)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.calculate_objective(data.float(), bag_label.float())\n",
    "        train_loss += loss.item()\n",
    "        error,y_pred = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "        train_error += error\n",
    "        y_pred=y_pred.squeeze(1)\n",
    "        ypred.extend(y_pred.tolist())\n",
    "        y.extend(bag_label.tolist())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    trainacc = f1_score(y,ypred)\n",
    "    train_loss /= len(train_loader)\n",
    "    train_error /= len(train_loader)\n",
    "    print(\"EPOCH \",epoch)\n",
    "    print('Train : Loss: {:.4f}, Train error: {:.4f}, Train acc : {}'.format(train_loss, \n",
    "                                                                                train_error,trainacc))\n",
    "    y =[]\n",
    "    ypred = []\n",
    "    model.eval()\n",
    "    for batch_idx, (data, label) in enumerate(val_loader):\n",
    "        bag_label = label[0]\n",
    "        data, bag_label = data.cuda(), bag_label.cuda()\n",
    "        data, bag_label = Variable(data), Variable(bag_label)\n",
    "        error, y_pred = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "        y_pred=y_pred.squeeze(1)\n",
    "        ypred.extend(y_pred.tolist())\n",
    "        y.extend(bag_label.tolist())\n",
    "    valacc = f1_score(y,ypred)\n",
    "    print('Val acc :{}'.format(valacc))\n",
    "    if (valacc>=best_acc and trainacc>0.65):\n",
    "        print(\"---------State saved---------\")\n",
    "        best_acc = valacc\n",
    "        best_state=model.state_dict()\n",
    "        torch.save(best_state, best_model+'_epoch_'+str(epoch)+\".pth\")\n",
    "        modelname.append(best_model+'_epoch_'+str(epoch)+\".pth\")\n",
    "    print('Best validation accuracy ',best_acc)\n",
    "\n",
    "    y =[]\n",
    "    ypred = []\n",
    "    for batch_idx, (data, label) in enumerate(test_loader):\n",
    "        bag_label = label[0]\n",
    "        data, bag_label = data.cuda(), bag_label.cuda()\n",
    "        data, bag_label = Variable(data), Variable(bag_label)\n",
    "        error, y_pred = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "        y_pred=y_pred.squeeze(1)\n",
    "        ypred.extend(y_pred.tolist())\n",
    "        y.extend(bag_label.tolist())\n",
    "    valacc = f1_score(y,ypred)\n",
    "    print('test acc :{}'.format(valacc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7796610169491526 0.7903225806451614 0.7424242424242424 0.8448275862068966 0.7807471264367816 0.7166666666666667\n",
      "./saved_models/best_model_MIL_raw_cs_nl_epoch_16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7542372881355932 0.7972027972027971 0.6705882352941176 0.9827586206896551 0.7580459770114942 0.5333333333333333\n",
      "./saved_models/best_model_MIL_raw_cs_nl_epoch_21.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6949152542372882 0.7313432835820897 0.6447368421052632 0.8448275862068966 0.6974137931034483 0.55\n",
      "./saved_models/best_model_MIL_raw_cs_nl_epoch_28.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7627118644067796 0.7971014492753623 0.6875 0.9482758620689655 0.7658045977011494 0.5833333333333334\n",
      "./saved_models/best_model_MIL_raw_cs_nl_epoch_33.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7711864406779662 0.7768595041322314 0.746031746031746 0.8103448275862069 0.7718390804597701 0.7333333333333333\n",
      "./saved_models/best_model_MIL_raw_cs_nl_epoch_36.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7796610169491526 0.7903225806451614 0.7424242424242424 0.8448275862068966 0.7807471264367816 0.7166666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "device = torch.device(\"cuda\")\n",
    "model=Attention()\n",
    "# why Mil\n",
    "# why attention mil\n",
    "# why modality specific embedding \n",
    "# why non-local\n",
    "# refere to figures\n",
    "best_state=torch.load(modelname[-1])\n",
    "model.load_state_dict(best_state)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "test_loss = 0.\n",
    "correct = 0\n",
    "total = 0\n",
    "y =[]\n",
    "ypred = []\n",
    "test_error = 0.\n",
    "for batch_idx, (data, label) in enumerate(test_loader):\n",
    "    bag_label = label[0]\n",
    "    instance_labels = label[1]\n",
    "    data, bag_label = data.cuda(), bag_label.cuda()\n",
    "    data, bag_label = Variable(data), Variable(bag_label)\n",
    "    loss = model.calculate_objective(data.float(), bag_label.float())\n",
    "    test_loss += loss.item()\n",
    "    error, predicted_label = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "    test_error += error\n",
    "    predicted_label=predicted_label.squeeze(1)\n",
    "    ypred.extend(predicted_label.tolist())\n",
    "    y.extend(bag_label.tolist())\n",
    "    \n",
    "acc=accuracy_score(y,ypred)\n",
    "# print(y,ypred)\n",
    "tn, fp, fn, tp = confusion_matrix(y,ypred).ravel()\n",
    "f1score=f1_score(y,ypred)\n",
    "precision=precision_score(y,ypred)\n",
    "recall=recall_score(y,ypred)\n",
    "roc=roc_auc_score(y,ypred)\n",
    "specificity=tn/(tn+fp)\n",
    "print(acc,f1score,precision,recall,roc,specificity)\n",
    "\n",
    "for i in modelname:\n",
    "    print(i)\n",
    "    model=Attention()\n",
    "    # best_state=torch.load(\"../best-models/Attention_MIL_best(stress)_F1_91.pth\")\n",
    "    best_state=torch.load(i)\n",
    "    model.load_state_dict(best_state)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y =[]\n",
    "    ypred = []\n",
    "    test_error = 0.\n",
    "    for batch_idx, (data, label) in enumerate(test_loader):\n",
    "        bag_label = label[0]\n",
    "        instance_labels = label[1]\n",
    "        data, bag_label = data.cuda(), bag_label.cuda()\n",
    "        data, bag_label = Variable(data), Variable(bag_label)\n",
    "        loss = model.calculate_objective(data.float(), bag_label.float())\n",
    "        test_loss += loss.item()\n",
    "        error, predicted_label = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "        test_error += error\n",
    "        predicted_label=predicted_label.squeeze(1)\n",
    "        ypred.extend(predicted_label.tolist())\n",
    "        y.extend(bag_label.tolist())\n",
    "\n",
    "    acc=accuracy_score(y,ypred)\n",
    "    # print(y,ypred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y,ypred).ravel()\n",
    "    f1score=f1_score(y,ypred)\n",
    "    precision=precision_score(y,ypred)\n",
    "    recall=recall_score(y,ypred)\n",
    "    roc=roc_auc_score(y,ypred)\n",
    "    specificity=tn/(tn+fp)\n",
    "    print(acc,f1score,precision,recall,roc,specificity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7796610169491526 0.7936507936507937 0.7352941176470589 0.8620689655172413 0.7810344827586206 0.7\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model=Attention()\n",
    "best_state=torch.load(modelname[-1])\n",
    "model.load_state_dict(best_state)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "testdataset = load_data('../Participant_wise_physio_change1/','test')\n",
    "test_loader = data_utils.DataLoader(Stammering(train=\"test\"),worker_init_fn=seed_worker,batch_size=1,shuffle=True)\n",
    "attn_weights=[]\n",
    "test_loss = 0.\n",
    "correct = 0\n",
    "total = 0\n",
    "y =[]\n",
    "ypred = []\n",
    "test_error = 0.\n",
    "for batch_idx, (data, label) in enumerate(test_loader):\n",
    "    bag_label = label[0]\n",
    "    instance_labels = label[1]\n",
    "    data, bag_label = data.cuda(), bag_label.cuda()\n",
    "    data, bag_label = Variable(data), Variable(bag_label)\n",
    "    loss = model.calculate_objective(data.float(), bag_label.float())\n",
    "    test_loss += loss.item()\n",
    "    error, predicted_label = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "    test_error += error\n",
    "    predicted_label=predicted_label.squeeze(1)\n",
    "    ypred.extend(predicted_label.tolist())\n",
    "    y.extend(bag_label.tolist())\n",
    "acc=accuracy_score(y,ypred)\n",
    "tn, fp, fn, tp = confusion_matrix(y,ypred).ravel()\n",
    "f1score=f1_score(y,ypred)\n",
    "precision=precision_score(y,ypred)\n",
    "recall=recall_score(y,ypred)\n",
    "roc=roc_auc_score(y,ypred)\n",
    "specificity=tn/(tn+fp)\n",
    "# print(best_model)\n",
    "print(acc,f1score,precision,recall,roc,specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7796610169491526 0.7868852459016394 0.75 0.8275862068965517 0.7804597701149425 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model=Attention()\n",
    "best_state=torch.load(modelname[-1])\n",
    "model.load_state_dict(best_state)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "testdataset = load_data('../Participant_wise_physio_change2/','test')\n",
    "test_loader = data_utils.DataLoader(Stammering(train=\"test\"),worker_init_fn=seed_worker,batch_size=1,shuffle=True)\n",
    "attn_weights=[]\n",
    "test_loss = 0.\n",
    "correct = 0\n",
    "total = 0\n",
    "y =[]\n",
    "ypred = []\n",
    "test_error = 0.\n",
    "for batch_idx, (data, label) in enumerate(test_loader):\n",
    "    bag_label = label[0]\n",
    "    instance_labels = label[1]\n",
    "    data, bag_label = data.cuda(), bag_label.cuda()\n",
    "    data, bag_label = Variable(data), Variable(bag_label)\n",
    "    loss = model.calculate_objective(data.float(), bag_label.float())\n",
    "\n",
    "    test_loss += loss.item()\n",
    "    error, predicted_label = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "    test_error += error\n",
    "    predicted_label=predicted_label.squeeze(1)\n",
    "    ypred.extend(predicted_label.tolist())\n",
    "    y.extend(bag_label.tolist())\n",
    "acc=accuracy_score(y,ypred)\n",
    "tn, fp, fn, tp = confusion_matrix(y,ypred).ravel()\n",
    "f1score=f1_score(y,ypred)\n",
    "precision=precision_score(y,ypred)\n",
    "recall=recall_score(y,ypred)\n",
    "roc=roc_auc_score(y,ypred)\n",
    "specificity=tn/(tn+fp)\n",
    "# print(best_model)\n",
    "print(acc,f1score,precision,recall,roc,specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./saved_models/best_model_MIL_raw_cs_nl_epoch_36.pth'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelname[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (physio)",
   "language": "python",
   "name": "physio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
