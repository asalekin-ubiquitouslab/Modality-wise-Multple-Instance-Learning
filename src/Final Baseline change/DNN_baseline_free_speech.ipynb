{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pylab\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "seed =2021\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(seed)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, X1, Y1):\n",
    "        self.X1 = X1\n",
    "        self.Y1 = Y1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.X1[index]\n",
    "        y1 = self.Y1[index]\n",
    "        return x, y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    if type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.L = 128\n",
    "        self.D = 64\n",
    "        self.K = 1\n",
    "        self.feature_size = 24\n",
    "        self.shared_layer_size = 512\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(8, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(9728, 1024), #166400\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256, affine=False),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "                               \n",
    "    def forward(self, x):\n",
    "        \n",
    "        Y_prob=self.fc(x)\n",
    "        Y_prob=self.fc2(Y_prob.reshape(Y_prob.size(0),-1))\n",
    "        \n",
    "        return Y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "class CyclicLR(_LRScheduler):\n",
    "    \n",
    "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
    "        assert callable(schedule)\n",
    "        self.schedule = schedule\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(t_max, eta_min=0):\n",
    "    \n",
    "    def scheduler(epoch, base_lr):\n",
    "        t = epoch % t_max\n",
    "        return eta_min + (base_lr - eta_min)*(1 + np.cos(np.pi*t/t_max))/2\n",
    "    \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=np.load(\"../extracted_features/FS-change3/input_features_free_train.npy\")\n",
    "labels_stress_train=np.load(\"../extracted_features/FS-change3/label_free_train.npy\")\n",
    "\n",
    "\n",
    "test_features=np.load(\"../extracted_features/FS-change3/input_features_free_test.npy\")\n",
    "labels_stress_test=np.load(\"../extracted_features/FS-change3/label_free_test.npy\")\n",
    "\n",
    "\n",
    "val_features=np.load(\"../extracted_features/FS-change3/input_features_free_val.npy\")\n",
    "labels_stress_val=np.load(\"../extracted_features/FS-change3/label_free_val.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1121,) [0. 0. 0. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(labels_stress_train.shape,labels_stress_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1121, 19, 8) (1121,)\n",
      "(190, 19, 8) (190,)\n",
      "(199, 19, 8) (199,)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape,labels_stress_train.shape)\n",
    "print(test_features.shape,labels_stress_test.shape)\n",
    "print(val_features.shape,labels_stress_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "train_data = Dataset(train_features, labels_stress_train)\n",
    "test_data=Dataset(test_features,labels_stress_test)\n",
    "val_data=Dataset(val_features,labels_stress_val)\n",
    "train_data_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_data_loader=DataLoader(test_data,shuffle=True,batch_size=batch_size)\n",
    "test_data_loader=DataLoader(val_data,shuffle=True,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for batch in val_data_loader:\n",
    "    print(batch[1].shape)\n",
    "    break\n",
    "print(len(val_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = 24\n",
    "shared_layer_size = 512\n",
    "LR = 0.0001\n",
    "epoch = 10\n",
    "model=Classifier()\n",
    "model.cuda()\n",
    "iterations_per_epoch = len(train_data_loader)\n",
    "model.apply(init_weights)\n",
    "loss_func = nn.BCELoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=LR)\n",
    "sched = CyclicLR(optimizer, cosine(t_max=iterations_per_epoch * 2, eta_min=LR/100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# summary(model.cuda(),(1,19,8))\n",
    "# torch.save(model, \"modelarchitect_final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0\n",
      "Train : Loss: 0.0080, Train acc1 : 0.5905\n",
      "Val : Loss: 0.0122, Val acc1 : 0.3053\n",
      "Best validation accuracy1  0.30526315789473685\n",
      "EPOCH  1\n",
      "Train : Loss: 0.0051, Train acc1 : 0.6735\n",
      "Val : Loss: 0.0105, Val acc1 : 0.3158\n",
      "Best validation accuracy1  0.3157894736842105\n",
      "EPOCH  2\n",
      "Train : Loss: 0.0050, Train acc1 : 0.6850\n",
      "Val : Loss: 0.0105, Val acc1 : 0.4158\n",
      "Best validation accuracy1  0.41578947368421054\n",
      "EPOCH  3\n",
      "Train : Loss: 0.0043, Train acc1 : 0.7490\n",
      "Val : Loss: 0.0105, Val acc1 : 0.3947\n",
      "EPOCH  4\n",
      "Train : Loss: 0.0043, Train acc1 : 0.7452\n",
      "Val : Loss: 0.0127, Val acc1 : 0.3421\n",
      "EPOCH  5\n",
      "Train : Loss: 0.0038, Train acc1 : 0.7811\n",
      "Val : Loss: 0.0115, Val acc1 : 0.3474\n",
      "EPOCH  6\n",
      "Train : Loss: 0.0040, Train acc1 : 0.7727\n",
      "Val : Loss: 0.0106, Val acc1 : 0.4053\n",
      "EPOCH  7\n",
      "Train : Loss: 0.0031, Train acc1 : 0.8124\n",
      "Val : Loss: 0.0116, Val acc1 : 0.3526\n",
      "EPOCH  8\n",
      "Train : Loss: 0.0031, Train acc1 : 0.7986\n",
      "Val : Loss: 0.0152, Val acc1 : 0.3105\n",
      "EPOCH  9\n",
      "Train : Loss: 0.0025, Train acc1 : 0.8276\n",
      "Val : Loss: 0.0120, Val acc1 : 0.3579\n",
      "EPOCH  10\n",
      "Train : Loss: 0.0028, Train acc1 : 0.8268\n",
      "Val : Loss: 0.0112, Val acc1 : 0.4421\n",
      "Best validation accuracy1  0.4421052631578947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "best_model1 = \"./saved_models/best_model_dNN_\"\n",
    "best_acc1 = 0\n",
    "# best_model1 = \"./saved_models/best_model_CNN_node3\"\n",
    "modelname=[]\n",
    "truth=[]\n",
    "preds=[]\n",
    "\n",
    "for it in range(epoch+1):\n",
    "    model.train()\n",
    "    total=len(train_data_loader)*batch_size\n",
    "    train_loss = 0.\n",
    "    for minibatch in train_data_loader:\n",
    "        X, Y1  = minibatch\n",
    "        X=X.cuda()\n",
    "        Y1=Y1.cuda()\n",
    "        output = model(X.float())\n",
    "        output=output.squeeze(1)\n",
    "#         print(output.shape,Y1.shape)\n",
    "        loss = loss_func(output, Y1.float())\n",
    "        Y_hat1 = torch.ge(output, 0.5).float()\n",
    "        train_loss += loss.item()\n",
    "        truth.extend(Y1.tolist())\n",
    "        preds.extend(Y_hat1.tolist())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sched.step()\n",
    "    trainacc1=accuracy_score(truth,preds)\n",
    "    train_loss /= total\n",
    "    print(\"EPOCH \",it)\n",
    "    print('Train : Loss: {:.4f}, Train acc1 : {:.4f}'.format(train_loss,trainacc1))\n",
    "    \n",
    "\n",
    "    val_loss= 0.\n",
    "    truth=[]\n",
    "    preds=[]\n",
    "    total=len(val_data_loader)*batch_size\n",
    "    model.eval()    \n",
    "    for minibatch in val_data_loader:\n",
    "        X_valid, Y1_valid  = minibatch\n",
    "        X_valid=X_valid.cuda()\n",
    "        Y1_valid=Y1_valid.cuda()\n",
    "        output_val = model(X_valid.float())\n",
    "        output_val=output_val.squeeze(1)\n",
    "        loss = loss_func(output_val, Y1_valid.float())\n",
    "        Y_hat1_val = torch.ge(output_val, 0.5).float()\n",
    "        val_loss += loss.item()\n",
    "        truth.extend(Y1_valid.tolist())\n",
    "        preds.extend(Y_hat1_val.tolist())\n",
    "    valacc1=accuracy_score(truth,preds)\n",
    "    val_loss /= total\n",
    "#     if(it%5==0):\n",
    "#         torch.save(model.state_dict(), best_model1+'_'+str(it)+\".pth\")\n",
    "#         modelname.append(best_model1+'_'+str(it)+\".pth\")\n",
    "    print('Val : Loss: {:.4f}, Val acc1 : {:.4f}'.format(val_loss,valacc1))\n",
    "    if valacc1 >= best_acc1:\n",
    "        torch.save(model.state_dict(), best_model1+str(it)+\".pth\")\n",
    "        modelname.append(best_model1+str(it)+\".pth\")\n",
    "        best_acc1 = valacc1\n",
    "        best_state = model.state_dict()\n",
    "        print('Best validation accuracy1 ', best_acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55 0.42 0.50 0.36 0.53 0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "modeltest=Classifier()\n",
    "best_state=torch.load(modelname[-1])\n",
    "modeltest.load_state_dict(best_state)\n",
    "modeltest.cuda()\n",
    "modeltest.eval()\n",
    "truth=[]\n",
    "preds=[]\n",
    "for minibatch in test_data_loader:\n",
    "            X_test, Y1_test  = minibatch\n",
    "            X_test=X_test.cuda()\n",
    "            Y1_test=Y1_test.cuda()\n",
    "            output_test = modeltest(X_test.float())\n",
    "            output_test=output_test.squeeze(1)\n",
    "            prediction = torch.ge(output_test, 0.5).float()\n",
    "            truth.extend(Y1_test.tolist())\n",
    "            preds.extend(prediction.tolist())\n",
    "acc=accuracy_score(truth,preds)\n",
    "# print(truth,preds)\n",
    "tn, fp, fn, tp = confusion_matrix(truth, preds).ravel()\n",
    "f1score=f1_score(truth, preds)\n",
    "precision=precision_score(truth, preds)\n",
    "recall=recall_score(truth,preds)\n",
    "roc=roc_auc_score(truth,preds)\n",
    "specificity=tn/(tn+fp)\n",
    "\n",
    "print('{:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f}'.format(acc,f1score,precision,recall,roc,specificity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.56 0.59 0.51 0.69 0.57 0.46\n",
      "0.39 0.30 0.31 0.29 0.38 0.48\n",
      "0.42 0.24 0.29 0.20 0.40 0.60\n",
      "0.55 0.42 0.50 0.36 0.53 0.71\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(modelname)):\n",
    "    modeltest=Classifier()\n",
    "    best_state=torch.load(modelname[i])\n",
    "    modeltest.load_state_dict(best_state)\n",
    "    modeltest.cuda()\n",
    "    modeltest.eval()\n",
    "    truth=[]\n",
    "    preds=[]\n",
    "    for minibatch in test_data_loader:\n",
    "                X_test, Y1_test  = minibatch\n",
    "                X_test=X_test.cuda()\n",
    "                Y1_test=Y1_test.cuda()\n",
    "                output_test = modeltest(X_test.float())\n",
    "                output_test=output_test.squeeze(1)\n",
    "                prediction = torch.ge(output_test, 0.5).float()\n",
    "                truth.extend(Y1_test.tolist())\n",
    "                preds.extend(prediction.tolist())\n",
    "    acc=accuracy_score(truth,preds)\n",
    "    # print(truth,preds)\n",
    "    tn, fp, fn, tp = confusion_matrix(truth, preds).ravel()\n",
    "    f1score=f1_score(truth, preds)\n",
    "    precision=precision_score(truth, preds)\n",
    "    recall=recall_score(truth,preds)\n",
    "    roc=roc_auc_score(truth,preds)\n",
    "    specificity=tn/(tn+fp)\n",
    "\n",
    "    print('{:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f}'.format(acc,f1score,precision,recall,roc,specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (physio)",
   "language": "python",
   "name": "physio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
