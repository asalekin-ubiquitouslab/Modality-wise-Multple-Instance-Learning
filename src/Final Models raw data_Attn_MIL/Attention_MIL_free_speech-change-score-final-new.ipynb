{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "seed =77\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = 11\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, X1,Y):\n",
    "        self.X1 = X1\n",
    "        self.Y = Y\n",
    "    def __len__(self):        \n",
    "        return len(self.X1)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.X1[index]\n",
    "        y = self.Y[index]\n",
    "        return x,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negetive pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain=np.load(\"../extracted_features/FS-change3/input_features_free_train.npy\")\n",
    "\n",
    "yTrain=np.load(\"../extracted_features/FS-change3/label_free_train.npy\")\n",
    "\n",
    "xTest=np.load(\"../extracted_features/FS-change3/input_features_free_test.npy\")\n",
    "\n",
    "yTest=np.load(\"../extracted_features/FS-change3/label_free_test.npy\")\n",
    "\n",
    "xVal=np.load(\"../extracted_features/FS-change3/input_features_free_val.npy\")\n",
    "\n",
    "yVal=np.load(\"../extracted_features/FS-change3/label_free_val.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1121, 19, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199, 19, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xVal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190, 19, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = xTrain.reshape(len(xTrain),1,19,8)\n",
    "xTest = xTest.reshape(len(xTest),1,19,8)\n",
    "xVal = xVal.reshape(len(xVal),1,19,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1121, 1, 19, 8) (1121,)\n",
      "(190, 1, 19, 8) (190,)\n",
      "(199, 1, 19, 8) (199,)\n"
     ]
    }
   ],
   "source": [
    "print(xTrain.shape,yTrain.shape)\n",
    "print(xTest.shape,yTest.shape)\n",
    "print(xVal.shape,yVal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = Dataset(xTrain,yTrain)\n",
    "testdataset = Dataset(xTest,yTest)\n",
    "valdataset = Dataset(xVal,yVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stammering(data_utils.Dataset):\n",
    "    def __init__(self, target_number=1, mean_bag_length=5, var_bag_length=2, num_bag=150, seed=2021, train=\"train\"):\n",
    "        self.target_number = target_number\n",
    "        self.mean_bag_length = mean_bag_length\n",
    "        self.var_bag_length = var_bag_length\n",
    "        self.num_bag = num_bag\n",
    "        self.train = train\n",
    "        self.r = np.random.RandomState(seed)\n",
    "\n",
    "        if self.train==\"train\":\n",
    "            self.train_bags_list, self.train_labels_list = self._create_bags()\n",
    "        elif self.train==\"val\":\n",
    "            self.val_bags_list, self.val_labels_list = self._create_bags()\n",
    "        else:\n",
    "            self.test_bags_list, self.test_labels_list = self._create_bags()\n",
    "\n",
    "    def _create_bags(self):\n",
    "        if self.train==\"train\":\n",
    "            print(\"train\")\n",
    "            loader = data_utils.DataLoader(traindataset,\n",
    "                                           batch_size=1,\n",
    "                                           shuffle=True)\n",
    "        elif self.train==\"val\":\n",
    "            print(\"val\")\n",
    "            loader = data_utils.DataLoader(valdataset,\n",
    "                                           batch_size=1,\n",
    "                                           shuffle=True)\n",
    "        else:\n",
    "            loader = data_utils.DataLoader(testdataset,\n",
    "                                           batch_size=1,\n",
    "                                           shuffle=True)\n",
    "            \n",
    "        bags_list = []\n",
    "        labels_list = []\n",
    "        for (batch_data, batch_labels) in loader:\n",
    "\n",
    "            bags_list.append(batch_data.reshape(19,1,8))\n",
    "            temp = torch.as_tensor(np.array([batch_labels for x in range(19)]))\n",
    "            labels_list.append(temp)\n",
    "            \n",
    "               \n",
    "\n",
    "        return bags_list, labels_list\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train==\"train\":\n",
    "            return len(self.train_labels_list)\n",
    "        elif self.train==\"val\":\n",
    "            return len(self.val_labels_list)\n",
    "        else:\n",
    "            return len(self.test_labels_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train==\"train\":\n",
    "            bag = self.train_bags_list[index]\n",
    "            label = [max(self.train_labels_list[index]), self.train_labels_list[index]]\n",
    "        elif self.train==\"val\":\n",
    "            bag = self.val_bags_list[index]\n",
    "            label = [max(self.val_labels_list[index]), self.val_labels_list[index]]\n",
    "        else:\n",
    "            bag = self.test_bags_list[index]\n",
    "            label = [max(self.test_labels_list[index]), self.test_labels_list[index]]\n",
    "\n",
    "        return bag, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "val\n"
     ]
    }
   ],
   "source": [
    "train_loader = data_utils.DataLoader(Stammering(train=\"train\"),num_workers=0,worker_init_fn=seed_worker,batch_size=1,shuffle=True)\n",
    "test_loader = data_utils.DataLoader(Stammering(train=\"val\"),num_workers=0,worker_init_fn=seed_worker,batch_size=1,shuffle=True)\n",
    "val_loader = data_utils.DataLoader(Stammering(train=\"test\"),num_workers=0,worker_init_fn=seed_worker,batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    if type(m) == nn.Conv1d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "        \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.L = 512\n",
    "        self.D = 128\n",
    "        self.K = 1\n",
    "\n",
    "        self.feature_extractor_part1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 32, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(6, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.feature_extractor_part2 = nn.Sequential(\n",
    "            nn.BatchNorm1d(512, affine=False),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024,self.L),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.L, self.D),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.D, self.K)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "\n",
    "            nn.Linear(self.L*self.K, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.squeeze(0)\n",
    "\n",
    "        H = self.feature_extractor_part1(x)\n",
    "        \n",
    "        H = H.view(H.size(0), -1)\n",
    "\n",
    "        H = self.feature_extractor_part2(H)  \n",
    "\n",
    "        A = self.attention(H)  \n",
    "\n",
    "        A = torch.transpose(A, 1, 0) \n",
    "\n",
    "        A = F.softmax(A, dim=1)  \n",
    "\n",
    "        M = torch.mm(A, H)  \n",
    "\n",
    "        Y_prob = self.classifier(M)\n",
    "        Y_hat = torch.ge(Y_prob, 0.5).float()\n",
    "\n",
    "        return Y_prob\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # AUXILIARY METHODS\n",
    "    def calculate_classification_error(self, X, Y):\n",
    "        Y = Y.float()\n",
    "        Y_prob= self.forward(X)\n",
    "        Y_hat = torch.ge(Y_prob, 0.5).float()\n",
    "        error = 1. - Y_hat.eq(Y).cpu().float().mean().item()\n",
    "\n",
    "        return error, Y_hat\n",
    "\n",
    "    def calculate_objective(self, X, Y):\n",
    "        Y = Y.float()\n",
    "        Y_prob = self.forward(X)\n",
    "        Y_prob = torch.clamp(Y_prob, min=1e-5, max=1. - 1e-5)\n",
    "        neg_log_likelihood = -1. * (Y * torch.log(Y_prob) + (1. - Y) * torch.log(1. - Y_prob))  # negative log bernoulli\n",
    "\n",
    "        return neg_log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# model=Attention()\n",
    "# summary(model.cuda(),(1,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0\n",
      "Train : Loss: 0.6780, Train error: 0.4389, Train f1 : 0.5611061552185549\n",
      "Val : Loss: 0.7318, val error: 0.6158, Val f1 :0.38421052631578945\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.38421052631578945\n",
      "EPOCH  1\n",
      "Train : Loss: 0.6341, Train error: 0.3782, Train f1 : 0.6217662801070473\n",
      "Val : Loss: 0.7542, val error: 0.5684, Val f1 :0.43157894736842106\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.43157894736842106\n",
      "EPOCH  2\n",
      "Train : Loss: 0.5982, Train error: 0.3238, Train f1 : 0.6761819803746655\n",
      "Val : Loss: 0.8564, val error: 0.5053, Val f1 :0.49473684210526314\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.49473684210526314\n",
      "EPOCH  3\n",
      "Train : Loss: 0.5589, Train error: 0.2890, Train f1 : 0.7109723461195361\n",
      "Val : Loss: 0.8440, val error: 0.5053, Val f1 :0.49473684210526314\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.49473684210526314\n",
      "EPOCH  4\n",
      "Train : Loss: 0.5433, Train error: 0.2881, Train f1 : 0.711864406779661\n",
      "Val : Loss: 0.9460, val error: 0.5421, Val f1 :0.45789473684210524\n",
      "Best validation accuracy  0.49473684210526314\n",
      "EPOCH  5\n",
      "Train : Loss: 0.5282, Train error: 0.2748, Train f1 : 0.7252453166815344\n",
      "Val : Loss: 0.8973, val error: 0.5263, Val f1 :0.47368421052631576\n",
      "Best validation accuracy  0.49473684210526314\n",
      "EPOCH  6\n",
      "Train : Loss: 0.5103, Train error: 0.2551, Train f1 : 0.7448706512042819\n",
      "Val : Loss: 0.7690, val error: 0.5158, Val f1 :0.4842105263157895\n",
      "Best validation accuracy  0.49473684210526314\n",
      "EPOCH  7\n",
      "Train : Loss: 0.4928, Train error: 0.2346, Train f1 : 0.7653880463871543\n",
      "Val : Loss: 1.3544, val error: 0.4632, Val f1 :0.5368421052631579\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.5368421052631579\n",
      "EPOCH  8\n",
      "Train : Loss: 0.5022, Train error: 0.2649, Train f1 : 0.7350579839429081\n",
      "Val : Loss: 1.9438, val error: 0.4789, Val f1 :0.5210526315789473\n",
      "Best validation accuracy  0.5368421052631579\n",
      "EPOCH  9\n",
      "Train : Loss: 0.4967, Train error: 0.2551, Train f1 : 0.7448706512042819\n",
      "Val : Loss: 0.9693, val error: 0.4684, Val f1 :0.531578947368421\n",
      "Best validation accuracy  0.5368421052631579\n",
      "EPOCH  10\n",
      "Train : Loss: 0.4888, Train error: 0.2525, Train f1 : 0.7475468331846565\n",
      "Val : Loss: 0.7573, val error: 0.4474, Val f1 :0.5526315789473685\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.5526315789473685\n",
      "EPOCH  11\n",
      "Train : Loss: 0.4839, Train error: 0.2516, Train f1 : 0.7484388938447815\n",
      "Val : Loss: 0.8244, val error: 0.4474, Val f1 :0.5526315789473685\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.5526315789473685\n",
      "EPOCH  12\n",
      "Train : Loss: 0.4643, Train error: 0.2186, Train f1 : 0.7814451382694023\n",
      "Val : Loss: 1.1255, val error: 0.5421, Val f1 :0.45789473684210524\n",
      "Best validation accuracy  0.5526315789473685\n",
      "EPOCH  13\n",
      "Train : Loss: 0.4557, Train error: 0.2230, Train f1 : 0.7769848349687779\n",
      "Val : Loss: 0.9846, val error: 0.4421, Val f1 :0.5578947368421052\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.5578947368421052\n",
      "EPOCH  14\n",
      "Train : Loss: 0.4407, Train error: 0.2177, Train f1 : 0.7823371989295272\n",
      "Val : Loss: 1.1149, val error: 0.4158, Val f1 :0.5842105263157895\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.5842105263157895\n",
      "EPOCH  15\n",
      "Train : Loss: 0.4215, Train error: 0.1945, Train f1 : 0.8055307760927743\n",
      "Val : Loss: 1.2120, val error: 0.4579, Val f1 :0.5421052631578948\n",
      "Best validation accuracy  0.5842105263157895\n",
      "EPOCH  16\n",
      "Train : Loss: 0.4457, Train error: 0.2025, Train f1 : 0.7975022301516503\n",
      "Val : Loss: 1.1444, val error: 0.4421, Val f1 :0.5578947368421052\n",
      "Best validation accuracy  0.5842105263157895\n",
      "EPOCH  17\n",
      "Train : Loss: 0.4200, Train error: 0.2079, Train f1 : 0.792149866190901\n",
      "Val : Loss: 1.5135, val error: 0.4737, Val f1 :0.5263157894736842\n",
      "Best validation accuracy  0.5842105263157895\n",
      "EPOCH  18\n",
      "Train : Loss: 0.4102, Train error: 0.1954, Train f1 : 0.8046387154326494\n",
      "Val : Loss: 1.0699, val error: 0.4053, Val f1 :0.5947368421052631\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.5947368421052631\n",
      "EPOCH  19\n",
      "Train : Loss: 0.4001, Train error: 0.1954, Train f1 : 0.8046387154326494\n",
      "Val : Loss: 1.1665, val error: 0.4579, Val f1 :0.5421052631578948\n",
      "Best validation accuracy  0.5947368421052631\n",
      "EPOCH  20\n",
      "Train : Loss: 0.3810, Train error: 0.1740, Train f1 : 0.8260481712756468\n",
      "Val : Loss: 1.0775, val error: 0.2947, Val f1 :0.7052631578947368\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  21\n",
      "Train : Loss: 0.3668, Train error: 0.1784, Train f1 : 0.8215878679750223\n",
      "Val : Loss: 1.4084, val error: 0.5421, Val f1 :0.45789473684210524\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  22\n",
      "Train : Loss: 0.3555, Train error: 0.1624, Train f1 : 0.8376449598572703\n",
      "Val : Loss: 1.5766, val error: 0.4895, Val f1 :0.5105263157894737\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  23\n",
      "Train : Loss: 0.3459, Train error: 0.1579, Train f1 : 0.8421052631578947\n",
      "Val : Loss: 2.2085, val error: 0.4842, Val f1 :0.5157894736842106\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  24\n",
      "Train : Loss: 0.3304, Train error: 0.1463, Train f1 : 0.8537020517395183\n",
      "Val : Loss: 2.2744, val error: 0.4105, Val f1 :0.5894736842105263\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  25\n",
      "Train : Loss: 0.3148, Train error: 0.1463, Train f1 : 0.8537020517395183\n",
      "Val : Loss: 1.6904, val error: 0.5105, Val f1 :0.48947368421052634\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  26\n",
      "Train : Loss: 0.3245, Train error: 0.1490, Train f1 : 0.8510258697591436\n",
      "Val : Loss: 1.9218, val error: 0.4684, Val f1 :0.531578947368421\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  27\n",
      "Train : Loss: 0.3033, Train error: 0.1392, Train f1 : 0.8608385370205174\n",
      "Val : Loss: 1.5815, val error: 0.3789, Val f1 :0.6210526315789474\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  28\n",
      "Train : Loss: 0.2954, Train error: 0.1311, Train f1 : 0.8688670829616414\n",
      "Val : Loss: 2.1159, val error: 0.3895, Val f1 :0.6105263157894737\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  29\n",
      "Train : Loss: 0.2697, Train error: 0.1160, Train f1 : 0.8840321141837645\n",
      "Val : Loss: 2.1779, val error: 0.4105, Val f1 :0.5894736842105263\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  30\n",
      "Train : Loss: 0.2742, Train error: 0.1276, Train f1 : 0.872435325602141\n",
      "Val : Loss: 1.7145, val error: 0.3684, Val f1 :0.631578947368421\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  31\n",
      "Train : Loss: 0.2964, Train error: 0.1293, Train f1 : 0.8706512042818911\n",
      "Val : Loss: 1.5583, val error: 0.4000, Val f1 :0.6\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  32\n",
      "Train : Loss: 0.2551, Train error: 0.1195, Train f1 : 0.8804638715432649\n",
      "Val : Loss: 1.0116, val error: 0.3474, Val f1 :0.6526315789473685\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  33\n",
      "Train : Loss: 0.2495, Train error: 0.1115, Train f1 : 0.8884924174843889\n",
      "Val : Loss: 2.1485, val error: 0.4421, Val f1 :0.5578947368421052\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  34\n",
      "Train : Loss: 0.2419, Train error: 0.1008, Train f1 : 0.8991971454058876\n",
      "Val : Loss: 1.9906, val error: 0.4211, Val f1 :0.5789473684210527\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  35\n",
      "Train : Loss: 0.2069, Train error: 0.0910, Train f1 : 0.9090098126672613\n",
      "Val : Loss: 2.3971, val error: 0.3789, Val f1 :0.6210526315789474\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  36\n",
      "Train : Loss: 0.2104, Train error: 0.0785, Train f1 : 0.9214986619090099\n",
      "Val : Loss: 2.0626, val error: 0.3947, Val f1 :0.6052631578947368\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  37\n",
      "Train : Loss: 0.1865, Train error: 0.0776, Train f1 : 0.9223907225691347\n",
      "Val : Loss: 3.0108, val error: 0.4000, Val f1 :0.6\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  38\n",
      "Train : Loss: 0.1719, Train error: 0.0696, Train f1 : 0.9304192685102587\n",
      "Val : Loss: 2.4543, val error: 0.3895, Val f1 :0.6105263157894737\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  39\n",
      "Train : Loss: 0.1814, Train error: 0.0687, Train f1 : 0.9313113291703836\n",
      "Val : Loss: 3.2357, val error: 0.4158, Val f1 :0.5842105263157895\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  40\n",
      "Train : Loss: 0.1822, Train error: 0.0731, Train f1 : 0.9268510258697591\n",
      "Val : Loss: 2.0920, val error: 0.3632, Val f1 :0.6368421052631579\n",
      "Best validation accuracy  0.7052631578947368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  41\n",
      "Train : Loss: 0.1872, Train error: 0.0785, Train f1 : 0.9214986619090099\n",
      "Val : Loss: 1.5742, val error: 0.3474, Val f1 :0.6526315789473685\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  42\n",
      "Train : Loss: 0.1346, Train error: 0.0491, Train f1 : 0.9509366636931311\n",
      "Val : Loss: 2.2045, val error: 0.3737, Val f1 :0.6263157894736842\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  43\n",
      "Train : Loss: 0.1725, Train error: 0.0758, Train f1 : 0.9241748438893844\n",
      "Val : Loss: 2.1079, val error: 0.4474, Val f1 :0.5526315789473685\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  44\n",
      "Train : Loss: 0.1726, Train error: 0.0660, Train f1 : 0.9339875111507583\n",
      "Val : Loss: 2.1460, val error: 0.4000, Val f1 :0.6\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  45\n",
      "Train : Loss: 0.1255, Train error: 0.0491, Train f1 : 0.9509366636931311\n",
      "Val : Loss: 2.4455, val error: 0.3421, Val f1 :0.6578947368421053\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  46\n",
      "Train : Loss: 0.1400, Train error: 0.0580, Train f1 : 0.9420160570918823\n",
      "Val : Loss: 2.3624, val error: 0.4053, Val f1 :0.5947368421052631\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  47\n",
      "Train : Loss: 0.1307, Train error: 0.0544, Train f1 : 0.9455842997323818\n",
      "Val : Loss: 2.3877, val error: 0.4421, Val f1 :0.5578947368421052\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  48\n",
      "Train : Loss: 0.1506, Train error: 0.0651, Train f1 : 0.9348795718108831\n",
      "Val : Loss: 3.3450, val error: 0.4579, Val f1 :0.5421052631578948\n",
      "Best validation accuracy  0.7052631578947368\n",
      "EPOCH  49\n",
      "Train : Loss: 0.1406, Train error: 0.0482, Train f1 : 0.951828724353256\n",
      "Val : Loss: 2.3713, val error: 0.4105, Val f1 :0.5894736842105263\n",
      "Best validation accuracy  0.7052631578947368\n"
     ]
    }
   ],
   "source": [
    "LR = 1e-4\n",
    "model=Attention()\n",
    "if torch.cuda.is_available():model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR, betas=(0.9, 0.999))\n",
    "\n",
    "best_model = \"./saved_models/best_model_Attention-mil-fs-grp3_change\"\n",
    "train_acc = []\n",
    "modelname=[]\n",
    "val_acc = []\n",
    "best_acc = 0\n",
    "for epoch in range(0, 50): #12345-24,\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    train_error = 0.\n",
    "    y =[]\n",
    "    ypred = []\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        bag_label = label[0]\n",
    "        data, bag_label = data.cuda(), bag_label.cuda()\n",
    "        data, bag_label = Variable(data), Variable(bag_label)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.calculate_objective(data.float(), bag_label.float())\n",
    "        train_loss += loss.data[0]\n",
    "        error,y_pred = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "        train_error += error\n",
    "        y_pred=y_pred.squeeze(1)\n",
    "        ypred.extend(y_pred.tolist())\n",
    "        y.extend(bag_label.tolist())\n",
    "        loss.mean().backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    \n",
    "    trainacc = accuracy_score(y,ypred)\n",
    "    train_loss /= len(train_loader)\n",
    "    train_error /= len(train_loader)\n",
    "    print(\"EPOCH \",epoch)\n",
    "    print('Train : Loss: {:.4f}, Train error: {:.4f}, Train f1 : {}'.format(train_loss.cpu().numpy()[0], \n",
    "                                                                                train_error,trainacc))\n",
    "    y =[]\n",
    "    ypred = []\n",
    "    val_error=0.\n",
    "    val_loss= 0.\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, label) in enumerate(val_loader):\n",
    "            bag_label = label[0]\n",
    "            data, bag_label = data.cuda(), bag_label.cuda()\n",
    "            data, bag_label = Variable(data), Variable(bag_label)\n",
    "            loss = model.calculate_objective(data.float(), bag_label.float())\n",
    "            val_loss += loss.data[0]\n",
    "            error, y_pred = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "            val_error += error\n",
    "            y_pred=y_pred.squeeze(1)\n",
    "            ypred.extend(y_pred.tolist())\n",
    "            y.extend(bag_label.tolist())\n",
    "        valacc = accuracy_score(y,ypred)\n",
    "        val_loss /= len(val_loader)\n",
    "        val_error /= len(val_loader)\n",
    "        print('Val : Loss: {:.4f}, val error: {:.4f}, Val f1 :{}'.format(val_loss.cpu().numpy()[0], val_error,valacc))\n",
    "        if valacc>=best_acc:\n",
    "            print(\"---------State saved---------\")\n",
    "            best_acc = valacc\n",
    "            best_state=model.state_dict()\n",
    "            torch.save(best_state, best_model+'_epoch_'+str(epoch)+\".pth\")\n",
    "            modelname.append(best_model+'_epoch_'+str(epoch)+\".pth\")\n",
    "        print('Best validation accuracy ',best_acc)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7638190954773869 0.7374301675977653 0.7415730337078652 0.7333333333333333 0.7611620795107034 0.7889908256880734\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model=Attention()\n",
    "# best_state=torch.load(\"../best-models/Attention_MIL_best_free_speech_F1_73.pth\")\n",
    "best_state=torch.load(modelname[-1])\n",
    "model.load_state_dict(best_state)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "test_loss = 0.\n",
    "correct = 0\n",
    "total = 0\n",
    "y =[]\n",
    "ypred = []\n",
    "ypred1=[]\n",
    "test_error = 0.\n",
    "for batch_idx, (data, label) in enumerate(test_loader):\n",
    "    bag_label = label[0]\n",
    "    instance_labels = label[1]\n",
    "    data, bag_label = data.cuda(), bag_label.cuda()\n",
    "    data, bag_label = Variable(data), Variable(bag_label)\n",
    "    y_pred = model(data.float())\n",
    "    error, predicted_label = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "    test_error += error\n",
    "    predicted_label=predicted_label.squeeze(1)\n",
    "    y_pred=y_pred.squeeze(1)\n",
    "    ypred.extend(predicted_label.tolist())\n",
    "    ypred1.extend(y_pred.tolist())\n",
    "    y.extend(bag_label.tolist())\n",
    "    \n",
    "acc=accuracy_score(y,ypred)\n",
    "# print(y,ypred)\n",
    "tn, fp, fn, tp = confusion_matrix(y,ypred).ravel()\n",
    "f1score=f1_score(y,ypred)\n",
    "precision=precision_score(y,ypred)\n",
    "recall=recall_score(y,ypred)\n",
    "roc=roc_auc_score(y,ypred)\n",
    "specificity=tn/(tn+fp)\n",
    "print(acc,f1score,precision,recall,roc,specificity)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49748743718592964 0.626865671641791 0.47191011235955055 0.9333333333333333 0.5354740061162079 0.13761467889908258\n",
      "0.5879396984924623 0.6434782608695652 0.5285714285714286 0.8222222222222222 0.6083588175331295 0.3944954128440367\n",
      "0.6532663316582915 0.6567164179104478 0.5945945945945946 0.7333333333333333 0.6602446483180429 0.5871559633027523\n",
      "0.5829145728643216 0.29059829059829057 0.6296296296296297 0.18888888888888888 0.548572884811417 0.908256880733945\n",
      "0.4824120603015075 0.5960784313725491 0.46060606060606063 0.8444444444444444 0.5139653414882772 0.1834862385321101\n",
      "0.457286432160804 0.2894736842105263 0.3548387096774194 0.24444444444444444 0.43873598369011213 0.6330275229357798\n",
      "0.5226130653266332 0.5128205128205129 0.47619047619047616 0.5555555555555556 0.5254841997961264 0.4954128440366973\n",
      "0.5326633165829145 0.42944785276073616 0.4794520547945205 0.3888888888888889 0.5201325178389399 0.6513761467889908\n",
      "0.5376884422110553 0.5964912280701755 0.4927536231884058 0.7555555555555555 0.556676860346585 0.3577981651376147\n",
      "0.6331658291457286 0.5921787709497207 0.5955056179775281 0.5888888888888889 0.6293068297655453 0.6697247706422018\n",
      "0.7638190954773869 0.7374301675977653 0.7415730337078652 0.7333333333333333 0.7611620795107034 0.7889908256880734\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(modelname)):\n",
    "#     device = torch.device(\"cuda\")\n",
    "#     model=Attention()\n",
    "#     # best_state=torch.load(\"../best-models/Attention_MIL_best_free_speech_F1_73.pth\")\n",
    "#     best_state=torch.load(modelname[i])\n",
    "#     model.load_state_dict(best_state)\n",
    "#     model.to(device)\n",
    "#     model.eval()\n",
    "#     test_loss = 0.\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     y =[]\n",
    "#     ypred = []\n",
    "#     ypred1=[]\n",
    "#     test_error = 0.\n",
    "#     for batch_idx, (data, label) in enumerate(test_loader):\n",
    "#         bag_label = label[0]\n",
    "#         instance_labels = label[1]\n",
    "#         data, bag_label = data.cuda(), bag_label.cuda()\n",
    "#         data, bag_label = Variable(data), Variable(bag_label)\n",
    "#         y_pred = model(data.float())\n",
    "#         error, predicted_label = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "#         test_error += error\n",
    "#         predicted_label=predicted_label.squeeze(1)\n",
    "#         y_pred=y_pred.squeeze(1)\n",
    "#         ypred.extend(predicted_label.tolist())\n",
    "#         ypred1.extend(y_pred.tolist())\n",
    "#         y.extend(bag_label.tolist())\n",
    "\n",
    "#     acc=accuracy_score(y,ypred)\n",
    "#     # print(y,ypred)\n",
    "#     tn, fp, fn, tp = confusion_matrix(y,ypred).ravel()\n",
    "#     f1score=f1_score(y,ypred)\n",
    "#     precision=precision_score(y,ypred)\n",
    "#     recall=recall_score(y,ypred)\n",
    "#     roc=roc_auc_score(y,ypred)\n",
    "#     specificity=tn/(tn+fp)\n",
    "#     print(acc,f1score,precision,recall,roc,specificity)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (physio)",
   "language": "python",
   "name": "physio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
