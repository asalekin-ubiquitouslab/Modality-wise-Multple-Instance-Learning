{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#5375-40\n",
    "\n",
    "seed =776\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = 11\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, X1,Y):\n",
    "        self.X1 = X1\n",
    "        self.Y = Y\n",
    "    def __len__(self):        \n",
    "        return len(self.X1)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.X1[index]\n",
    "        y = self.Y[index]\n",
    "        return x,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negetive pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain=np.load(\"../extracted_features/FS/input_features_free_train.npy\")\n",
    "\n",
    "yTrain=np.load(\"../extracted_features/FS/label_free_train.npy\")\n",
    "\n",
    "xTest=np.load(\"../extracted_features/FS/input_features_free_test.npy\")\n",
    "\n",
    "yTest=np.load(\"../extracted_features/FS/label_free_test.npy\")\n",
    "\n",
    "xVal=np.load(\"../extracted_features/FS/input_features_free_val.npy\")\n",
    "\n",
    "yVal=np.load(\"../extracted_features/FS/label_free_val.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1121, 19, 24)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199, 19, 24)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xVal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190, 19, 24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = xTrain.reshape(len(xTrain),1,19,24)\n",
    "xTest = xTest.reshape(len(xTest),1,19,24)\n",
    "xVal = xVal.reshape(len(xVal),1,19,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1121, 1, 19, 24) (1121,)\n",
      "(190, 1, 19, 24) (190,)\n",
      "(199, 1, 19, 24) (199,)\n"
     ]
    }
   ],
   "source": [
    "print(xTrain.shape,yTrain.shape)\n",
    "print(xTest.shape,yTest.shape)\n",
    "print(xVal.shape,yVal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = Dataset(xTrain,yTrain)\n",
    "testdataset = Dataset(xTest,yTest)\n",
    "valdataset = Dataset(xVal,yVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stammering(data_utils.Dataset):\n",
    "    def __init__(self, target_number=1, mean_bag_length=5, var_bag_length=2, num_bag=150, seed=2021, train=\"train\"):\n",
    "        self.target_number = target_number\n",
    "        self.mean_bag_length = mean_bag_length\n",
    "        self.var_bag_length = var_bag_length\n",
    "        self.num_bag = num_bag\n",
    "        self.train = train\n",
    "        self.r = np.random.RandomState(seed)\n",
    "\n",
    "        if self.train==\"train\":\n",
    "            self.train_bags_list, self.train_labels_list = self._create_bags()\n",
    "        elif self.train==\"val\":\n",
    "            self.val_bags_list, self.val_labels_list = self._create_bags()\n",
    "        else:\n",
    "            self.test_bags_list, self.test_labels_list = self._create_bags()\n",
    "\n",
    "    def _create_bags(self):\n",
    "        if self.train==\"train\":\n",
    "            print(\"train\")\n",
    "            loader = data_utils.DataLoader(traindataset,\n",
    "                                           batch_size=1,\n",
    "                                           shuffle=True)\n",
    "        elif self.train==\"val\":\n",
    "            print(\"val\")\n",
    "            loader = data_utils.DataLoader(valdataset,\n",
    "                                           batch_size=1,\n",
    "                                           shuffle=True)\n",
    "        else:\n",
    "            loader = data_utils.DataLoader(testdataset,\n",
    "                                           batch_size=1,\n",
    "                                           shuffle=True)\n",
    "            \n",
    "        bags_list = []\n",
    "        labels_list = []\n",
    "        for (batch_data, batch_labels) in loader:\n",
    "\n",
    "            bags_list.append(batch_data.reshape(19,1,24))\n",
    "            temp = torch.as_tensor(np.array([batch_labels for x in range(19)]))\n",
    "            labels_list.append(temp)\n",
    "            \n",
    "               \n",
    "\n",
    "        return bags_list, labels_list\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train==\"train\":\n",
    "            return len(self.train_labels_list)\n",
    "        elif self.train==\"val\":\n",
    "            return len(self.val_labels_list)\n",
    "        else:\n",
    "            return len(self.test_labels_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train==\"train\":\n",
    "            bag = self.train_bags_list[index]\n",
    "            label = [max(self.train_labels_list[index]), self.train_labels_list[index]]\n",
    "        elif self.train==\"val\":\n",
    "            bag = self.val_bags_list[index]\n",
    "            label = [max(self.val_labels_list[index]), self.val_labels_list[index]]\n",
    "        else:\n",
    "            bag = self.test_bags_list[index]\n",
    "            label = [max(self.test_labels_list[index]), self.test_labels_list[index]]\n",
    "\n",
    "        return bag, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "val\n"
     ]
    }
   ],
   "source": [
    "train_loader = data_utils.DataLoader(Stammering(train=\"train\"),num_workers=0,worker_init_fn=seed_worker,batch_size=1,shuffle=True)\n",
    "test_loader = data_utils.DataLoader(Stammering(train=\"val\"),num_workers=0,worker_init_fn=seed_worker,batch_size=1,shuffle=True)\n",
    "val_loader = data_utils.DataLoader(Stammering(train=\"test\"),num_workers=0,worker_init_fn=seed_worker,batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    if type(m) == nn.Conv1d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "        \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.L = 128\n",
    "        self.D = 64\n",
    "        self.K = 1\n",
    "\n",
    "        self.feature_extractor_part1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 256, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 512, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(512, 128, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 32, kernel_size=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.feature_extractor_part2 = nn.Sequential(\n",
    "            nn.BatchNorm1d(640, affine=False),\n",
    "            nn.Linear(640, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,self.L),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.L, self.D),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.D, self.K)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "\n",
    "            nn.Linear(self.L*self.K, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.squeeze(0)\n",
    "\n",
    "        H = self.feature_extractor_part1(x)\n",
    "        \n",
    "        H = H.view(H.size(0), -1)\n",
    "\n",
    "        H = self.feature_extractor_part2(H)  \n",
    "\n",
    "        A = self.attention(H)\n",
    "\n",
    "        A = torch.transpose(A, 1, 0) \n",
    "\n",
    "        A = F.softmax(A, dim=1)  \n",
    "\n",
    "        M = torch.mm(A, H)  \n",
    "\n",
    "        Y_prob = self.classifier(M)\n",
    "        Y_hat = torch.ge(Y_prob, 0.5).float()\n",
    "\n",
    "        return Y_prob, Y_hat, A\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # AUXILIARY METHODS\n",
    "    def calculate_classification_error(self, X, Y):\n",
    "        Y = Y.float()\n",
    "        _, Y_hat, _ = self.forward(X)\n",
    "        error = 1. - Y_hat.eq(Y).cpu().float().mean().item()\n",
    "\n",
    "        return error, Y_hat\n",
    "\n",
    "    def calculate_objective(self, X, Y):\n",
    "        Y = Y.float()\n",
    "        Y_prob, _, A = self.forward(X)\n",
    "        Y_prob = torch.clamp(Y_prob, min=1e-5, max=1. - 1e-5)\n",
    "        neg_log_likelihood = -1. * (Y * torch.log(Y_prob) + (1. - Y) * torch.log(1. - Y_prob))  # negative log bernoulli\n",
    "\n",
    "        return neg_log_likelihood, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# model=Attention()\n",
    "# summary=summary(model.cuda(),(1,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0\n",
      "Train : Loss: 0.6887, Train error: 0.4817, Train f1 : 0.5182872435325602\n",
      "Val : Loss: 2.1729, val error: 0.4579, Val f1 :0.5421052631578948\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.5421052631578948\n",
      "EPOCH  1\n",
      "Train : Loss: 0.6497, Train error: 0.4326, Train f1 : 0.567350579839429\n",
      "Val : Loss: 1.9664, val error: 0.4158, Val f1 :0.5842105263157895\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.5842105263157895\n",
      "EPOCH  2\n",
      "Train : Loss: 0.6318, Train error: 0.4273, Train f1 : 0.5727029438001784\n",
      "Val : Loss: 3.3035, val error: 0.5368, Val f1 :0.4631578947368421\n",
      "Best validation accuracy  0.5842105263157895\n",
      "EPOCH  3\n",
      "Train : Loss: 0.6256, Train error: 0.4005, Train f1 : 0.5994647636039251\n",
      "Val : Loss: 2.0707, val error: 0.4947, Val f1 :0.5052631578947369\n",
      "Best validation accuracy  0.5842105263157895\n",
      "EPOCH  4\n",
      "Train : Loss: 0.6181, Train error: 0.3996, Train f1 : 0.6003568242640499\n",
      "Val : Loss: 3.0714, val error: 0.4421, Val f1 :0.5578947368421052\n",
      "Best validation accuracy  0.5842105263157895\n",
      "EPOCH  5\n",
      "Train : Loss: 0.6158, Train error: 0.4032, Train f1 : 0.5967885816235504\n",
      "Val : Loss: 4.0677, val error: 0.5526, Val f1 :0.4473684210526316\n",
      "Best validation accuracy  0.5842105263157895\n",
      "EPOCH  6\n",
      "Train : Loss: 0.6094, Train error: 0.3809, Train f1 : 0.6190900981266726\n",
      "Val : Loss: 2.8567, val error: 0.4263, Val f1 :0.5736842105263158\n",
      "Best validation accuracy  0.5842105263157895\n",
      "EPOCH  7\n",
      "Train : Loss: 0.6021, Train error: 0.3666, Train f1 : 0.6333630686886709\n",
      "Val : Loss: 4.0974, val error: 0.4947, Val f1 :0.5052631578947369\n",
      "Best validation accuracy  0.5842105263157895\n",
      "EPOCH  8\n",
      "Train : Loss: 0.5976, Train error: 0.3640, Train f1 : 0.6360392506690455\n",
      "Val : Loss: 3.2067, val error: 0.4158, Val f1 :0.5842105263157895\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.5842105263157895\n",
      "EPOCH  9\n",
      "Train : Loss: 0.5882, Train error: 0.3595, Train f1 : 0.64049955396967\n",
      "Val : Loss: 3.3534, val error: 0.4421, Val f1 :0.5578947368421052\n",
      "Best validation accuracy  0.5842105263157895\n",
      "EPOCH  10\n",
      "Train : Loss: 0.5788, Train error: 0.3515, Train f1 : 0.648528099910794\n",
      "Val : Loss: 4.9200, val error: 0.4947, Val f1 :0.5052631578947369\n",
      "Best validation accuracy  0.5842105263157895\n",
      "EPOCH  11\n",
      "Train : Loss: 0.5735, Train error: 0.3274, Train f1 : 0.6726137377341659\n",
      "Val : Loss: 1.9089, val error: 0.3895, Val f1 :0.6105263157894737\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.6105263157894737\n",
      "EPOCH  12\n",
      "Train : Loss: 0.5599, Train error: 0.3176, Train f1 : 0.6824264049955397\n",
      "Val : Loss: 5.5369, val error: 0.5526, Val f1 :0.4473684210526316\n",
      "Best validation accuracy  0.6105263157894737\n",
      "EPOCH  13\n",
      "Train : Loss: 0.5580, Train error: 0.2997, Train f1 : 0.7002676181980375\n",
      "Val : Loss: 5.2111, val error: 0.5368, Val f1 :0.4631578947368421\n",
      "Best validation accuracy  0.6105263157894737\n",
      "EPOCH  14\n",
      "Train : Loss: 0.5483, Train error: 0.3015, Train f1 : 0.6984834968777877\n",
      "Val : Loss: 5.8359, val error: 0.5526, Val f1 :0.4473684210526316\n",
      "Best validation accuracy  0.6105263157894737\n",
      "EPOCH  15\n",
      "Train : Loss: 0.5420, Train error: 0.2935, Train f1 : 0.7065120428189117\n",
      "Val : Loss: 5.1022, val error: 0.4789, Val f1 :0.5210526315789473\n",
      "Best validation accuracy  0.6105263157894737\n",
      "EPOCH  16\n",
      "Train : Loss: 0.5303, Train error: 0.2881, Train f1 : 0.711864406779661\n",
      "Val : Loss: 5.1797, val error: 0.4789, Val f1 :0.5210526315789473\n",
      "Best validation accuracy  0.6105263157894737\n",
      "EPOCH  17\n",
      "Train : Loss: 0.5241, Train error: 0.2953, Train f1 : 0.7047279214986619\n",
      "Val : Loss: 4.9125, val error: 0.5579, Val f1 :0.4421052631578947\n",
      "Best validation accuracy  0.6105263157894737\n",
      "EPOCH  18\n",
      "Train : Loss: 0.5113, Train error: 0.2649, Train f1 : 0.7350579839429081\n",
      "Val : Loss: 5.8065, val error: 0.5684, Val f1 :0.43157894736842106\n",
      "Best validation accuracy  0.6105263157894737\n",
      "EPOCH  19\n",
      "Train : Loss: 0.5032, Train error: 0.2667, Train f1 : 0.7332738626226584\n",
      "Val : Loss: 6.6101, val error: 0.5842, Val f1 :0.41578947368421054\n",
      "Best validation accuracy  0.6105263157894737\n",
      "EPOCH  20\n",
      "Train : Loss: 0.4992, Train error: 0.2596, Train f1 : 0.7404103479036575\n",
      "Val : Loss: 6.0853, val error: 0.5737, Val f1 :0.4263157894736842\n",
      "Best validation accuracy  0.6105263157894737\n",
      "EPOCH  21\n",
      "Train : Loss: 0.4888, Train error: 0.2614, Train f1 : 0.7386262265834077\n",
      "Val : Loss: 5.8433, val error: 0.5737, Val f1 :0.4263157894736842\n",
      "Best validation accuracy  0.6105263157894737\n",
      "EPOCH  22\n",
      "Train : Loss: 0.4797, Train error: 0.2525, Train f1 : 0.7475468331846565\n",
      "Val : Loss: 3.3652, val error: 0.4895, Val f1 :0.5105263157894737\n",
      "Best validation accuracy  0.6105263157894737\n",
      "EPOCH  23\n",
      "Train : Loss: 0.4818, Train error: 0.2480, Train f1 : 0.752007136485281\n",
      "Val : Loss: 3.5259, val error: 0.5368, Val f1 :0.4631578947368421\n",
      "Best validation accuracy  0.6105263157894737\n",
      "EPOCH  24\n",
      "Train : Loss: 0.4684, Train error: 0.2337, Train f1 : 0.7662801070472792\n",
      "Val : Loss: 5.7669, val error: 0.5474, Val f1 :0.45263157894736844\n",
      "Best validation accuracy  0.6105263157894737\n",
      "EPOCH  25\n",
      "Train : Loss: 0.4715, Train error: 0.2409, Train f1 : 0.7591436217662801\n",
      "Val : Loss: 5.5173, val error: 0.5263, Val f1 :0.47368421052631576\n",
      "Best validation accuracy  0.6105263157894737\n",
      "EPOCH  26\n",
      "Train : Loss: 0.4540, Train error: 0.2194, Train f1 : 0.7805530776092774\n",
      "Val : Loss: 5.8617, val error: 0.5632, Val f1 :0.4368421052631579\n",
      "Best validation accuracy  0.6105263157894737\n",
      "EPOCH  27\n",
      "Train : Loss: 0.4407, Train error: 0.2132, Train f1 : 0.7867975022301517\n",
      "Val : Loss: 6.5736, val error: 0.5842, Val f1 :0.41578947368421054\n",
      "Best validation accuracy  0.6105263157894737\n",
      "EPOCH  28\n",
      "Train : Loss: 0.4338, Train error: 0.2194, Train f1 : 0.7805530776092774\n",
      "Val : Loss: 5.4616, val error: 0.5158, Val f1 :0.4842105263157895\n",
      "Best validation accuracy  0.6105263157894737\n",
      "EPOCH  29\n",
      "Train : Loss: 0.4248, Train error: 0.2087, Train f1 : 0.7912578055307761\n",
      "Val : Loss: 3.6757, val error: 0.4053, Val f1 :0.5947368421052631\n",
      "Best validation accuracy  0.6105263157894737\n",
      "EPOCH  30\n",
      "Train : Loss: 0.4064, Train error: 0.2007, Train f1 : 0.7992863514719001\n",
      "Val : Loss: 5.5614, val error: 0.5579, Val f1 :0.4421052631578947\n",
      "Best validation accuracy  0.6105263157894737\n",
      "EPOCH  31\n",
      "Train : Loss: 0.4104, Train error: 0.2016, Train f1 : 0.7983942908117752\n",
      "Val : Loss: 5.4936, val error: 0.6000, Val f1 :0.4\n",
      "Best validation accuracy  0.6105263157894737\n",
      "EPOCH  32\n",
      "Train : Loss: 0.3850, Train error: 0.1900, Train f1 : 0.8099910793933988\n",
      "Val : Loss: 3.3847, val error: 0.3842, Val f1 :0.6157894736842106\n",
      "---------State saved---------\n",
      "Best validation accuracy  0.6157894736842106\n",
      "EPOCH  33\n",
      "Train : Loss: 0.3908, Train error: 0.1855, Train f1 : 0.8144513826940232\n",
      "Val : Loss: 6.3207, val error: 0.5684, Val f1 :0.43157894736842106\n",
      "Best validation accuracy  0.6157894736842106\n",
      "EPOCH  34\n",
      "Train : Loss: 0.3691, Train error: 0.1820, Train f1 : 0.8180196253345228\n",
      "Val : Loss: 6.3403, val error: 0.5632, Val f1 :0.4368421052631579\n",
      "Best validation accuracy  0.6157894736842106\n",
      "EPOCH  35\n",
      "Train : Loss: 0.3581, Train error: 0.1695, Train f1 : 0.8305084745762712\n",
      "Val : Loss: 3.9557, val error: 0.4000, Val f1 :0.6\n",
      "Best validation accuracy  0.6157894736842106\n",
      "EPOCH  36\n",
      "Train : Loss: 0.3438, Train error: 0.1552, Train f1 : 0.8447814451382694\n",
      "Val : Loss: 5.4597, val error: 0.4842, Val f1 :0.5157894736842106\n",
      "Best validation accuracy  0.6157894736842106\n",
      "EPOCH  37\n",
      "Train : Loss: 0.3370, Train error: 0.1525, Train f1 : 0.847457627118644\n",
      "Val : Loss: 5.3416, val error: 0.5526, Val f1 :0.4473684210526316\n",
      "Best validation accuracy  0.6157894736842106\n",
      "EPOCH  38\n",
      "Train : Loss: 0.3380, Train error: 0.1579, Train f1 : 0.8421052631578947\n",
      "Val : Loss: 4.0727, val error: 0.4526, Val f1 :0.5473684210526316\n",
      "Best validation accuracy  0.6157894736842106\n",
      "EPOCH  39\n",
      "Train : Loss: 0.3346, Train error: 0.1481, Train f1 : 0.8519179304192686\n",
      "Val : Loss: 5.3424, val error: 0.4684, Val f1 :0.531578947368421\n",
      "Best validation accuracy  0.6157894736842106\n",
      "EPOCH  40\n",
      "Train : Loss: 0.3153, Train error: 0.1445, Train f1 : 0.855486173059768\n",
      "Val : Loss: 5.8559, val error: 0.5368, Val f1 :0.4631578947368421\n",
      "Best validation accuracy  0.6157894736842106\n",
      "EPOCH  41\n",
      "Train : Loss: 0.2993, Train error: 0.1356, Train f1 : 0.864406779661017\n",
      "Val : Loss: 5.4327, val error: 0.4947, Val f1 :0.5052631578947369\n",
      "Best validation accuracy  0.6157894736842106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  42\n",
      "Train : Loss: 0.3123, Train error: 0.1347, Train f1 : 0.8652988403211418\n",
      "Val : Loss: 5.4529, val error: 0.4737, Val f1 :0.5263157894736842\n",
      "Best validation accuracy  0.6157894736842106\n",
      "EPOCH  43\n",
      "Train : Loss: 0.2847, Train error: 0.1249, Train f1 : 0.8751115075825157\n",
      "Val : Loss: 5.7929, val error: 0.5421, Val f1 :0.45789473684210524\n",
      "Best validation accuracy  0.6157894736842106\n",
      "EPOCH  44\n",
      "Train : Loss: 0.2756, Train error: 0.1151, Train f1 : 0.8849241748438894\n",
      "Val : Loss: 4.5585, val error: 0.4211, Val f1 :0.5789473684210527\n",
      "Best validation accuracy  0.6157894736842106\n",
      "EPOCH  45\n",
      "Train : Loss: 0.2752, Train error: 0.1195, Train f1 : 0.8804638715432649\n",
      "Val : Loss: 3.6307, val error: 0.4368, Val f1 :0.5631578947368421\n",
      "Best validation accuracy  0.6157894736842106\n",
      "EPOCH  46\n",
      "Train : Loss: 0.2661, Train error: 0.1213, Train f1 : 0.8786797502230151\n",
      "Val : Loss: 5.2710, val error: 0.5368, Val f1 :0.4631578947368421\n",
      "Best validation accuracy  0.6157894736842106\n",
      "EPOCH  47\n",
      "Train : Loss: 0.2478, Train error: 0.1088, Train f1 : 0.8911685994647636\n",
      "Val : Loss: 4.5633, val error: 0.4526, Val f1 :0.5473684210526316\n",
      "Best validation accuracy  0.6157894736842106\n",
      "EPOCH  48\n",
      "Train : Loss: 0.2224, Train error: 0.0901, Train f1 : 0.9099018733273863\n",
      "Val : Loss: 4.3746, val error: 0.4263, Val f1 :0.5736842105263158\n",
      "Best validation accuracy  0.6157894736842106\n",
      "EPOCH  49\n",
      "Train : Loss: 0.2681, Train error: 0.1124, Train f1 : 0.8876003568242641\n",
      "Val : Loss: 6.7289, val error: 0.5947, Val f1 :0.4052631578947368\n",
      "Best validation accuracy  0.6157894736842106\n"
     ]
    }
   ],
   "source": [
    "LR = 1e-4\n",
    "model=Attention()\n",
    "if torch.cuda.is_available():model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
    "\n",
    "best_model = \"./saved_models/best_model_Attention-mil-fs-grp3\"\n",
    "train_acc = []\n",
    "modelname=[]\n",
    "val_acc = []\n",
    "best_acc = 0\n",
    "for epoch in range(0, 50): #15,#15,200\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    train_error = 0.\n",
    "    y =[]\n",
    "    ypred = []\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        bag_label = label[0]\n",
    "        data, bag_label = data.cuda(), bag_label.cuda()\n",
    "        data, bag_label = Variable(data), Variable(bag_label)\n",
    "        optimizer.zero_grad()\n",
    "        loss, _ = model.calculate_objective(data.float(), bag_label.float())\n",
    "        train_loss += loss.data[0]\n",
    "        error,y_pred = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "        train_error += error\n",
    "        y_pred=y_pred.squeeze(1)\n",
    "        ypred.extend(y_pred.tolist())\n",
    "        y.extend(bag_label.tolist())\n",
    "        loss.mean().backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    \n",
    "    trainacc = accuracy_score(y,ypred)\n",
    "    train_loss /= len(train_loader)\n",
    "    train_error /= len(train_loader)\n",
    "    print(\"EPOCH \",epoch)\n",
    "    print('Train : Loss: {:.4f}, Train error: {:.4f}, Train f1 : {}'.format(train_loss.cpu().numpy()[0], \n",
    "                                                                                train_error,trainacc))\n",
    "    y =[]\n",
    "    ypred = []\n",
    "    val_error=0.\n",
    "    val_loss= 0.\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, label) in enumerate(val_loader):\n",
    "            bag_label = label[0]\n",
    "            data, bag_label = data.cuda(), bag_label.cuda()\n",
    "            data, bag_label = Variable(data), Variable(bag_label)\n",
    "            loss, _ = model.calculate_objective(data.float(), bag_label.float())\n",
    "            val_loss += loss.data[0]\n",
    "            error, y_pred = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "            val_error += error\n",
    "            y_pred=y_pred.squeeze(1)\n",
    "            ypred.extend(y_pred.tolist())\n",
    "            y.extend(bag_label.tolist())\n",
    "        valacc = accuracy_score(y,ypred)\n",
    "        val_loss /= len(val_loader)\n",
    "        val_error /= len(val_loader)\n",
    "        print('Val : Loss: {:.4f}, val error: {:.4f}, Val f1 :{}'.format(val_loss.cpu().numpy()[0], val_error,valacc))\n",
    "        if valacc>=best_acc:\n",
    "            print(\"---------State saved---------\")\n",
    "            best_acc = valacc\n",
    "            best_state=model.state_dict()\n",
    "            torch.save(best_state, best_model+'_epoch_'+str(epoch)+\".pth\")\n",
    "            modelname.append(best_model+'_epoch_'+str(epoch)+\".pth\")\n",
    "        print('Best validation accuracy ',best_acc)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7236180904522613 0.7263681592039801 0.6576576576576577 0.8111111111111111 0.731243628950051 0.6513761467889908\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model=Attention()\n",
    "best_state=torch.load(modelname[-1]) #../best-models/Attention_MIL_best_free_speech_raw_F1_79.pth\n",
    "model.load_state_dict(best_state)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "test_loss = 0.\n",
    "correct = 0\n",
    "total = 0\n",
    "y =[]\n",
    "ypred = []\n",
    "test_error = 0.\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for batch_idx, (data, label) in enumerate(test_loader):\n",
    "        bag_label = label[0]\n",
    "        instance_labels = label[1]\n",
    "        data, bag_label = data.cuda(), bag_label.cuda()\n",
    "        data, bag_label = Variable(data), Variable(bag_label)\n",
    "        loss, attention_weights = model.calculate_objective(data.float(), bag_label.float())\n",
    "        test_loss += loss.data[0]\n",
    "        error, predicted_label = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "        test_error += error\n",
    "        predicted_label=predicted_label.squeeze(1)\n",
    "        ypred.extend(predicted_label.tolist())\n",
    "        y.extend(bag_label.tolist())\n",
    "\n",
    "    acc=accuracy_score(y,ypred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y,ypred).ravel()\n",
    "    f1score=f1_score(y,ypred)\n",
    "    precision=precision_score(y,ypred)\n",
    "    recall=recall_score(y,ypred)\n",
    "    roc=roc_auc_score(y,ypred)\n",
    "    specificity=tn/(tn+fp)\n",
    "    print(acc,f1score,precision,recall,roc,specificity)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.678391959798995 0.728813559322034 0.589041095890411 0.9555555555555556 0.7025484199796127 0.44954128440366975\n",
      "0.48743718592964824 0.2388059701492537 0.36363636363636365 0.17777777777777778 0.46044852191641183 0.7431192660550459\n",
      "0.5879396984924623 0.6203703703703705 0.5317460317460317 0.7444444444444445 0.6015800203873598 0.45871559633027525\n",
      "0.49748743718592964 0.3055555555555555 0.4074074074074074 0.24444444444444444 0.47543323139653415 0.7064220183486238\n",
      "0.7236180904522613 0.7263681592039801 0.6576576576576577 0.8111111111111111 0.731243628950051 0.6513761467889908\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(modelname)):\n",
    "    device = torch.device(\"cuda\")\n",
    "    model=Attention()\n",
    "    best_state=torch.load(modelname[i]) #../best-models/Attention_MIL_best_free_speech_raw_F1_79.pth\n",
    "    model.load_state_dict(best_state)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y =[]\n",
    "    ypred = []\n",
    "    test_error = 0.\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch_idx, (data, label) in enumerate(test_loader):\n",
    "            bag_label = label[0]\n",
    "            instance_labels = label[1]\n",
    "            data, bag_label = data.cuda(), bag_label.cuda()\n",
    "            data, bag_label = Variable(data), Variable(bag_label)\n",
    "            loss, attention_weights = model.calculate_objective(data.float(), bag_label.float())\n",
    "            test_loss += loss.data[0]\n",
    "            error, predicted_label = model.calculate_classification_error(data.float(), bag_label.float())\n",
    "            test_error += error\n",
    "            predicted_label=predicted_label.squeeze(1)\n",
    "            ypred.extend(predicted_label.tolist())\n",
    "            y.extend(bag_label.tolist())\n",
    "\n",
    "        acc=accuracy_score(y,ypred)\n",
    "        tn, fp, fn, tp = confusion_matrix(y,ypred).ravel()\n",
    "        f1score=f1_score(y,ypred)\n",
    "        precision=precision_score(y,ypred)\n",
    "        recall=recall_score(y,ypred)\n",
    "        roc=roc_auc_score(y,ypred)\n",
    "        specificity=tn/(tn+fp)\n",
    "        print(acc,f1score,precision,recall,roc,specificity)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./saved_models/best_model_Attention-mil-fs-grp3_epoch_32.pth'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelname[-1]\n",
    "#9639-.628140703517588 0.5795454545454546 0.5930232558139535 0.5666666666666667 0.622782874617737 0.6788990825688074"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------\n",
    "        Layer (type)               Output Shape         Param #\n",
    "================================================================\n",
    "            Conv1d-1              [-1, 256, 23]             768\n",
    "              ReLU-2              [-1, 256, 23]               0\n",
    "            Conv1d-3               [-1, 64, 22]          32,832\n",
    "              ReLU-4               [-1, 64, 22]               0\n",
    "       BatchNorm1d-5                 [-1, 1408]               0\n",
    "            Linear-6                  [-1, 512]         721,408\n",
    "              ReLU-7                  [-1, 512]               0\n",
    "            Linear-8                  [-1, 256]         131,328\n",
    "              ReLU-9                  [-1, 256]               0\n",
    "           Linear-10                  [-1, 128]          32,896\n",
    "             ReLU-11                  [-1, 128]               0\n",
    "           Linear-12                   [-1, 64]           8,256\n",
    "             Tanh-13                   [-1, 64]               0\n",
    "           Linear-14                    [-1, 1]              65\n",
    "           Linear-15                   [-1, 64]           8,256\n",
    "             ReLU-16                   [-1, 64]               0\n",
    "           Linear-17                    [-1, 1]              65\n",
    "          Sigmoid-18                    [-1, 1]               0\n",
    "================================================================\n",
    "Total params: 935,874\n",
    "Trainable params: 935,874\n",
    "Non-trainable params: 0\n",
    "----------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (physio)",
   "language": "python",
   "name": "physio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
