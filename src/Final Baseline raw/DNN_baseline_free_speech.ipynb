{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pylab\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "seed =11\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(seed)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, X1, Y1):\n",
    "        self.X1 = X1\n",
    "        self.Y1 = Y1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.X1[index]\n",
    "        y1 = self.Y1[index]\n",
    "        return x, y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    if type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.L = 128\n",
    "        self.D = 64\n",
    "        self.K = 1\n",
    "        self.feature_size = 24\n",
    "        self.shared_layer_size = 512\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(24, 128),\n",
    "#             nn.Dropout(0.1),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "#             nn.Dropout(0.1),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(9728, 512), #166400\n",
    "            nn.BatchNorm1d(512),\n",
    "#             nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "#             nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "                               \n",
    "    def forward(self, x):\n",
    "        \n",
    "        Y_prob=self.fc(x)\n",
    "        Y_prob=self.fc2(Y_prob.reshape(Y_prob.size(0),-1))\n",
    "        \n",
    "        return Y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "class CyclicLR(_LRScheduler):\n",
    "    \n",
    "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
    "        assert callable(schedule)\n",
    "        self.schedule = schedule\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(t_max, eta_min=0):\n",
    "    \n",
    "    def scheduler(epoch, base_lr):\n",
    "        t = epoch % t_max\n",
    "        return eta_min + (base_lr - eta_min)*(1 + np.cos(np.pi*t/t_max))/2\n",
    "    \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=np.load(\"../extracted_features/FS/input_features_free_train.npy\")\n",
    "labels_stress_train=np.load(\"../extracted_features/FS/label_free_train.npy\")\n",
    "\n",
    "\n",
    "test_features=np.load(\"../extracted_features/FS/input_features_free_test.npy\")\n",
    "labels_stress_test=np.load(\"../extracted_features/FS/label_free_test.npy\")\n",
    "\n",
    "\n",
    "val_features=np.load(\"../extracted_features/FS/input_features_free_val.npy\")\n",
    "labels_stress_val=np.load(\"../extracted_features/FS/label_free_val.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1121,) [0. 0. 0. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(labels_stress_train.shape,labels_stress_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1121, 19, 24) (1121,)\n",
      "(190, 19, 24) (190,)\n",
      "(199, 19, 24) (199,)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape,labels_stress_train.shape)\n",
    "print(test_features.shape,labels_stress_test.shape)\n",
    "print(val_features.shape,labels_stress_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=50\n",
    "train_data = Dataset(train_features, labels_stress_train)\n",
    "test_data=Dataset(test_features,labels_stress_test)\n",
    "val_data=Dataset(val_features,labels_stress_val)\n",
    "train_data_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_data_loader=DataLoader(test_data,shuffle=True,batch_size=batch_size)\n",
    "test_data_loader=DataLoader(val_data,shuffle=True,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50])\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for batch in val_data_loader:\n",
    "    print(batch[1].shape)\n",
    "    break\n",
    "print(len(val_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = 24\n",
    "shared_layer_size = 512\n",
    "LR = 0.0001\n",
    "epoch = 50\n",
    "model=Classifier()\n",
    "model.cuda()\n",
    "iterations_per_epoch = len(train_data_loader)\n",
    "model.apply(init_weights)\n",
    "loss_func = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "sched = CyclicLR(optimizer, cosine(t_max=iterations_per_epoch * 2, eta_min=LR/100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# summary(model.cuda(),(1,19,24))\n",
    "# torch.save(model, \"modelarchitect_final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0\n",
      "Train : Loss: 0.0181, Train acc1 : 0.5438\n",
      "Val : Loss: 0.0192, Val acc1 : 0.5736\n",
      "Best validation accuracy1  0.5735849056603775\n",
      "Test : Loss: 0.0210, test acc1 : 0.6246\n",
      "EPOCH  1\n",
      "Train : Loss: 0.0144, Train acc1 : 0.5997\n",
      "Val : Loss: 0.0151, Val acc1 : 0.4151\n",
      "Test : Loss: 0.0149, test acc1 : 0.6457\n",
      "EPOCH  2\n",
      "Train : Loss: 0.0140, Train acc1 : 0.5933\n",
      "Val : Loss: 0.0144, Val acc1 : 0.4623\n",
      "Test : Loss: 0.0155, test acc1 : 0.6307\n",
      "EPOCH  3\n",
      "Train : Loss: 0.0134, Train acc1 : 0.6203\n",
      "Val : Loss: 0.0144, Val acc1 : 0.4205\n",
      "Test : Loss: 0.0152, test acc1 : 0.6524\n",
      "EPOCH  4\n",
      "Train : Loss: 0.0136, Train acc1 : 0.6197\n",
      "Val : Loss: 0.0149, Val acc1 : 0.4775\n",
      "Test : Loss: 0.0154, test acc1 : 0.6400\n",
      "EPOCH  5\n",
      "Train : Loss: 0.0131, Train acc1 : 0.6223\n",
      "Val : Loss: 0.0149, Val acc1 : 0.3902\n",
      "Test : Loss: 0.0157, test acc1 : 0.6446\n",
      "EPOCH  6\n",
      "Train : Loss: 0.0136, Train acc1 : 0.6163\n",
      "Val : Loss: 0.0139, Val acc1 : 0.3636\n",
      "Test : Loss: 0.0155, test acc1 : 0.3185\n",
      "EPOCH  7\n",
      "Train : Loss: 0.0129, Train acc1 : 0.6258\n",
      "Val : Loss: 0.0147, Val acc1 : 0.3678\n",
      "Test : Loss: 0.0152, test acc1 : 0.6000\n",
      "EPOCH  8\n",
      "Train : Loss: 0.0132, Train acc1 : 0.6141\n",
      "Val : Loss: 0.0149, Val acc1 : 0.5259\n",
      "Test : Loss: 0.0156, test acc1 : 0.6100\n",
      "EPOCH  9\n",
      "Train : Loss: 0.0125, Train acc1 : 0.6562\n",
      "Val : Loss: 0.0147, Val acc1 : 0.4658\n",
      "Test : Loss: 0.0152, test acc1 : 0.6185\n",
      "EPOCH  10\n",
      "Train : Loss: 0.0127, Train acc1 : 0.6235\n",
      "Val : Loss: 0.0144, Val acc1 : 0.2500\n",
      "Test : Loss: 0.0153, test acc1 : 0.2290\n",
      "EPOCH  11\n",
      "Train : Loss: 0.0126, Train acc1 : 0.6145\n",
      "Val : Loss: 0.0144, Val acc1 : 0.4343\n",
      "Test : Loss: 0.0155, test acc1 : 0.6337\n",
      "EPOCH  12\n",
      "Train : Loss: 0.0127, Train acc1 : 0.6584\n",
      "Val : Loss: 0.0152, Val acc1 : 0.5725\n",
      "Test : Loss: 0.0179, test acc1 : 0.5921\n",
      "EPOCH  13\n",
      "Train : Loss: 0.0125, Train acc1 : 0.6336\n",
      "Val : Loss: 0.0146, Val acc1 : 0.3889\n",
      "Test : Loss: 0.0170, test acc1 : 0.6094\n",
      "EPOCH  14\n",
      "Train : Loss: 0.0123, Train acc1 : 0.6622\n",
      "Val : Loss: 0.0148, Val acc1 : 0.4249\n",
      "Test : Loss: 0.0168, test acc1 : 0.6134\n",
      "EPOCH  15\n",
      "Train : Loss: 0.0122, Train acc1 : 0.6497\n",
      "Val : Loss: 0.0144, Val acc1 : 0.4176\n",
      "Test : Loss: 0.0166, test acc1 : 0.5983\n",
      "EPOCH  16\n",
      "Train : Loss: 0.0122, Train acc1 : 0.6708\n",
      "Val : Loss: 0.0146, Val acc1 : 0.4222\n",
      "Test : Loss: 0.0174, test acc1 : 0.6174\n",
      "EPOCH  17\n",
      "Train : Loss: 0.0119, Train acc1 : 0.6667\n",
      "Val : Loss: 0.0149, Val acc1 : 0.4308\n",
      "Test : Loss: 0.0176, test acc1 : 0.5932\n",
      "EPOCH  18\n",
      "Train : Loss: 0.0121, Train acc1 : 0.6544\n",
      "Val : Loss: 0.0148, Val acc1 : 0.2264\n",
      "Test : Loss: 0.0187, test acc1 : 0.0476\n",
      "EPOCH  19\n",
      "Train : Loss: 0.0120, Train acc1 : 0.6256\n",
      "Val : Loss: 0.0145, Val acc1 : 0.4479\n",
      "Test : Loss: 0.0176, test acc1 : 0.5398\n",
      "EPOCH  20\n",
      "Train : Loss: 0.0122, Train acc1 : 0.6685\n",
      "Val : Loss: 0.0162, Val acc1 : 0.5285\n",
      "Test : Loss: 0.0206, test acc1 : 0.5891\n",
      "EPOCH  21\n",
      "Train : Loss: 0.0118, Train acc1 : 0.6751\n",
      "Val : Loss: 0.0149, Val acc1 : 0.3977\n",
      "Test : Loss: 0.0184, test acc1 : 0.5429\n",
      "EPOCH  22\n",
      "Train : Loss: 0.0123, Train acc1 : 0.6607\n",
      "Val : Loss: 0.0159, Val acc1 : 0.5824\n",
      "Best validation accuracy1  0.5823754789272031\n",
      "Test : Loss: 0.0193, test acc1 : 0.5957\n",
      "EPOCH  23\n",
      "Train : Loss: 0.0115, Train acc1 : 0.6813\n",
      "Val : Loss: 0.0154, Val acc1 : 0.4130\n",
      "Test : Loss: 0.0186, test acc1 : 0.5308\n",
      "EPOCH  24\n",
      "Train : Loss: 0.0120, Train acc1 : 0.6676\n",
      "Val : Loss: 0.0157, Val acc1 : 0.4324\n",
      "Test : Loss: 0.0222, test acc1 : 0.5954\n",
      "EPOCH  25\n",
      "Train : Loss: 0.0113, Train acc1 : 0.6722\n",
      "Val : Loss: 0.0153, Val acc1 : 0.3858\n",
      "Test : Loss: 0.0197, test acc1 : 0.5778\n",
      "EPOCH  26\n",
      "Train : Loss: 0.0118, Train acc1 : 0.6740\n",
      "Val : Loss: 0.0145, Val acc1 : 0.4414\n",
      "Test : Loss: 0.0223, test acc1 : 0.3911\n",
      "EPOCH  27\n",
      "Train : Loss: 0.0115, Train acc1 : 0.6452\n",
      "Val : Loss: 0.0152, Val acc1 : 0.4162\n",
      "Test : Loss: 0.0205, test acc1 : 0.5236\n",
      "EPOCH  28\n",
      "Train : Loss: 0.0118, Train acc1 : 0.6545\n",
      "Val : Loss: 0.0158, Val acc1 : 0.5692\n",
      "Test : Loss: 0.0207, test acc1 : 0.5912\n",
      "EPOCH  29\n",
      "Train : Loss: 0.0112, Train acc1 : 0.6848\n",
      "Val : Loss: 0.0146, Val acc1 : 0.4146\n",
      "Test : Loss: 0.0194, test acc1 : 0.4433\n",
      "EPOCH  30\n",
      "Train : Loss: 0.0113, Train acc1 : 0.6686\n",
      "Val : Loss: 0.0153, Val acc1 : 0.3704\n",
      "Test : Loss: 0.0191, test acc1 : 0.5571\n",
      "EPOCH  31\n",
      "Train : Loss: 0.0114, Train acc1 : 0.6811\n",
      "Val : Loss: 0.0157, Val acc1 : 0.3617\n",
      "Test : Loss: 0.0230, test acc1 : 0.5494\n",
      "EPOCH  32\n",
      "Train : Loss: 0.0116, Train acc1 : 0.6725\n",
      "Val : Loss: 0.0146, Val acc1 : 0.3922\n",
      "Test : Loss: 0.0202, test acc1 : 0.4199\n",
      "EPOCH  33\n",
      "Train : Loss: 0.0110, Train acc1 : 0.6749\n",
      "Val : Loss: 0.0153, Val acc1 : 0.3774\n",
      "Test : Loss: 0.0216, test acc1 : 0.4569\n",
      "EPOCH  34\n",
      "Train : Loss: 0.0111, Train acc1 : 0.6814\n",
      "Val : Loss: 0.0166, Val acc1 : 0.5736\n",
      "Test : Loss: 0.0207, test acc1 : 0.6028\n",
      "EPOCH  35\n",
      "Train : Loss: 0.0109, Train acc1 : 0.6972\n",
      "Val : Loss: 0.0153, Val acc1 : 0.3955\n",
      "Test : Loss: 0.0213, test acc1 : 0.4880\n",
      "EPOCH  36\n",
      "Train : Loss: 0.0110, Train acc1 : 0.6832\n",
      "Val : Loss: 0.0183, Val acc1 : 0.5781\n",
      "Test : Loss: 0.0245, test acc1 : 0.6000\n",
      "EPOCH  37\n",
      "Train : Loss: 0.0108, Train acc1 : 0.6943\n",
      "Val : Loss: 0.0153, Val acc1 : 0.3899\n",
      "Test : Loss: 0.0229, test acc1 : 0.4444\n",
      "EPOCH  38\n",
      "Train : Loss: 0.0114, Train acc1 : 0.6913\n",
      "Val : Loss: 0.0150, Val acc1 : 0.3816\n",
      "Test : Loss: 0.0202, test acc1 : 0.4301\n",
      "EPOCH  39\n",
      "Train : Loss: 0.0105, Train acc1 : 0.6764\n",
      "Val : Loss: 0.0153, Val acc1 : 0.3920\n",
      "Test : Loss: 0.0205, test acc1 : 0.5259\n",
      "EPOCH  40\n",
      "Train : Loss: 0.0111, Train acc1 : 0.6825\n",
      "Val : Loss: 0.0158, Val acc1 : 0.3500\n",
      "Test : Loss: 0.0227, test acc1 : 0.1571\n",
      "EPOCH  41\n",
      "Train : Loss: 0.0107, Train acc1 : 0.6622\n",
      "Val : Loss: 0.0152, Val acc1 : 0.3846\n",
      "Test : Loss: 0.0226, test acc1 : 0.4286\n",
      "EPOCH  42\n",
      "Train : Loss: 0.0113, Train acc1 : 0.6723\n",
      "Val : Loss: 0.0156, Val acc1 : 0.3911\n",
      "Test : Loss: 0.0239, test acc1 : 0.4700\n",
      "EPOCH  43\n",
      "Train : Loss: 0.0104, Train acc1 : 0.7110\n",
      "Val : Loss: 0.0152, Val acc1 : 0.3825\n",
      "Test : Loss: 0.0200, test acc1 : 0.4729\n",
      "EPOCH  44\n",
      "Train : Loss: 0.0109, Train acc1 : 0.6912\n",
      "Val : Loss: 0.0154, Val acc1 : 0.4022\n",
      "Test : Loss: 0.0195, test acc1 : 0.4554\n",
      "EPOCH  45\n",
      "Train : Loss: 0.0101, Train acc1 : 0.7052\n",
      "Val : Loss: 0.0154, Val acc1 : 0.3892\n",
      "Test : Loss: 0.0221, test acc1 : 0.4953\n",
      "EPOCH  46\n",
      "Train : Loss: 0.0106, Train acc1 : 0.7003\n",
      "Val : Loss: 0.0161, Val acc1 : 0.4068\n",
      "Test : Loss: 0.0261, test acc1 : 0.5135\n",
      "EPOCH  47\n",
      "Train : Loss: 0.0099, Train acc1 : 0.7276\n",
      "Val : Loss: 0.0156, Val acc1 : 0.4466\n",
      "Test : Loss: 0.0220, test acc1 : 0.5311\n",
      "EPOCH  48\n",
      "Train : Loss: 0.0103, Train acc1 : 0.7190\n",
      "Val : Loss: 0.0159, Val acc1 : 0.4000\n",
      "Test : Loss: 0.0235, test acc1 : 0.5273\n",
      "EPOCH  49\n",
      "Train : Loss: 0.0097, Train acc1 : 0.7252\n",
      "Val : Loss: 0.0160, Val acc1 : 0.3750\n",
      "Test : Loss: 0.0225, test acc1 : 0.4100\n",
      "EPOCH  50\n",
      "Train : Loss: 0.0102, Train acc1 : 0.7171\n",
      "Val : Loss: 0.0163, Val acc1 : 0.3529\n",
      "Test : Loss: 0.0238, test acc1 : 0.1931\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "# best_model = \"./runs/\"+ts+\"/best_model_CNN_Cuda1.pth\"\n",
    "best_acc1 = 0\n",
    "best_model1 = \"./saved_models/best_model_dnn_fs\"\n",
    "modelname=[]\n",
    "truth=[]\n",
    "preds=[]\n",
    "\n",
    "for it in range(epoch+1):\n",
    "    model.train()\n",
    "    total=len(train_data_loader)*batch_size\n",
    "    train_loss = 0.\n",
    "    for minibatch in train_data_loader:\n",
    "        X, Y1  = minibatch\n",
    "        X=X.cuda()\n",
    "        Y1=Y1.cuda()\n",
    "        output = model(X.float())\n",
    "        output=output.squeeze(1)\n",
    "        loss = loss_func(output, Y1.float())\n",
    "        Y_hat1 = torch.ge(output, 0.5).float()\n",
    "        train_loss += loss.item()\n",
    "        truth.extend(Y1.tolist())\n",
    "        preds.extend(Y_hat1.tolist())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sched.step()\n",
    "    trainacc1=f1_score(truth,preds)\n",
    "    train_loss /= total\n",
    "    print(\"EPOCH \",it)\n",
    "    print('Train : Loss: {:.4f}, Train acc1 : {:.4f}'.format(train_loss,trainacc1))\n",
    "    \n",
    "\n",
    "    val_loss= 0.\n",
    "    truth=[]\n",
    "    preds=[]\n",
    "    total=len(val_data_loader)*batch_size\n",
    "    model.eval()    \n",
    "    for minibatch in val_data_loader:\n",
    "        X_valid, Y1_valid  = minibatch\n",
    "        X_valid=X_valid.cuda()\n",
    "        Y1_valid=Y1_valid.cuda()\n",
    "        output_val = model(X_valid.float())\n",
    "        output_val=output_val.squeeze(1)\n",
    "        loss = loss_func(output_val, Y1_valid.float())\n",
    "        Y_hat1_val = torch.ge(output_val, 0.5).float()\n",
    "        val_loss += loss.item()\n",
    "        truth.extend(Y1_valid.tolist())\n",
    "        preds.extend(Y_hat1_val.tolist())\n",
    "    valacc1=f1_score(truth,preds)\n",
    "    val_loss /= total\n",
    "    print('Val : Loss: {:.4f}, Val acc1 : {:.4f}'.format(val_loss,valacc1))\n",
    "    if valacc1 >= best_acc1:\n",
    "        torch.save(model.state_dict(), best_model1+\".pth\")\n",
    "        modelname.append(best_model1+\".pth\")\n",
    "        best_acc1 = valacc1\n",
    "        best_state = model.state_dict()\n",
    "        print('Best validation accuracy1 ', best_acc1)\n",
    "    val_loss= 0.\n",
    "    truth=[]\n",
    "    preds=[]\n",
    "    total=len(test_data_loader)*batch_size\n",
    "    model.eval()    \n",
    "    for minibatch in test_data_loader:\n",
    "        X_valid, Y1_valid  = minibatch\n",
    "        X_valid=X_valid.cuda()\n",
    "        Y1_valid=Y1_valid.cuda()\n",
    "        output_val = model(X_valid.float())\n",
    "        output_val=output_val.squeeze(1)\n",
    "        loss = loss_func(output_val, Y1_valid.float())\n",
    "        Y_hat1_val = torch.ge(output_val, 0.5).float()\n",
    "        val_loss += loss.item()\n",
    "        truth.extend(Y1_valid.tolist())\n",
    "        preds.extend(Y_hat1_val.tolist())\n",
    "    valacc1=f1_score(truth,preds)\n",
    "    val_loss /= total\n",
    "    print('Test : Loss: {:.4f}, test acc1 : {:.4f}'.format(val_loss,valacc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43 0.60 0.44 0.93 0.47 0.01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "modeltest=Classifier()\n",
    "best_state=torch.load(modelname[-1])\n",
    "modeltest.load_state_dict(best_state)\n",
    "modeltest.cuda()\n",
    "modeltest.eval()\n",
    "truth=[]\n",
    "preds=[]\n",
    "for minibatch in test_data_loader:\n",
    "            X_test, Y1_test  = minibatch\n",
    "            X_test=X_test.cuda()\n",
    "            Y1_test=Y1_test.cuda()\n",
    "            output_test = modeltest(X_test.float())\n",
    "            output_test=output_test.squeeze(1)\n",
    "            prediction = torch.ge(output_test, 0.5).float()\n",
    "            truth.extend(Y1_test.tolist())\n",
    "            preds.extend(prediction.tolist())\n",
    "acc=accuracy_score(truth,preds)\n",
    "# print(truth,preds)\n",
    "tn, fp, fn, tp = confusion_matrix(truth, preds).ravel()\n",
    "f1score=f1_score(truth, preds)\n",
    "precision=precision_score(truth, preds)\n",
    "recall=recall_score(truth,preds)\n",
    "roc=roc_auc_score(truth,preds)\n",
    "specificity=tn/(tn+fp)\n",
    "\n",
    "print('{:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f}'.format(acc,f1score,precision,recall,roc,specificity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43 0.60 0.44 0.93 0.47 0.01\n",
      "0.43 0.60 0.44 0.93 0.47 0.01\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(modelname)):\n",
    "    modeltest=Classifier()\n",
    "    best_state=torch.load(modelname[i])\n",
    "    modeltest.load_state_dict(best_state)\n",
    "    modeltest.cuda()\n",
    "    modeltest.eval()\n",
    "    truth=[]\n",
    "    preds=[]\n",
    "    for minibatch in test_data_loader:\n",
    "                X_test, Y1_test  = minibatch\n",
    "                X_test=X_test.cuda()\n",
    "                Y1_test=Y1_test.cuda()\n",
    "                output_test = modeltest(X_test.float())\n",
    "                output_test=output_test.squeeze(1)\n",
    "                prediction = torch.ge(output_test, 0.5).float()\n",
    "                truth.extend(Y1_test.tolist())\n",
    "                preds.extend(prediction.tolist())\n",
    "    acc=accuracy_score(truth,preds)\n",
    "    # print(truth,preds)\n",
    "    tn, fp, fn, tp = confusion_matrix(truth, preds).ravel()\n",
    "    f1score=f1_score(truth, preds)\n",
    "    precision=precision_score(truth, preds)\n",
    "    recall=recall_score(truth,preds)\n",
    "    roc=roc_auc_score(truth,preds)\n",
    "    specificity=tn/(tn+fp)\n",
    "    print('{:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f}'.format(acc,f1score,precision,recall,roc,specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(best_state, \"./saved_model-baseline-free/DNN_best_free_speech_F1_52.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (physio)",
   "language": "python",
   "name": "physio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
