{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "seed = 2021\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, X1, Y1):\n",
    "        self.X1 = X1\n",
    "        self.Y1 = Y1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.X1[index]\n",
    "        y1 = self.Y1[index]\n",
    "        return x, y1\n",
    "\n",
    "train_features=np.load(\"../extracted_features/FS/input_features_free_train.npy\")\n",
    "labels_stress_train=np.load(\"../extracted_features/FS/label_free_train.npy\")\n",
    "\n",
    "\n",
    "test_features=np.load(\"../extracted_features/FS/input_features_free_test.npy\")\n",
    "labels_stress_test=np.load(\"../extracted_features/FS/label_free_test.npy\")\n",
    "\n",
    "\n",
    "val_features=np.load(\"../extracted_features/FS/input_features_free_val.npy\")\n",
    "labels_stress_val=np.load(\"../extracted_features/FS/label_free_val.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1121,) [0. 0. 0. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(labels_stress_train.shape,labels_stress_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=20\n",
    "train_data = Dataset(train_features, labels_stress_train)\n",
    "test_data=Dataset(test_features,labels_stress_test)\n",
    "val_data=Dataset(val_features,labels_stress_val)\n",
    "train_data_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_data_loader=DataLoader(test_data,shuffle=True,batch_size=batch_size)\n",
    "test_data_loader=DataLoader(val_data,shuffle=True,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(_LRScheduler):\n",
    "    \n",
    "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
    "        assert callable(schedule)\n",
    "        self.schedule = schedule\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(t_max, eta_min=0):\n",
    "    \n",
    "    def scheduler(epoch, base_lr):\n",
    "        t = epoch % t_max\n",
    "        return eta_min + (base_lr - eta_min)*(1 + np.cos(np.pi*t/t_max))/2\n",
    "    \n",
    "    return scheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_dim = 24\n",
    "        self.hidden_dim = 250\n",
    "        self.L=64\n",
    "        self.layer_dim = 3\n",
    "        self.output_dim=1\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.rnn = nn.LSTM(self.input_dim, self.hidden_dim, self.layer_dim, batch_first=True)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.L),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.L, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0, c0 = self.init_hidden(x)\n",
    "        out, (hn, cn) = self.rnn(x, (h0, c0))\n",
    "\n",
    "        A = self.attention(out) \n",
    "        A = torch.transpose(A, 2,1)  \n",
    "        A = F.softmax(A, dim=2) \n",
    "#         print(A.shape)\n",
    "        M = torch.matmul(A, out) .squeeze(1)\n",
    "#         print(M.shape)\n",
    "        out=self.fc1(M)\n",
    "#         print(out.shape)\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        return [t.cuda() for t in (h0, c0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_data_loader):\n",
    "    best_acc1 = 0\n",
    "    modelname=[]\n",
    "    truth=[]\n",
    "    preds=[]\n",
    "    model.train()\n",
    "    total=len(train_data_loader)*batch_size\n",
    "    train_loss = 0.\n",
    "    for minibatch in train_data_loader:\n",
    "        X, Y1  = minibatch\n",
    "        X=X.cuda()\n",
    "        Y1=Y1.cuda()\n",
    "        output = model(X.float())\n",
    "        output=output.squeeze(1)\n",
    "        loss = loss_func(output, Y1.float())\n",
    "        Y_hat1 = torch.ge(output, 0.5).float()\n",
    "        train_loss += loss.item()\n",
    "        truth.extend(Y1.tolist())\n",
    "        preds.extend(Y_hat1.tolist())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sched.step()\n",
    "    trainacc1=accuracy_score(truth,preds)\n",
    "    train_loss /= total\n",
    "    print(\"EPOCH \",it)\n",
    "    print('Train : Loss: {:.4f}, Train acc1 : {:.4f}'.format(train_loss,trainacc1))\n",
    "\n",
    "def evalue(model,best_acc1,val_data_loader,modelname,it):\n",
    "    count=0\n",
    "    val_loss= 0.\n",
    "    truth=[]\n",
    "    preds=[]\n",
    "    total=len(val_data_loader)*batch_size\n",
    "    model.eval()\n",
    "    best_model=\"./saved_models/best_model_fs\"\n",
    "    for minibatch in val_data_loader:\n",
    "        X_valid, Y1_valid  = minibatch\n",
    "        X_valid=X_valid.cuda()\n",
    "        Y1_valid=Y1_valid.cuda()\n",
    "        output_val = model(X_valid.float())\n",
    "        output_val=output_val.squeeze(1)\n",
    "        loss = loss_func(output_val, Y1_valid.float())\n",
    "        Y_hat1_val = torch.ge(output_val, 0.5).float()\n",
    "        val_loss += loss.item()\n",
    "        truth.extend(Y1_valid.tolist())\n",
    "        preds.extend(Y_hat1_val.tolist())\n",
    "    valacc1=accuracy_score(truth,preds)\n",
    "    val_loss /= total\n",
    "    print('Val : Loss: {:.4f}, Val acc1 : {:.4f}'.format(val_loss,valacc1))\n",
    "    if valacc1 >= best_acc1:\n",
    "        best_acc1 = valacc1\n",
    "        best_state = model.state_dict()\n",
    "        torch.save(best_state, best_model+'_epoch_'+str(it)+\".pth\")\n",
    "        modelname.append(best_model+'_epoch_'+str(it)+\".pth\")\n",
    "        print('Best validation accuracy1 ', best_acc1)\n",
    "    return best_acc1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = 24\n",
    "shared_layer_size = 512\n",
    "LR = 0.0001\n",
    "epoch = 100\n",
    "model=Classifier()\n",
    "model.cuda()\n",
    "iterations_per_epoch = len(train_data_loader)\n",
    "loss_func = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "sched = CyclicLR(optimizer, cosine(t_max=iterations_per_epoch * 2, eta_min=LR/100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0\n",
      "Train : Loss: 0.0345, Train acc1 : 0.5254\n",
      "Val : Loss: 0.0350, Val acc1 : 0.4316\n",
      "Best validation accuracy1  0.43157894736842106\n",
      "EPOCH  1\n",
      "Train : Loss: 0.0344, Train acc1 : 0.5406\n",
      "Val : Loss: 0.0353, Val acc1 : 0.4316\n",
      "Best validation accuracy1  0.43157894736842106\n",
      "EPOCH  2\n",
      "Train : Loss: 0.0339, Train acc1 : 0.5584\n",
      "Val : Loss: 0.0361, Val acc1 : 0.4368\n",
      "Best validation accuracy1  0.4368421052631579\n",
      "EPOCH  3\n",
      "Train : Loss: 0.0332, Train acc1 : 0.5718\n",
      "Val : Loss: 0.0353, Val acc1 : 0.5316\n",
      "Best validation accuracy1  0.531578947368421\n",
      "EPOCH  4\n",
      "Train : Loss: 0.0322, Train acc1 : 0.5825\n",
      "Val : Loss: 0.0358, Val acc1 : 0.4895\n",
      "EPOCH  5\n",
      "Train : Loss: 0.0310, Train acc1 : 0.6039\n",
      "Val : Loss: 0.0399, Val acc1 : 0.5368\n",
      "Best validation accuracy1  0.5368421052631579\n",
      "EPOCH  6\n",
      "Train : Loss: 0.0309, Train acc1 : 0.6218\n",
      "Val : Loss: 0.0379, Val acc1 : 0.5158\n",
      "EPOCH  7\n",
      "Train : Loss: 0.0294, Train acc1 : 0.6494\n",
      "Val : Loss: 0.0412, Val acc1 : 0.5211\n",
      "EPOCH  8\n",
      "Train : Loss: 0.0302, Train acc1 : 0.6343\n",
      "Val : Loss: 0.0402, Val acc1 : 0.4895\n",
      "EPOCH  9\n",
      "Train : Loss: 0.0287, Train acc1 : 0.6664\n",
      "Val : Loss: 0.0404, Val acc1 : 0.4895\n",
      "EPOCH  10\n",
      "Train : Loss: 0.0283, Train acc1 : 0.6628\n",
      "Val : Loss: 0.0431, Val acc1 : 0.4526\n",
      "EPOCH  11\n",
      "Train : Loss: 0.0278, Train acc1 : 0.6949\n",
      "Val : Loss: 0.0431, Val acc1 : 0.4947\n",
      "EPOCH  12\n",
      "Train : Loss: 0.0281, Train acc1 : 0.6949\n",
      "Val : Loss: 0.0439, Val acc1 : 0.4368\n",
      "EPOCH  13\n",
      "Train : Loss: 0.0262, Train acc1 : 0.7244\n",
      "Val : Loss: 0.0463, Val acc1 : 0.4789\n",
      "EPOCH  14\n",
      "Train : Loss: 0.0269, Train acc1 : 0.7029\n",
      "Val : Loss: 0.0461, Val acc1 : 0.4789\n",
      "EPOCH  15\n",
      "Train : Loss: 0.0259, Train acc1 : 0.7377\n",
      "Val : Loss: 0.0485, Val acc1 : 0.4789\n",
      "EPOCH  16\n",
      "Train : Loss: 0.0277, Train acc1 : 0.6824\n",
      "Val : Loss: 0.0451, Val acc1 : 0.4684\n",
      "EPOCH  17\n",
      "Train : Loss: 0.0261, Train acc1 : 0.7342\n",
      "Val : Loss: 0.0469, Val acc1 : 0.4842\n",
      "EPOCH  18\n",
      "Train : Loss: 0.0268, Train acc1 : 0.7056\n",
      "Val : Loss: 0.0485, Val acc1 : 0.4368\n",
      "EPOCH  19\n",
      "Train : Loss: 0.0240, Train acc1 : 0.7502\n",
      "Val : Loss: 0.0539, Val acc1 : 0.4211\n",
      "EPOCH  20\n",
      "Train : Loss: 0.0276, Train acc1 : 0.6842\n",
      "Val : Loss: 0.0484, Val acc1 : 0.4842\n",
      "EPOCH  21\n",
      "Train : Loss: 0.0241, Train acc1 : 0.7565\n",
      "Val : Loss: 0.0542, Val acc1 : 0.4579\n",
      "EPOCH  22\n",
      "Train : Loss: 0.0253, Train acc1 : 0.7315\n",
      "Val : Loss: 0.0524, Val acc1 : 0.4895\n",
      "EPOCH  23\n",
      "Train : Loss: 0.0228, Train acc1 : 0.7565\n",
      "Val : Loss: 0.0527, Val acc1 : 0.4526\n",
      "EPOCH  24\n",
      "Train : Loss: 0.0229, Train acc1 : 0.7645\n",
      "Val : Loss: 0.0551, Val acc1 : 0.4000\n",
      "EPOCH  25\n",
      "Train : Loss: 0.0223, Train acc1 : 0.7779\n",
      "Val : Loss: 0.0603, Val acc1 : 0.4421\n",
      "EPOCH  26\n",
      "Train : Loss: 0.0250, Train acc1 : 0.7288\n",
      "Val : Loss: 0.0589, Val acc1 : 0.5053\n",
      "EPOCH  27\n",
      "Train : Loss: 0.0222, Train acc1 : 0.7707\n",
      "Val : Loss: 0.0597, Val acc1 : 0.4579\n",
      "EPOCH  28\n",
      "Train : Loss: 0.0225, Train acc1 : 0.7609\n",
      "Val : Loss: 0.0630, Val acc1 : 0.4211\n",
      "EPOCH  29\n",
      "Train : Loss: 0.0207, Train acc1 : 0.7948\n",
      "Val : Loss: 0.0672, Val acc1 : 0.4474\n",
      "EPOCH  30\n",
      "Train : Loss: 0.0249, Train acc1 : 0.7743\n",
      "Val : Loss: 0.0662, Val acc1 : 0.4211\n",
      "EPOCH  31\n",
      "Train : Loss: 0.0209, Train acc1 : 0.7850\n",
      "Val : Loss: 0.0582, Val acc1 : 0.4421\n",
      "EPOCH  32\n",
      "Train : Loss: 0.0213, Train acc1 : 0.7841\n",
      "Val : Loss: 0.0647, Val acc1 : 0.4947\n",
      "EPOCH  33\n",
      "Train : Loss: 0.0201, Train acc1 : 0.7895\n",
      "Val : Loss: 0.0660, Val acc1 : 0.4368\n",
      "EPOCH  34\n",
      "Train : Loss: 0.0198, Train acc1 : 0.7984\n",
      "Val : Loss: 0.0710, Val acc1 : 0.3789\n",
      "EPOCH  35\n",
      "Train : Loss: 0.0182, Train acc1 : 0.8082\n",
      "Val : Loss: 0.0752, Val acc1 : 0.4211\n",
      "EPOCH  36\n",
      "Train : Loss: 0.0196, Train acc1 : 0.7806\n",
      "Val : Loss: 0.0764, Val acc1 : 0.4632\n",
      "EPOCH  37\n",
      "Train : Loss: 0.0182, Train acc1 : 0.8198\n",
      "Val : Loss: 0.0770, Val acc1 : 0.4158\n",
      "EPOCH  38\n",
      "Train : Loss: 0.0199, Train acc1 : 0.7868\n",
      "Val : Loss: 0.0715, Val acc1 : 0.4368\n",
      "EPOCH  39\n",
      "Train : Loss: 0.0182, Train acc1 : 0.8198\n",
      "Val : Loss: 0.0752, Val acc1 : 0.4263\n",
      "EPOCH  40\n",
      "Train : Loss: 0.0223, Train acc1 : 0.7315\n",
      "Val : Loss: 0.0650, Val acc1 : 0.3947\n",
      "EPOCH  41\n",
      "Train : Loss: 0.0199, Train acc1 : 0.7797\n",
      "Val : Loss: 0.0688, Val acc1 : 0.4000\n",
      "EPOCH  42\n",
      "Train : Loss: 0.0220, Train acc1 : 0.7743\n",
      "Val : Loss: 0.0679, Val acc1 : 0.3789\n",
      "EPOCH  43\n",
      "Train : Loss: 0.0175, Train acc1 : 0.8243\n",
      "Val : Loss: 0.0792, Val acc1 : 0.3737\n",
      "EPOCH  44\n",
      "Train : Loss: 0.0187, Train acc1 : 0.8109\n",
      "Val : Loss: 0.0785, Val acc1 : 0.4000\n",
      "EPOCH  45\n",
      "Train : Loss: 0.0165, Train acc1 : 0.8252\n",
      "Val : Loss: 0.0818, Val acc1 : 0.3737\n",
      "EPOCH  46\n",
      "Train : Loss: 0.0177, Train acc1 : 0.8162\n",
      "Val : Loss: 0.0868, Val acc1 : 0.4316\n",
      "EPOCH  47\n",
      "Train : Loss: 0.0165, Train acc1 : 0.8359\n",
      "Val : Loss: 0.0886, Val acc1 : 0.3789\n",
      "EPOCH  48\n",
      "Train : Loss: 0.0184, Train acc1 : 0.8073\n",
      "Val : Loss: 0.0889, Val acc1 : 0.3895\n",
      "EPOCH  49\n",
      "Train : Loss: 0.0155, Train acc1 : 0.8403\n",
      "Val : Loss: 0.0955, Val acc1 : 0.3947\n",
      "EPOCH  50\n",
      "Train : Loss: 0.0156, Train acc1 : 0.8323\n",
      "Val : Loss: 0.0930, Val acc1 : 0.4000\n",
      "EPOCH  51\n",
      "Train : Loss: 0.0160, Train acc1 : 0.8243\n",
      "Val : Loss: 0.0898, Val acc1 : 0.4158\n",
      "EPOCH  52\n",
      "Train : Loss: 0.0164, Train acc1 : 0.8180\n",
      "Val : Loss: 0.0903, Val acc1 : 0.4211\n",
      "EPOCH  53\n",
      "Train : Loss: 0.0152, Train acc1 : 0.8385\n",
      "Val : Loss: 0.0970, Val acc1 : 0.4000\n",
      "EPOCH  54\n",
      "Train : Loss: 0.0170, Train acc1 : 0.8198\n",
      "Val : Loss: 0.0981, Val acc1 : 0.4211\n",
      "EPOCH  55\n",
      "Train : Loss: 0.0153, Train acc1 : 0.8403\n",
      "Val : Loss: 0.1043, Val acc1 : 0.3895\n",
      "EPOCH  56\n",
      "Train : Loss: 0.0165, Train acc1 : 0.8314\n",
      "Val : Loss: 0.0904, Val acc1 : 0.3895\n",
      "EPOCH  57\n",
      "Train : Loss: 0.0145, Train acc1 : 0.8350\n",
      "Val : Loss: 0.1007, Val acc1 : 0.3895\n",
      "EPOCH  58\n",
      "Train : Loss: 0.0156, Train acc1 : 0.8368\n",
      "Val : Loss: 0.0920, Val acc1 : 0.4526\n",
      "EPOCH  59\n",
      "Train : Loss: 0.0139, Train acc1 : 0.8599\n",
      "Val : Loss: 0.1022, Val acc1 : 0.4105\n",
      "EPOCH  60\n",
      "Train : Loss: 0.0159, Train acc1 : 0.8323\n",
      "Val : Loss: 0.0990, Val acc1 : 0.4053\n",
      "EPOCH  61\n",
      "Train : Loss: 0.0133, Train acc1 : 0.8617\n",
      "Val : Loss: 0.1052, Val acc1 : 0.4263\n",
      "EPOCH  62\n",
      "Train : Loss: 0.0148, Train acc1 : 0.8564\n",
      "Val : Loss: 0.1064, Val acc1 : 0.3684\n",
      "EPOCH  63\n",
      "Train : Loss: 0.0205, Train acc1 : 0.7993\n",
      "Val : Loss: 0.0828, Val acc1 : 0.3789\n",
      "EPOCH  64\n",
      "Train : Loss: 0.0148, Train acc1 : 0.8519\n",
      "Val : Loss: 0.1040, Val acc1 : 0.3895\n",
      "EPOCH  65\n",
      "Train : Loss: 0.0133, Train acc1 : 0.8662\n",
      "Val : Loss: 0.0959, Val acc1 : 0.3947\n",
      "EPOCH  66\n",
      "Train : Loss: 0.0136, Train acc1 : 0.8573\n",
      "Val : Loss: 0.1007, Val acc1 : 0.4368\n",
      "EPOCH  67\n",
      "Train : Loss: 0.0123, Train acc1 : 0.8733\n",
      "Val : Loss: 0.1114, Val acc1 : 0.4211\n",
      "EPOCH  68\n",
      "Train : Loss: 0.0148, Train acc1 : 0.8519\n",
      "Val : Loss: 0.1102, Val acc1 : 0.3947\n",
      "EPOCH  69\n",
      "Train : Loss: 0.0115, Train acc1 : 0.8715\n",
      "Val : Loss: 0.1182, Val acc1 : 0.4000\n",
      "EPOCH  70\n",
      "Train : Loss: 0.0137, Train acc1 : 0.8546\n",
      "Val : Loss: 0.1042, Val acc1 : 0.3789\n",
      "EPOCH  71\n",
      "Train : Loss: 0.0126, Train acc1 : 0.8742\n",
      "Val : Loss: 0.1144, Val acc1 : 0.3842\n",
      "EPOCH  72\n",
      "Train : Loss: 0.0134, Train acc1 : 0.8475\n",
      "Val : Loss: 0.1129, Val acc1 : 0.3947\n",
      "EPOCH  73\n",
      "Train : Loss: 0.0116, Train acc1 : 0.8742\n",
      "Val : Loss: 0.1238, Val acc1 : 0.3526\n",
      "EPOCH  74\n",
      "Train : Loss: 0.0117, Train acc1 : 0.8707\n",
      "Val : Loss: 0.1223, Val acc1 : 0.4053\n",
      "EPOCH  75\n",
      "Train : Loss: 0.0116, Train acc1 : 0.8796\n",
      "Val : Loss: 0.1271, Val acc1 : 0.3895\n",
      "EPOCH  76\n",
      "Train : Loss: 0.0137, Train acc1 : 0.8582\n",
      "Val : Loss: 0.1048, Val acc1 : 0.4158\n",
      "EPOCH  77\n",
      "Train : Loss: 0.0114, Train acc1 : 0.8733\n",
      "Val : Loss: 0.1219, Val acc1 : 0.4105\n",
      "EPOCH  78\n",
      "Train : Loss: 0.0128, Train acc1 : 0.8733\n",
      "Val : Loss: 0.1148, Val acc1 : 0.4263\n",
      "EPOCH  79\n",
      "Train : Loss: 0.0107, Train acc1 : 0.8849\n",
      "Val : Loss: 0.1218, Val acc1 : 0.4053\n",
      "EPOCH  80\n",
      "Train : Loss: 0.0115, Train acc1 : 0.8831\n",
      "Val : Loss: 0.1215, Val acc1 : 0.4105\n",
      "EPOCH  81\n",
      "Train : Loss: 0.0106, Train acc1 : 0.8849\n",
      "Val : Loss: 0.1353, Val acc1 : 0.3947\n",
      "EPOCH  82\n",
      "Train : Loss: 0.0145, Train acc1 : 0.8510\n",
      "Val : Loss: 0.1090, Val acc1 : 0.4316\n",
      "EPOCH  83\n",
      "Train : Loss: 0.0111, Train acc1 : 0.8822\n",
      "Val : Loss: 0.1146, Val acc1 : 0.4053\n",
      "EPOCH  84\n",
      "Train : Loss: 0.0112, Train acc1 : 0.8930\n",
      "Val : Loss: 0.1221, Val acc1 : 0.3895\n",
      "EPOCH  85\n",
      "Train : Loss: 0.0097, Train acc1 : 0.8983\n",
      "Val : Loss: 0.1295, Val acc1 : 0.3789\n",
      "EPOCH  86\n",
      "Train : Loss: 0.0123, Train acc1 : 0.8751\n",
      "Val : Loss: 0.1161, Val acc1 : 0.3842\n",
      "EPOCH  87\n",
      "Train : Loss: 0.0101, Train acc1 : 0.8921\n",
      "Val : Loss: 0.1197, Val acc1 : 0.4053\n",
      "EPOCH  88\n",
      "Train : Loss: 0.0108, Train acc1 : 0.8930\n",
      "Val : Loss: 0.1243, Val acc1 : 0.4053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  89\n",
      "Train : Loss: 0.0086, Train acc1 : 0.9126\n",
      "Val : Loss: 0.1364, Val acc1 : 0.3947\n",
      "EPOCH  90\n",
      "Train : Loss: 0.0149, Train acc1 : 0.8492\n",
      "Val : Loss: 0.1209, Val acc1 : 0.4474\n",
      "EPOCH  91\n",
      "Train : Loss: 0.0127, Train acc1 : 0.8724\n",
      "Val : Loss: 0.1093, Val acc1 : 0.4158\n",
      "EPOCH  92\n",
      "Train : Loss: 0.0111, Train acc1 : 0.8921\n",
      "Val : Loss: 0.1391, Val acc1 : 0.3474\n",
      "EPOCH  93\n",
      "Train : Loss: 0.0091, Train acc1 : 0.8965\n",
      "Val : Loss: 0.1383, Val acc1 : 0.3737\n",
      "EPOCH  94\n",
      "Train : Loss: 0.0106, Train acc1 : 0.8965\n",
      "Val : Loss: 0.1296, Val acc1 : 0.4368\n",
      "EPOCH  95\n",
      "Train : Loss: 0.0088, Train acc1 : 0.9081\n",
      "Val : Loss: 0.1306, Val acc1 : 0.3895\n",
      "EPOCH  96\n",
      "Train : Loss: 0.0097, Train acc1 : 0.9099\n",
      "Val : Loss: 0.1433, Val acc1 : 0.3421\n",
      "EPOCH  97\n",
      "Train : Loss: 0.0085, Train acc1 : 0.9090\n",
      "Val : Loss: 0.1460, Val acc1 : 0.4000\n",
      "EPOCH  98\n",
      "Train : Loss: 0.0088, Train acc1 : 0.9045\n",
      "Val : Loss: 0.1619, Val acc1 : 0.3474\n",
      "EPOCH  99\n",
      "Train : Loss: 0.0076, Train acc1 : 0.9170\n",
      "Val : Loss: 0.1574, Val acc1 : 0.3579\n",
      "EPOCH  100\n",
      "Train : Loss: 0.0095, Train acc1 : 0.9019\n",
      "Val : Loss: 0.1456, Val acc1 : 0.3579\n"
     ]
    }
   ],
   "source": [
    "best_acc1=0\n",
    "modelname=[]\n",
    "for it in range(epoch+1):\n",
    "    train(model,train_data_loader)\n",
    "    best_acc1=evalue(model,best_acc1,val_data_loader,modelname,it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.56 0.57 0.51 0.64 0.57 0.50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "modeltest=Classifier()\n",
    "best_state=torch.load(modelname[-1])\n",
    "modeltest.load_state_dict(best_state)\n",
    "modeltest.cuda()\n",
    "modeltest.eval()\n",
    "truth=[]\n",
    "preds=[]\n",
    "for minibatch in test_data_loader:\n",
    "            X_test, Y1_test  = minibatch\n",
    "            X_test=X_test.cuda()\n",
    "            Y1_test=Y1_test.cuda()\n",
    "            output_test = modeltest(X_test.float())\n",
    "            output_test=output_test.squeeze(1)\n",
    "            prediction = torch.ge(output_test, 0.5).float()\n",
    "            truth.extend(Y1_test.tolist())\n",
    "            preds.extend(prediction.tolist())\n",
    "acc=accuracy_score(truth,preds)\n",
    "# print(truth,preds)\n",
    "tn, fp, fn, tp = confusion_matrix(truth, preds).ravel()\n",
    "f1score=f1_score(truth, preds)\n",
    "precision=precision_score(truth, preds)\n",
    "recall=recall_score(truth,preds)\n",
    "roc=roc_auc_score(truth,preds)\n",
    "specificity=tn/(tn+fp)\n",
    "\n",
    "print('{:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f}'.format(acc,f1score,precision,recall,roc,specificity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.62 0.45 1.00 0.50 0.00\n",
      "0.45 0.62 0.45 1.00 0.50 0.00\n",
      "0.44 0.61 0.44 0.97 0.48 0.00\n",
      "0.46 0.61 0.45 0.92 0.50 0.07\n",
      "0.56 0.57 0.51 0.64 0.57 0.50\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(modelname)):\n",
    "    modeltest=Classifier()\n",
    "    best_state=torch.load(modelname[i])\n",
    "    modeltest.load_state_dict(best_state)\n",
    "    modeltest.cuda()\n",
    "    modeltest.eval()\n",
    "    truth=[]\n",
    "    preds=[]\n",
    "    for minibatch in test_data_loader:\n",
    "                X_test, Y1_test  = minibatch\n",
    "                X_test=X_test.cuda()\n",
    "                Y1_test=Y1_test.cuda()\n",
    "                output_test = modeltest(X_test.float())\n",
    "                output_test=output_test.squeeze(1)\n",
    "                prediction = torch.ge(output_test, 0.5).float()\n",
    "                truth.extend(Y1_test.tolist())\n",
    "                preds.extend(prediction.tolist())\n",
    "    acc=accuracy_score(truth,preds)\n",
    "    # print(truth,preds)\n",
    "    tn, fp, fn, tp = confusion_matrix(truth, preds).ravel()\n",
    "    f1score=f1_score(truth, preds)\n",
    "    precision=precision_score(truth, preds)\n",
    "    recall=recall_score(truth,preds)\n",
    "    roc=roc_auc_score(truth,preds)\n",
    "    specificity=tn/(tn+fp)\n",
    "\n",
    "    print('{:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f}'.format(acc,f1score,precision,recall,roc,specificity))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (physio)",
   "language": "python",
   "name": "physio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
