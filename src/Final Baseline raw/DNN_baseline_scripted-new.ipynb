{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pylab\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "seed = 2021\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, X1, Y1):\n",
    "        self.X1 = X1\n",
    "        self.Y1 = Y1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.X1[index]\n",
    "        y1 = self.Y1[index]\n",
    "        return x, y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(24, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(38912, 256), #166400\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "                               \n",
    "    def forward(self, x):\n",
    "        \n",
    "        H=self.fc(x)\n",
    "        \n",
    "        Y_prob=self.fc2(H.reshape(H.size(0),-1))\n",
    "\n",
    "        return Y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "class CyclicLR(_LRScheduler):\n",
    "    \n",
    "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
    "        assert callable(schedule)\n",
    "        self.schedule = schedule\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(t_max, eta_min=0):\n",
    "    \n",
    "    def scheduler(epoch, base_lr):\n",
    "        t = epoch % t_max\n",
    "        return eta_min + (base_lr - eta_min)*(1 + np.cos(np.pi*t/t_max))/2\n",
    "    \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain=np.load(\"../extracted_features/0/GRP-3/input_features_train_grp3.npy\")\n",
    "yTrain=np.load(\"../extracted_features/0/GRP-3/labels_train_grp3.npy\")\n",
    "\n",
    "xTest=np.load(\"../extracted_features/0/GRP-3/input_features_test_grp3.npy\")\n",
    "yTest=np.load(\"../extracted_features/0/GRP-3/labels_test_grp3.npy\")\n",
    "\n",
    "\n",
    "xVal=np.load(\"../extracted_features/0/GRP-3/input_features_val_grp3.npy\")\n",
    "yVal=np.load(\"../extracted_features/0/GRP-3/labels_val_grp3.npy\")\n",
    "\n",
    "train_features=np.load(\"../extracted_features/bl/0/GRP-3/input_features_train_grp3.npy\")\n",
    "labels_train=np.load(\"../extracted_features/bl/0/GRP-3/labels_train_grp3.npy\")\n",
    "\n",
    "test_features=np.load(\"../extracted_features/bl/0/GRP-3/input_features_test_grp3.npy\")\n",
    "labels_test=np.load(\"../extracted_features/bl/0/GRP-3/labels_test_grp3.npy\")\n",
    "\n",
    "val_features=np.load(\"../extracted_features/bl/0/GRP-3/input_features_val_grp3.npy\")\n",
    "labels_val=np.load(\"../extracted_features/bl/0/GRP-3/labels_val_grp3.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def readFeatures(path):\n",
    "    features=np.array([])\n",
    "    start=0\n",
    "    for file in os.listdir(path):\n",
    "        d = os.path.join(path, file)\n",
    "        datafile=d+\"/features.npy\"\n",
    "        try:\n",
    "            temp=np.load(datafile)\n",
    "#             print(datafile)\n",
    "#             print(temp.shape)\n",
    "            if(start==0):\n",
    "                features=temp\n",
    "                if(d[-10]=='S'):\n",
    "                    label=np.ones(len(temp))\n",
    "                else:\n",
    "                    label=np.zeros(len(temp))\n",
    "                start=1\n",
    "            else:\n",
    "                features=np.vstack((features,temp))\n",
    "                if(d[-10]=='S'):\n",
    "                    label=np.append(label,np.ones(len(temp)))\n",
    "                else:\n",
    "                    label=np.append(label,np.zeros(len(temp)))\n",
    "        except IOError:\n",
    "            print('file not in Scripted')\n",
    "\n",
    "            \n",
    "    return features,label\n",
    "\n",
    "def load_data(path,mode):\n",
    "    if mode == \"test\":\n",
    "        xTest,yTest=readFeatures(path+\"/\"+mode)\n",
    "        xTest = xTest.reshape(len(xTest),1,19,24)\n",
    "        return Dataset(xTest,yTest)\n",
    "        \n",
    "    elif mode == \"train\":\n",
    "        xTrain,yTrain=readFeatures(path+\"/\"+mode)\n",
    "        xTrain = xTrain.reshape(len(xTrain),1,19,24)\n",
    "        return Dataset(xTrain,yTrain)\n",
    "        \n",
    "    elif mode == \"val\":\n",
    "        xVal,yVal=readFeatures(path+\"/\"+mode)\n",
    "        xVal = xVal.reshape(len(xVal),1,19,24)\n",
    "        return Dataset(xVal,yVal)\n",
    "    else:\n",
    "        print(\"Mode not defined\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(yVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(497, 19, 24) (497,)\n",
      "(119, 19, 24) (119,)\n",
      "(110, 19, 24) (110,)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape,labels_train.shape)\n",
    "print(test_features.shape,labels_test.shape)\n",
    "print(val_features.shape,labels_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 19, 24) (512,)\n",
      "(122, 19, 24) (122,)\n",
      "(118, 19, 24) (118,)\n"
     ]
    }
   ],
   "source": [
    "print(xTrain.shape,yTrain.shape)\n",
    "print(xTest.shape,yTest.shape)\n",
    "print(xVal.shape,yVal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(497, 19, 24) (497,)\n",
      "(119, 19, 24) (119,)\n",
      "(110, 19, 24) (110,)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape,labels_train.shape)\n",
    "print(test_features.shape,labels_test.shape)\n",
    "print(val_features.shape,labels_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=train_features.reshape(len(train_features),1,19,24)\n",
    "test_features=test_features.reshape(len(test_features),1,19,24)\n",
    "val_features=val_features.reshape(len(val_features),1,19,24)\n",
    "\n",
    "xTrain = xTrain.reshape(len(xTrain),1,19,24)\n",
    "xTest = xTest.reshape(len(xTest),1,19,24)\n",
    "xVal = xVal.reshape(len(xVal),1,19,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xTrain=np.append(train_features,xTrain,axis=0)\n",
    "# xTest=np.append(test_features,xTest,axis=0)\n",
    "# xVal=np.append(val_features,xVal,axis=0)\n",
    "# yTrain=np.append(labels_train,yTrain,axis=0)\n",
    "# yTest=np.append(labels_test,yTest,axis=0)\n",
    "# yVal=np.append(labels_val,yVal,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=20\n",
    "\n",
    "train_data = load_data(\"../Participant_wise\",'train')\n",
    "test_data=load_data(\"../Participant_wise\",'test')\n",
    "val_data=load_data(\"../Participant_wise\",'val')\n",
    "\n",
    "# train_data = Dataset(train_features, labels_train)\n",
    "# test_data=Dataset(test_features,labels_test)\n",
    "# val_data=Dataset(val_features,labels_val)\n",
    "\n",
    "train_data_loader = DataLoader(train_data,worker_init_fn=seed_worker, shuffle=True, batch_size=batch_size)\n",
    "val_data_loader=DataLoader(val_data,worker_init_fn=seed_worker,shuffle=True,batch_size=batch_size)\n",
    "test_data_loader=DataLoader(test_data,worker_init_fn=seed_worker,shuffle=True,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = 24\n",
    "shared_layer_size = 512\n",
    "LR = 0.0001\n",
    "epoch = 100\n",
    "model=Classifier()\n",
    "model.cuda()\n",
    "iterations_per_epoch = len(train_data_loader)\n",
    "model.apply(init_weights)\n",
    "loss_func = nn.BCELoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=LR)\n",
    "sched = CyclicLR(optimizer, cosine(t_max=iterations_per_epoch * 2, eta_min=LR/100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# summary(model.cuda(),(19,24))\n",
    "# torch.save(model, \"modelarchitect_final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0\n",
      "Train : Loss: 0.0455, Train acc1 : 0.5000\n",
      "Val : Loss: 0.0402, Val acc1 : 0.6533\n",
      "Best validation accuracy1  0.6533333333333333\n",
      "EPOCH  1\n",
      "Train : Loss: 0.0308, Train acc1 : 0.6364\n",
      "Val : Loss: 0.0357, Val acc1 : 0.4800\n",
      "EPOCH  2\n",
      "Train : Loss: 0.0326, Train acc1 : 0.5832\n",
      "Val : Loss: 0.0334, Val acc1 : 0.4524\n",
      "EPOCH  3\n",
      "Train : Loss: 0.0271, Train acc1 : 0.6456\n",
      "Val : Loss: 0.0378, Val acc1 : 0.4255\n",
      "EPOCH  4\n",
      "Train : Loss: 0.0266, Train acc1 : 0.6632\n",
      "Val : Loss: 0.0337, Val acc1 : 0.5149\n",
      "EPOCH  5\n",
      "Train : Loss: 0.0263, Train acc1 : 0.6761\n",
      "Val : Loss: 0.0376, Val acc1 : 0.4444\n",
      "EPOCH  6\n",
      "Train : Loss: 0.0266, Train acc1 : 0.6538\n",
      "Val : Loss: 0.0379, Val acc1 : 0.4898\n",
      "EPOCH  7\n",
      "Train : Loss: 0.0228, Train acc1 : 0.7203\n",
      "Val : Loss: 0.0400, Val acc1 : 0.4330\n",
      "EPOCH  8\n",
      "Train : Loss: 0.0246, Train acc1 : 0.6975\n",
      "Val : Loss: 0.0467, Val acc1 : 0.4000\n",
      "EPOCH  9\n",
      "Train : Loss: 0.0205, Train acc1 : 0.7477\n",
      "Val : Loss: 0.0454, Val acc1 : 0.3542\n",
      "EPOCH  10\n",
      "Train : Loss: 0.0219, Train acc1 : 0.6908\n",
      "Val : Loss: 0.0757, Val acc1 : 0.0968\n",
      "EPOCH  11\n",
      "Train : Loss: 0.0185, Train acc1 : 0.7621\n",
      "Val : Loss: 0.0513, Val acc1 : 0.5254\n",
      "EPOCH  12\n",
      "Train : Loss: 0.0194, Train acc1 : 0.7496\n",
      "Val : Loss: 0.0488, Val acc1 : 0.4950\n",
      "EPOCH  13\n",
      "Train : Loss: 0.0165, Train acc1 : 0.7922\n",
      "Val : Loss: 0.0501, Val acc1 : 0.4860\n",
      "EPOCH  14\n",
      "Train : Loss: 0.0197, Train acc1 : 0.7465\n",
      "Val : Loss: 0.0582, Val acc1 : 0.4528\n",
      "EPOCH  15\n",
      "Train : Loss: 0.0147, Train acc1 : 0.8021\n",
      "Val : Loss: 0.0563, Val acc1 : 0.4752\n",
      "EPOCH  16\n",
      "Train : Loss: 0.0162, Train acc1 : 0.7917\n",
      "Val : Loss: 0.0642, Val acc1 : 0.3143\n",
      "EPOCH  17\n",
      "Train : Loss: 0.0132, Train acc1 : 0.8312\n",
      "Val : Loss: 0.0548, Val acc1 : 0.4706\n",
      "EPOCH  18\n",
      "Train : Loss: 0.0135, Train acc1 : 0.8091\n",
      "Val : Loss: 0.0864, Val acc1 : 0.1212\n",
      "EPOCH  19\n",
      "Train : Loss: 0.0123, Train acc1 : 0.8060\n",
      "Val : Loss: 0.0567, Val acc1 : 0.5321\n",
      "EPOCH  20\n",
      "Train : Loss: 0.0133, Train acc1 : 0.8048\n",
      "Val : Loss: 0.0801, Val acc1 : 0.5882\n",
      "EPOCH  21\n",
      "Train : Loss: 0.0107, Train acc1 : 0.8389\n",
      "Val : Loss: 0.0593, Val acc1 : 0.4660\n",
      "EPOCH  22\n",
      "Train : Loss: 0.0134, Train acc1 : 0.8215\n",
      "Val : Loss: 0.0475, Val acc1 : 0.6942\n",
      "Best validation accuracy1  0.6942148760330579\n",
      "EPOCH  23\n",
      "Train : Loss: 0.0094, Train acc1 : 0.8941\n",
      "Val : Loss: 0.0644, Val acc1 : 0.5049\n",
      "EPOCH  24\n",
      "Train : Loss: 0.0130, Train acc1 : 0.8180\n",
      "Val : Loss: 0.0547, Val acc1 : 0.5149\n",
      "EPOCH  25\n",
      "Train : Loss: 0.0076, Train acc1 : 0.8824\n",
      "Val : Loss: 0.0590, Val acc1 : 0.5333\n",
      "EPOCH  26\n",
      "Train : Loss: 0.0107, Train acc1 : 0.8434\n",
      "Val : Loss: 0.0885, Val acc1 : 0.3056\n",
      "EPOCH  27\n",
      "Train : Loss: 0.0085, Train acc1 : 0.8613\n",
      "Val : Loss: 0.0639, Val acc1 : 0.5091\n",
      "EPOCH  28\n",
      "Train : Loss: 0.0079, Train acc1 : 0.8722\n",
      "Val : Loss: 0.0579, Val acc1 : 0.6667\n",
      "EPOCH  29\n",
      "Train : Loss: 0.0071, Train acc1 : 0.8970\n",
      "Val : Loss: 0.0660, Val acc1 : 0.4600\n",
      "EPOCH  30\n",
      "Train : Loss: 0.0087, Train acc1 : 0.8456\n",
      "Val : Loss: 0.0962, Val acc1 : 0.2051\n",
      "EPOCH  31\n",
      "Train : Loss: 0.0068, Train acc1 : 0.8577\n",
      "Val : Loss: 0.0593, Val acc1 : 0.5370\n",
      "EPOCH  32\n",
      "Train : Loss: 0.0099, Train acc1 : 0.8537\n",
      "Val : Loss: 0.0809, Val acc1 : 0.2381\n",
      "EPOCH  33\n",
      "Train : Loss: 0.0059, Train acc1 : 0.8714\n",
      "Val : Loss: 0.0605, Val acc1 : 0.4615\n",
      "EPOCH  34\n",
      "Train : Loss: 0.0074, Train acc1 : 0.8601\n",
      "Val : Loss: 0.0707, Val acc1 : 0.3294\n",
      "EPOCH  35\n",
      "Train : Loss: 0.0056, Train acc1 : 0.8821\n",
      "Val : Loss: 0.0583, Val acc1 : 0.4906\n",
      "EPOCH  36\n",
      "Train : Loss: 0.0074, Train acc1 : 0.8679\n",
      "Val : Loss: 0.0489, Val acc1 : 0.6271\n",
      "EPOCH  37\n",
      "Train : Loss: 0.0042, Train acc1 : 0.9146\n",
      "Val : Loss: 0.0614, Val acc1 : 0.4906\n",
      "EPOCH  38\n",
      "Train : Loss: 0.0058, Train acc1 : 0.8814\n",
      "Val : Loss: 0.0623, Val acc1 : 0.6912\n",
      "EPOCH  39\n",
      "Train : Loss: 0.0043, Train acc1 : 0.9145\n",
      "Val : Loss: 0.0715, Val acc1 : 0.4444\n",
      "EPOCH  40\n",
      "Train : Loss: 0.0057, Train acc1 : 0.8657\n",
      "Val : Loss: 0.0893, Val acc1 : 0.3590\n",
      "EPOCH  41\n",
      "Train : Loss: 0.0052, Train acc1 : 0.8909\n",
      "Val : Loss: 0.0626, Val acc1 : 0.4854\n",
      "EPOCH  42\n",
      "Train : Loss: 0.0074, Train acc1 : 0.8684\n",
      "Val : Loss: 0.1482, Val acc1 : 0.0923\n",
      "EPOCH  43\n",
      "Train : Loss: 0.0042, Train acc1 : 0.8715\n",
      "Val : Loss: 0.0737, Val acc1 : 0.4400\n",
      "EPOCH  44\n",
      "Train : Loss: 0.0053, Train acc1 : 0.8754\n",
      "Val : Loss: 0.0682, Val acc1 : 0.4762\n",
      "EPOCH  45\n",
      "Train : Loss: 0.0037, Train acc1 : 0.8962\n",
      "Val : Loss: 0.0671, Val acc1 : 0.5098\n",
      "EPOCH  46\n",
      "Train : Loss: 0.0036, Train acc1 : 0.9047\n",
      "Val : Loss: 0.0629, Val acc1 : 0.6610\n",
      "EPOCH  47\n",
      "Train : Loss: 0.0028, Train acc1 : 0.9259\n",
      "Val : Loss: 0.0735, Val acc1 : 0.4752\n",
      "EPOCH  48\n",
      "Train : Loss: 0.0036, Train acc1 : 0.8990\n",
      "Val : Loss: 0.0695, Val acc1 : 0.6034\n",
      "EPOCH  49\n",
      "Train : Loss: 0.0022, Train acc1 : 0.9207\n",
      "Val : Loss: 0.0701, Val acc1 : 0.5000\n",
      "EPOCH  50\n",
      "Train : Loss: 0.0027, Train acc1 : 0.9034\n",
      "Val : Loss: 0.0804, Val acc1 : 0.4000\n",
      "EPOCH  51\n",
      "Train : Loss: 0.0025, Train acc1 : 0.9000\n",
      "Val : Loss: 0.0633, Val acc1 : 0.5913\n",
      "EPOCH  52\n",
      "Train : Loss: 0.0038, Train acc1 : 0.9100\n",
      "Val : Loss: 0.0745, Val acc1 : 0.5047\n",
      "EPOCH  53\n",
      "Train : Loss: 0.0028, Train acc1 : 0.9003\n",
      "Val : Loss: 0.0697, Val acc1 : 0.5536\n",
      "EPOCH  54\n",
      "Train : Loss: 0.0036, Train acc1 : 0.8957\n",
      "Val : Loss: 0.0729, Val acc1 : 0.6571\n",
      "EPOCH  55\n",
      "Train : Loss: 0.0038, Train acc1 : 0.9002\n",
      "Val : Loss: 0.0617, Val acc1 : 0.5234\n",
      "EPOCH  56\n",
      "Train : Loss: 0.0023, Train acc1 : 0.9072\n",
      "Val : Loss: 0.0783, Val acc1 : 0.6992\n",
      "Best validation accuracy1  0.6991869918699186\n",
      "EPOCH  57\n",
      "Train : Loss: 0.0024, Train acc1 : 0.9365\n",
      "Val : Loss: 0.0692, Val acc1 : 0.4706\n",
      "EPOCH  58\n",
      "Train : Loss: 0.0039, Train acc1 : 0.8873\n",
      "Val : Loss: 0.1292, Val acc1 : 0.3000\n",
      "EPOCH  59\n",
      "Train : Loss: 0.0027, Train acc1 : 0.8901\n",
      "Val : Loss: 0.0785, Val acc1 : 0.5437\n",
      "EPOCH  60\n",
      "Train : Loss: 0.0025, Train acc1 : 0.9132\n",
      "Val : Loss: 0.0912, Val acc1 : 0.4301\n",
      "EPOCH  61\n",
      "Train : Loss: 0.0025, Train acc1 : 0.9049\n",
      "Val : Loss: 0.0698, Val acc1 : 0.5524\n",
      "EPOCH  62\n",
      "Train : Loss: 0.0036, Train acc1 : 0.9107\n",
      "Val : Loss: 0.0608, Val acc1 : 0.6772\n",
      "EPOCH  63\n",
      "Train : Loss: 0.0027, Train acc1 : 0.9195\n",
      "Val : Loss: 0.0745, Val acc1 : 0.5208\n",
      "EPOCH  64\n",
      "Train : Loss: 0.0027, Train acc1 : 0.9091\n",
      "Val : Loss: 0.0756, Val acc1 : 0.6271\n",
      "EPOCH  65\n",
      "Train : Loss: 0.0018, Train acc1 : 0.9241\n",
      "Val : Loss: 0.0851, Val acc1 : 0.4536\n",
      "EPOCH  66\n",
      "Train : Loss: 0.0019, Train acc1 : 0.8990\n",
      "Val : Loss: 0.1025, Val acc1 : 0.4510\n",
      "EPOCH  67\n",
      "Train : Loss: 0.0023, Train acc1 : 0.8962\n",
      "Val : Loss: 0.0916, Val acc1 : 0.4646\n",
      "EPOCH  68\n",
      "Train : Loss: 0.0025, Train acc1 : 0.8947\n",
      "Val : Loss: 0.1030, Val acc1 : 0.2500\n",
      "EPOCH  69\n",
      "Train : Loss: 0.0021, Train acc1 : 0.8861\n",
      "Val : Loss: 0.0689, Val acc1 : 0.5192\n",
      "EPOCH  70\n",
      "Train : Loss: 0.0044, Train acc1 : 0.8819\n",
      "Val : Loss: 0.1015, Val acc1 : 0.4138\n",
      "EPOCH  71\n",
      "Train : Loss: 0.0022, Train acc1 : 0.9023\n",
      "Val : Loss: 0.0799, Val acc1 : 0.4950\n",
      "EPOCH  72\n",
      "Train : Loss: 0.0022, Train acc1 : 0.9097\n",
      "Val : Loss: 0.0885, Val acc1 : 0.4583\n",
      "EPOCH  73\n",
      "Train : Loss: 0.0013, Train acc1 : 0.9072\n",
      "Val : Loss: 0.0802, Val acc1 : 0.5149\n",
      "EPOCH  74\n",
      "Train : Loss: 0.0033, Train acc1 : 0.8977\n",
      "Val : Loss: 0.1245, Val acc1 : 0.3200\n",
      "EPOCH  75\n",
      "Train : Loss: 0.0017, Train acc1 : 0.9055\n",
      "Val : Loss: 0.0855, Val acc1 : 0.5283\n",
      "EPOCH  76\n",
      "Train : Loss: 0.0026, Train acc1 : 0.9069\n",
      "Val : Loss: 0.1031, Val acc1 : 0.2254\n",
      "EPOCH  77\n",
      "Train : Loss: 0.0015, Train acc1 : 0.8974\n",
      "Val : Loss: 0.0710, Val acc1 : 0.5370\n",
      "EPOCH  78\n",
      "Train : Loss: 0.0015, Train acc1 : 0.9125\n",
      "Val : Loss: 0.0740, Val acc1 : 0.5049\n",
      "EPOCH  79\n",
      "Train : Loss: 0.0016, Train acc1 : 0.9085\n",
      "Val : Loss: 0.0766, Val acc1 : 0.4898\n",
      "EPOCH  80\n",
      "Train : Loss: 0.0016, Train acc1 : 0.9094\n",
      "Val : Loss: 0.0703, Val acc1 : 0.7031\n",
      "Best validation accuracy1  0.703125\n",
      "EPOCH  81\n",
      "Train : Loss: 0.0015, Train acc1 : 0.9338\n",
      "Val : Loss: 0.0733, Val acc1 : 0.4792\n",
      "EPOCH  82\n",
      "Train : Loss: 0.0026, Train acc1 : 0.8995\n",
      "Val : Loss: 0.0729, Val acc1 : 0.4348\n",
      "EPOCH  83\n",
      "Train : Loss: 0.0015, Train acc1 : 0.9085\n",
      "Val : Loss: 0.0691, Val acc1 : 0.5333\n",
      "EPOCH  84\n",
      "Train : Loss: 0.0033, Train acc1 : 0.8977\n",
      "Val : Loss: 0.1162, Val acc1 : 0.3544\n",
      "EPOCH  85\n",
      "Train : Loss: 0.0013, Train acc1 : 0.9081\n",
      "Val : Loss: 0.0737, Val acc1 : 0.5283\n",
      "EPOCH  86\n",
      "Train : Loss: 0.0034, Train acc1 : 0.8916\n",
      "Val : Loss: 0.0904, Val acc1 : 0.3765\n",
      "EPOCH  87\n",
      "Train : Loss: 0.0019, Train acc1 : 0.8980\n",
      "Val : Loss: 0.0659, Val acc1 : 0.6422\n",
      "EPOCH  88\n",
      "Train : Loss: 0.0007, Train acc1 : 0.9333\n",
      "Val : Loss: 0.0743, Val acc1 : 0.5437\n",
      "EPOCH  89\n",
      "Train : Loss: 0.0010, Train acc1 : 0.9188\n",
      "Val : Loss: 0.0770, Val acc1 : 0.5794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  90\n",
      "Train : Loss: 0.0011, Train acc1 : 0.9191\n",
      "Val : Loss: 0.1075, Val acc1 : 0.4419\n",
      "EPOCH  91\n",
      "Train : Loss: 0.0012, Train acc1 : 0.9146\n",
      "Val : Loss: 0.0729, Val acc1 : 0.5905\n",
      "EPOCH  92\n",
      "Train : Loss: 0.0010, Train acc1 : 0.9260\n",
      "Val : Loss: 0.0703, Val acc1 : 0.6379\n",
      "EPOCH  93\n",
      "Train : Loss: 0.0010, Train acc1 : 0.9272\n",
      "Val : Loss: 0.0812, Val acc1 : 0.5577\n",
      "EPOCH  94\n",
      "Train : Loss: 0.0013, Train acc1 : 0.9160\n",
      "Val : Loss: 0.0703, Val acc1 : 0.5243\n",
      "EPOCH  95\n",
      "Train : Loss: 0.0020, Train acc1 : 0.9085\n",
      "Val : Loss: 0.0868, Val acc1 : 0.5294\n",
      "EPOCH  96\n",
      "Train : Loss: 0.0027, Train acc1 : 0.9081\n",
      "Val : Loss: 0.1237, Val acc1 : 0.3218\n",
      "EPOCH  97\n",
      "Train : Loss: 0.0015, Train acc1 : 0.8936\n",
      "Val : Loss: 0.0870, Val acc1 : 0.5094\n",
      "EPOCH  98\n",
      "Train : Loss: 0.0010, Train acc1 : 0.9072\n",
      "Val : Loss: 0.0806, Val acc1 : 0.6393\n",
      "EPOCH  99\n",
      "Train : Loss: 0.0007, Train acc1 : 0.9246\n",
      "Val : Loss: 0.0849, Val acc1 : 0.5098\n",
      "EPOCH  100\n",
      "Train : Loss: 0.0014, Train acc1 : 0.9119\n",
      "Val : Loss: 0.1634, Val acc1 : 0.1563\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "best_model = \"./saved_models/best_model_dnn_raw\"\n",
    "best_acc1 = 0\n",
    "# best_model1 = \"./saved_models/best_model_CNN_node3\"\n",
    "modelname=[]\n",
    "truth=[]\n",
    "preds=[]\n",
    "for it in range(epoch+1):\n",
    "    total=len(train_data_loader)*batch_size\n",
    "    train_loss = 0.\n",
    "    model.train()\n",
    "    for minibatch in train_data_loader:\n",
    "        X, Y1  = minibatch\n",
    "        X=X.cuda()\n",
    "        Y1=Y1.cuda()\n",
    "        output = model(X.float())\n",
    "        output=output.squeeze(1)\n",
    "        loss = loss_func(output, Y1.float())\n",
    "        Y_hat1 = torch.ge(output, 0.5).float()\n",
    "        train_loss += loss.item()\n",
    "        truth.extend(Y1.tolist())\n",
    "        preds.extend(Y_hat1.tolist())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sched.step()\n",
    "    trainacc1=f1_score(truth,preds)\n",
    "    train_loss /= total\n",
    "    print(\"EPOCH \",it)\n",
    "    print('Train : Loss: {:.4f}, Train acc1 : {:.4f}'.format(train_loss,trainacc1))\n",
    "    \n",
    "    count=0\n",
    "    val_loss= 0.\n",
    "    truth=[]\n",
    "    preds=[]\n",
    "    total=len(val_data_loader)*batch_size\n",
    "    model.eval()    \n",
    "    for minibatch in val_data_loader:\n",
    "        X_valid, Y1_valid  = minibatch\n",
    "        X_valid=X_valid.cuda()\n",
    "        Y1_valid=Y1_valid.cuda()\n",
    "        output_val = model(X_valid.float())\n",
    "        output_val=output_val.squeeze(1)\n",
    "        loss = loss_func(output_val, Y1_valid.float())\n",
    "        Y_hat1_val = torch.ge(output_val, 0.5).float()\n",
    "        val_loss += loss.item()\n",
    "        truth.extend(Y1_valid.tolist())\n",
    "        preds.extend(Y_hat1_val.tolist())\n",
    "    valacc1=f1_score(truth,preds)\n",
    "    val_loss /= total\n",
    "    print('Val : Loss: {:.4f}, Val acc1 : {:.4f}'.format(val_loss,valacc1))\n",
    "    if valacc1 >= best_acc1:\n",
    "        best_acc1 = valacc1\n",
    "        best_state = model.state_dict()\n",
    "        torch.save(best_state, best_model+'_epoch_'+str(epoch)+\".pth\")\n",
    "        modelname.append(best_model+'_epoch_'+str(epoch)+\".pth\")\n",
    "        print('Best validation accuracy1 ', best_acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.60 0.64 0.58 0.71 0.60 0.50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "modeltest=Classifier()\n",
    "best_state=torch.load(modelname[-1])\n",
    "modeltest.load_state_dict(best_state)\n",
    "modeltest.cuda()\n",
    "modeltest.eval()\n",
    "truth=[]\n",
    "preds=[]\n",
    "for minibatch in test_data_loader:\n",
    "            X_test, Y1_test  = minibatch\n",
    "            X_test=X_test.cuda()\n",
    "            Y1_test=Y1_test.cuda()\n",
    "            output_test = modeltest(X_test.float())\n",
    "            output_test=output_test.squeeze(1)\n",
    "            prediction = torch.ge(output_test, 0.5).float()\n",
    "            truth.extend(Y1_test.tolist())\n",
    "            preds.extend(prediction.tolist())\n",
    "acc=accuracy_score(truth,preds)\n",
    "# print(truth,preds)\n",
    "tn, fp, fn, tp = confusion_matrix(truth, preds).ravel()\n",
    "f1score=f1_score(truth, preds)\n",
    "precision=precision_score(truth, preds)\n",
    "recall=recall_score(truth,preds)\n",
    "roc=roc_auc_score(truth,preds)\n",
    "specificity=tn/(tn+fp)\n",
    "\n",
    "print('{:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f}'.format(acc,f1score,precision,recall,roc,specificity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(best_state, \"./saved_model-baseline-free/DNN_best_free_speech_F1_52.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58 0.60 0.56 0.66 0.58 0.50\n"
     ]
    }
   ],
   "source": [
    "testdataset = load_data(\"../Participant_wise_win-1\",'test')\n",
    "\n",
    "test_data_loader = DataLoader(testdataset,worker_init_fn=seed_worker,shuffle=True,batch_size=batch_size)\n",
    "\n",
    "modeltest=Classifier()\n",
    "best_state=torch.load(modelname[-1])\n",
    "modeltest.load_state_dict(best_state)\n",
    "modeltest.cuda()\n",
    "modeltest.eval()\n",
    "truth=[]\n",
    "preds=[]\n",
    "for minibatch in test_data_loader:\n",
    "            X_test, Y1_test  = minibatch\n",
    "            X_test=X_test.cuda()\n",
    "            Y1_test=Y1_test.cuda()\n",
    "            output_test = modeltest(X_test.float())\n",
    "            output_test=output_test.squeeze(1)\n",
    "            prediction = torch.ge(output_test, 0.5).float()\n",
    "            truth.extend(Y1_test.tolist())\n",
    "            preds.extend(prediction.tolist())\n",
    "acc=accuracy_score(truth,preds)\n",
    "# print(truth,preds)\n",
    "tn, fp, fn, tp = confusion_matrix(truth, preds).ravel()\n",
    "f1score=f1_score(truth, preds)\n",
    "precision=precision_score(truth, preds)\n",
    "recall=recall_score(truth,preds)\n",
    "roc=roc_auc_score(truth,preds)\n",
    "specificity=tn/(tn+fp)\n",
    "\n",
    "print('{:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f}'.format(acc,f1score,precision,recall,roc,specificity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63 0.67 0.59 0.76 0.63 0.50\n"
     ]
    }
   ],
   "source": [
    "testdataset = load_data(\"../Participant_wise_win-2\",'test')\n",
    "\n",
    "test_data_loader = DataLoader(testdataset,worker_init_fn=seed_worker,shuffle=True,batch_size=batch_size)\n",
    "\n",
    "modeltest=Classifier()\n",
    "best_state=torch.load(modelname[-1])\n",
    "modeltest.load_state_dict(best_state)\n",
    "modeltest.cuda()\n",
    "modeltest.eval()\n",
    "truth=[]\n",
    "preds=[]\n",
    "for minibatch in test_data_loader:\n",
    "            X_test, Y1_test  = minibatch\n",
    "            X_test=X_test.cuda()\n",
    "            Y1_test=Y1_test.cuda()\n",
    "            output_test = modeltest(X_test.float())\n",
    "            output_test=output_test.squeeze(1)\n",
    "            prediction = torch.ge(output_test, 0.5).float()\n",
    "            truth.extend(Y1_test.tolist())\n",
    "            preds.extend(prediction.tolist())\n",
    "acc=accuracy_score(truth,preds)\n",
    "# print(truth,preds)\n",
    "tn, fp, fn, tp = confusion_matrix(truth, preds).ravel()\n",
    "f1score=f1_score(truth, preds)\n",
    "precision=precision_score(truth, preds)\n",
    "recall=recall_score(truth,preds)\n",
    "roc=roc_auc_score(truth,preds)\n",
    "specificity=tn/(tn+fp)\n",
    "\n",
    "print('{:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f}'.format(acc,f1score,precision,recall,roc,specificity))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (physio)",
   "language": "python",
   "name": "physio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
