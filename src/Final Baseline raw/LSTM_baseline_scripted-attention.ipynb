{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, X1, Y1):\n",
    "        self.X1 = X1\n",
    "        self.Y1 = Y1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.X1[index]\n",
    "        y1 = self.Y1[index]\n",
    "        return x, y1\n",
    "    \n",
    "seed = 2021\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "xTrain=np.load(\"../extracted_features/0/GRP-3/input_features_train_grp3.npy\")\n",
    "yTrain=np.load(\"../extracted_features/0/GRP-3/labels_train_grp3.npy\")\n",
    "\n",
    "xTest=np.load(\"../extracted_features/0/GRP-3/input_features_test_grp3.npy\")\n",
    "yTest=np.load(\"../extracted_features/0/GRP-3/labels_test_grp3.npy\")\n",
    "\n",
    "\n",
    "xVal=np.load(\"../extracted_features/0/GRP-3/input_features_val_grp3.npy\")\n",
    "yVal=np.load(\"../extracted_features/0/GRP-3/labels_val_grp3.npy\")\n",
    "\n",
    "train_features=np.load(\"../extracted_features/bl/0/GRP-3/input_features_train_grp3.npy\")\n",
    "labels_train=np.load(\"../extracted_features/bl/0/GRP-3/labels_train_grp3.npy\")\n",
    "\n",
    "test_features=np.load(\"../extracted_features/bl/0/GRP-3/input_features_test_grp3.npy\")\n",
    "labels_test=np.load(\"../extracted_features/bl/0/GRP-3/labels_test_grp3.npy\")\n",
    "\n",
    "val_features=np.load(\"../extracted_features/bl/0/GRP-3/input_features_val_grp3.npy\")\n",
    "labels_val=np.load(\"../extracted_features/bl/0/GRP-3/labels_val_grp3.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(497,) [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(labels_train.shape,labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(497, 19, 24) (497,)\n",
      "(119, 19, 24) (119,)\n",
      "(110, 19, 24) (110,)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape,labels_train.shape)\n",
    "print(test_features.shape,labels_test.shape)\n",
    "print(val_features.shape,labels_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 19, 24) (512,)\n",
      "(122, 19, 24) (122,)\n",
      "(118, 19, 24) (118,)\n"
     ]
    }
   ],
   "source": [
    "print(xTrain.shape,yTrain.shape)\n",
    "print(xTest.shape,yTest.shape)\n",
    "print(xVal.shape,yVal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xTrain=np.append(train_features,xTrain,axis=0)\n",
    "# xTest=np.append(test_features,xTest,axis=0)\n",
    "# xVal=np.append(val_features,xVal,axis=0)\n",
    "# yTrain=np.append(labels_train,yTrain,axis=0)\n",
    "# yTest=np.append(labels_test,yTest,axis=0)\n",
    "# yVal=np.append(labels_val,yVal,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def readFeatures(path):\n",
    "    features=np.array([])\n",
    "    start=0\n",
    "    for file in os.listdir(path):\n",
    "        d = os.path.join(path, file)\n",
    "        datafile=d+\"/features.npy\"\n",
    "        try:\n",
    "            temp=np.load(datafile)\n",
    "#             print(datafile)\n",
    "#             print(temp.shape)\n",
    "            if(start==0):\n",
    "                features=temp\n",
    "                if(d[-10]=='S'):\n",
    "                    label=np.ones(len(temp))\n",
    "                else:\n",
    "                    label=np.zeros(len(temp))\n",
    "                start=1\n",
    "            else:\n",
    "                features=np.vstack((features,temp))\n",
    "                if(d[-10]=='S'):\n",
    "                    label=np.append(label,np.ones(len(temp)))\n",
    "                else:\n",
    "                    label=np.append(label,np.zeros(len(temp)))\n",
    "        except IOError:\n",
    "            print('file not in Scripted')\n",
    "\n",
    "            \n",
    "    return features,label\n",
    "\n",
    "def load_data(path,mode):\n",
    "    if mode == \"test\":\n",
    "        xTest,yTest=readFeatures(path+\"/\"+mode)\n",
    "#         xTest = xTest.reshape(len(xTest),1,19,24)\n",
    "        return Dataset(xTest,yTest)\n",
    "        \n",
    "    elif mode == \"train\":\n",
    "        xTrain,yTrain=readFeatures(path+\"/\"+mode)\n",
    "#         xTrain = xTrain.reshape(len(xTrain),1,19,24)\n",
    "        return Dataset(xTrain,yTrain)\n",
    "        \n",
    "    elif mode == \"val\":\n",
    "        xVal,yVal=readFeatures(path+\"/\"+mode)\n",
    "#         xVal = xVal.reshape(len(xVal),1,19,24)\n",
    "        return Dataset(xVal,yVal)\n",
    "    else:\n",
    "        print(\"Mode not defined\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=20\n",
    "\n",
    "# train_data = Dataset(xTrain, yTrain)\n",
    "# test_data=Dataset(xTest,yTest)\n",
    "# val_data=Dataset(xVal,yVal)\n",
    "\n",
    "train_data = load_data(\"../Participant_wise\",'train')\n",
    "test_data=load_data(\"../Participant_wise\",'test')\n",
    "val_data=load_data(\"../Participant_wise\",'val')\n",
    "\n",
    "train_data_loader = DataLoader(train_data,worker_init_fn=seed_worker, shuffle=True, batch_size=batch_size)\n",
    "val_data_loader=DataLoader(val_data,worker_init_fn=seed_worker,shuffle=True,batch_size=batch_size)\n",
    "test_data_loader=DataLoader(test_data,worker_init_fn=seed_worker,shuffle=True,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(_LRScheduler):\n",
    "    \n",
    "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
    "        assert callable(schedule)\n",
    "        self.schedule = schedule\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(t_max, eta_min=0):\n",
    "    \n",
    "    def scheduler(epoch, base_lr):\n",
    "        t = epoch % t_max\n",
    "        return eta_min + (base_lr - eta_min)*(1 + np.cos(np.pi*t/t_max))/2\n",
    "    \n",
    "    return scheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_dim = 24\n",
    "        self.hidden_dim = 500\n",
    "        self.L=250\n",
    "        self.layer_dim = 4\n",
    "        self.output_dim=1\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.rnn = nn.LSTM(self.input_dim, self.hidden_dim, self.layer_dim, batch_first=True)\n",
    "        \n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.L),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.L, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0, c0 = self.init_hidden(x)\n",
    "        out, (hn, cn) = self.rnn(x, (h0, c0))\n",
    "\n",
    "        A = self.attention(out) \n",
    "        A = torch.transpose(A, 2,1)  \n",
    "        A = F.softmax(A, dim=2) \n",
    "#         print(A.shape)\n",
    "        M = torch.matmul(A, out) .squeeze(1)\n",
    "#         print(M.shape)\n",
    "        out=self.fc1(M)\n",
    "#         print(out.shape)\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        return [t.cuda() for t in (h0, c0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_data_loader):\n",
    "    best_acc1 = 0\n",
    "    modelname=[]\n",
    "    truth=[]\n",
    "    preds=[]\n",
    "    model.train()\n",
    "    total=len(train_data_loader)*batch_size\n",
    "    train_loss = 0.\n",
    "    for minibatch in train_data_loader:\n",
    "        X, Y1  = minibatch\n",
    "        X=X.cuda()\n",
    "        Y1=Y1.cuda()\n",
    "        output = model(X.float())\n",
    "        output=output.squeeze(1)\n",
    "        loss = loss_func(output, Y1.float())\n",
    "        Y_hat1 = torch.ge(output, 0.5).float()\n",
    "        train_loss += loss.item()\n",
    "        truth.extend(Y1.tolist())\n",
    "        preds.extend(Y_hat1.tolist())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sched.step()\n",
    "    trainacc1=accuracy_score(truth,preds)\n",
    "    train_loss /= total\n",
    "    print(\"EPOCH \",it)\n",
    "    print('Train : Loss: {:.4f}, Train acc1 : {:.4f}'.format(train_loss,trainacc1))\n",
    "\n",
    "def evalue(model,best_acc1,val_data_loader,modelname,it):\n",
    "    count=0\n",
    "    val_loss= 0.\n",
    "    truth=[]\n",
    "    preds=[]\n",
    "    total=len(val_data_loader)*batch_size\n",
    "    model.eval()\n",
    "    best_model=\"./saved_models/best_model\"\n",
    "    for minibatch in val_data_loader:\n",
    "        X_valid, Y1_valid  = minibatch\n",
    "        X_valid=X_valid.cuda()\n",
    "        Y1_valid=Y1_valid.cuda()\n",
    "        output_val = model(X_valid.float())\n",
    "        output_val=output_val.squeeze(1)\n",
    "        loss = loss_func(output_val, Y1_valid.float())\n",
    "        Y_hat1_val = torch.ge(output_val, 0.5).float()\n",
    "        val_loss += loss.item()\n",
    "        truth.extend(Y1_valid.tolist())\n",
    "        preds.extend(Y_hat1_val.tolist())\n",
    "    valacc1=accuracy_score(truth,preds)\n",
    "    val_loss /= total\n",
    "    print('Val : Loss: {:.4f}, Val acc1 : {:.4f}'.format(val_loss,valacc1))\n",
    "    if valacc1 >= best_acc1:\n",
    "        best_acc1 = valacc1\n",
    "        best_state = model.state_dict()\n",
    "        torch.save(best_state, best_model+'_epoch_'+str(it)+\".pth\")\n",
    "        modelname.append(best_model+'_epoch_'+str(it)+\".pth\")\n",
    "        print('Best validation accuracy1 ', best_acc1)\n",
    "    return best_acc1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = 24\n",
    "shared_layer_size = 512\n",
    "LR = 0.0001\n",
    "epoch = 200\n",
    "model=Classifier()\n",
    "model.cuda()\n",
    "iterations_per_epoch = len(train_data_loader)\n",
    "loss_func = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "sched = CyclicLR(optimizer, cosine(t_max=iterations_per_epoch * 2, eta_min=LR/100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0\n",
      "Train : Loss: 0.0346, Train acc1 : 0.5504\n",
      "Val : Loss: 0.0345, Val acc1 : 0.5085\n",
      "Best validation accuracy1  0.5084745762711864\n",
      "EPOCH  1\n",
      "Train : Loss: 0.0344, Train acc1 : 0.5446\n",
      "Val : Loss: 0.0345, Val acc1 : 0.5169\n",
      "Best validation accuracy1  0.5169491525423728\n",
      "EPOCH  2\n",
      "Train : Loss: 0.0340, Train acc1 : 0.5756\n",
      "Val : Loss: 0.0352, Val acc1 : 0.6610\n",
      "Best validation accuracy1  0.6610169491525424\n",
      "EPOCH  3\n",
      "Train : Loss: 0.0333, Train acc1 : 0.5891\n",
      "Val : Loss: 0.0370, Val acc1 : 0.6780\n",
      "Best validation accuracy1  0.6779661016949152\n",
      "EPOCH  4\n",
      "Train : Loss: 0.0325, Train acc1 : 0.6260\n",
      "Val : Loss: 0.0355, Val acc1 : 0.5424\n",
      "EPOCH  5\n",
      "Train : Loss: 0.0320, Train acc1 : 0.6124\n",
      "Val : Loss: 0.0372, Val acc1 : 0.6610\n",
      "EPOCH  6\n",
      "Train : Loss: 0.0316, Train acc1 : 0.6686\n",
      "Val : Loss: 0.0376, Val acc1 : 0.5763\n",
      "EPOCH  7\n",
      "Train : Loss: 0.0297, Train acc1 : 0.6550\n",
      "Val : Loss: 0.0367, Val acc1 : 0.5254\n",
      "EPOCH  8\n",
      "Train : Loss: 0.0298, Train acc1 : 0.6550\n",
      "Val : Loss: 0.0297, Val acc1 : 0.6949\n",
      "Best validation accuracy1  0.6949152542372882\n",
      "EPOCH  9\n",
      "Train : Loss: 0.0281, Train acc1 : 0.6860\n",
      "Val : Loss: 0.0349, Val acc1 : 0.6780\n",
      "EPOCH  10\n",
      "Train : Loss: 0.0300, Train acc1 : 0.6105\n",
      "Val : Loss: 0.0373, Val acc1 : 0.6695\n",
      "EPOCH  11\n",
      "Train : Loss: 0.0272, Train acc1 : 0.6337\n",
      "Val : Loss: 0.0420, Val acc1 : 0.6441\n",
      "EPOCH  12\n",
      "Train : Loss: 0.0277, Train acc1 : 0.6880\n",
      "Val : Loss: 0.0530, Val acc1 : 0.5254\n",
      "EPOCH  13\n",
      "Train : Loss: 0.0262, Train acc1 : 0.7190\n",
      "Val : Loss: 0.0473, Val acc1 : 0.5339\n",
      "EPOCH  14\n",
      "Train : Loss: 0.0283, Train acc1 : 0.6841\n",
      "Val : Loss: 0.0373, Val acc1 : 0.5678\n",
      "EPOCH  15\n",
      "Train : Loss: 0.0248, Train acc1 : 0.7364\n",
      "Val : Loss: 0.0442, Val acc1 : 0.5254\n",
      "EPOCH  16\n",
      "Train : Loss: 0.0256, Train acc1 : 0.7209\n",
      "Val : Loss: 0.0384, Val acc1 : 0.5678\n",
      "EPOCH  17\n",
      "Train : Loss: 0.0250, Train acc1 : 0.7345\n",
      "Val : Loss: 0.0478, Val acc1 : 0.5424\n",
      "EPOCH  18\n",
      "Train : Loss: 0.0240, Train acc1 : 0.7578\n",
      "Val : Loss: 0.0561, Val acc1 : 0.4492\n",
      "EPOCH  19\n",
      "Train : Loss: 0.0223, Train acc1 : 0.7636\n",
      "Val : Loss: 0.0463, Val acc1 : 0.5424\n",
      "EPOCH  20\n",
      "Train : Loss: 0.0228, Train acc1 : 0.7713\n",
      "Val : Loss: 0.0443, Val acc1 : 0.5424\n",
      "EPOCH  21\n",
      "Train : Loss: 0.0201, Train acc1 : 0.8023\n",
      "Val : Loss: 0.0483, Val acc1 : 0.5424\n",
      "EPOCH  22\n",
      "Train : Loss: 0.0222, Train acc1 : 0.7539\n",
      "Val : Loss: 0.0558, Val acc1 : 0.5254\n",
      "EPOCH  23\n",
      "Train : Loss: 0.0211, Train acc1 : 0.7868\n",
      "Val : Loss: 0.0464, Val acc1 : 0.5847\n",
      "EPOCH  24\n",
      "Train : Loss: 0.0215, Train acc1 : 0.7694\n",
      "Val : Loss: 0.0586, Val acc1 : 0.5254\n",
      "EPOCH  25\n",
      "Train : Loss: 0.0178, Train acc1 : 0.8217\n",
      "Val : Loss: 0.0537, Val acc1 : 0.5593\n",
      "EPOCH  26\n",
      "Train : Loss: 0.0212, Train acc1 : 0.7713\n",
      "Val : Loss: 0.0562, Val acc1 : 0.5847\n",
      "EPOCH  27\n",
      "Train : Loss: 0.0190, Train acc1 : 0.8140\n",
      "Val : Loss: 0.0516, Val acc1 : 0.5508\n",
      "EPOCH  28\n",
      "Train : Loss: 0.0214, Train acc1 : 0.7984\n",
      "Val : Loss: 0.0671, Val acc1 : 0.5424\n",
      "EPOCH  29\n",
      "Train : Loss: 0.0224, Train acc1 : 0.8120\n",
      "Val : Loss: 0.0527, Val acc1 : 0.5339\n",
      "EPOCH  30\n",
      "Train : Loss: 0.0220, Train acc1 : 0.7636\n",
      "Val : Loss: 0.0600, Val acc1 : 0.5339\n",
      "EPOCH  31\n",
      "Train : Loss: 0.0159, Train acc1 : 0.8508\n",
      "Val : Loss: 0.0558, Val acc1 : 0.5847\n",
      "EPOCH  32\n",
      "Train : Loss: 0.0183, Train acc1 : 0.7926\n",
      "Val : Loss: 0.0538, Val acc1 : 0.5763\n",
      "EPOCH  33\n",
      "Train : Loss: 0.0151, Train acc1 : 0.8547\n",
      "Val : Loss: 0.0619, Val acc1 : 0.5593\n",
      "EPOCH  34\n",
      "Train : Loss: 0.0158, Train acc1 : 0.8333\n",
      "Val : Loss: 0.0563, Val acc1 : 0.5932\n",
      "EPOCH  35\n",
      "Train : Loss: 0.0125, Train acc1 : 0.8857\n",
      "Val : Loss: 0.0646, Val acc1 : 0.6017\n",
      "EPOCH  36\n",
      "Train : Loss: 0.0175, Train acc1 : 0.8430\n",
      "Val : Loss: 0.0509, Val acc1 : 0.5847\n",
      "EPOCH  37\n",
      "Train : Loss: 0.0147, Train acc1 : 0.8702\n",
      "Val : Loss: 0.0714, Val acc1 : 0.5508\n",
      "EPOCH  38\n",
      "Train : Loss: 0.0139, Train acc1 : 0.8566\n",
      "Val : Loss: 0.0660, Val acc1 : 0.5932\n",
      "EPOCH  39\n",
      "Train : Loss: 0.0126, Train acc1 : 0.8643\n",
      "Val : Loss: 0.0833, Val acc1 : 0.5424\n",
      "EPOCH  40\n",
      "Train : Loss: 0.0152, Train acc1 : 0.8566\n",
      "Val : Loss: 0.0715, Val acc1 : 0.5424\n",
      "EPOCH  41\n",
      "Train : Loss: 0.0129, Train acc1 : 0.8915\n",
      "Val : Loss: 0.0774, Val acc1 : 0.5424\n",
      "EPOCH  42\n",
      "Train : Loss: 0.0152, Train acc1 : 0.8605\n",
      "Val : Loss: 0.0753, Val acc1 : 0.5424\n",
      "EPOCH  43\n",
      "Train : Loss: 0.0113, Train acc1 : 0.9012\n",
      "Val : Loss: 0.0808, Val acc1 : 0.5763\n",
      "EPOCH  44\n",
      "Train : Loss: 0.0148, Train acc1 : 0.8605\n",
      "Val : Loss: 0.0573, Val acc1 : 0.6102\n",
      "EPOCH  45\n",
      "Train : Loss: 0.0129, Train acc1 : 0.8818\n",
      "Val : Loss: 0.0753, Val acc1 : 0.5424\n",
      "EPOCH  46\n",
      "Train : Loss: 0.0116, Train acc1 : 0.8915\n",
      "Val : Loss: 0.0792, Val acc1 : 0.5763\n",
      "EPOCH  47\n",
      "Train : Loss: 0.0091, Train acc1 : 0.9147\n",
      "Val : Loss: 0.0846, Val acc1 : 0.5508\n",
      "EPOCH  48\n",
      "Train : Loss: 0.0107, Train acc1 : 0.8992\n",
      "Val : Loss: 0.1008, Val acc1 : 0.5169\n",
      "EPOCH  49\n",
      "Train : Loss: 0.0090, Train acc1 : 0.9264\n",
      "Val : Loss: 0.0861, Val acc1 : 0.5847\n",
      "EPOCH  50\n",
      "Train : Loss: 0.0174, Train acc1 : 0.8314\n",
      "Val : Loss: 0.0624, Val acc1 : 0.6271\n",
      "EPOCH  51\n",
      "Train : Loss: 0.0180, Train acc1 : 0.8314\n",
      "Val : Loss: 0.0483, Val acc1 : 0.5847\n",
      "EPOCH  52\n",
      "Train : Loss: 0.0149, Train acc1 : 0.8663\n",
      "Val : Loss: 0.0641, Val acc1 : 0.5508\n",
      "EPOCH  53\n",
      "Train : Loss: 0.0114, Train acc1 : 0.9012\n",
      "Val : Loss: 0.0789, Val acc1 : 0.5339\n",
      "EPOCH  54\n",
      "Train : Loss: 0.0098, Train acc1 : 0.9128\n",
      "Val : Loss: 0.0744, Val acc1 : 0.6356\n",
      "EPOCH  55\n",
      "Train : Loss: 0.0104, Train acc1 : 0.9205\n",
      "Val : Loss: 0.0872, Val acc1 : 0.5678\n",
      "EPOCH  56\n",
      "Train : Loss: 0.0103, Train acc1 : 0.9147\n",
      "Val : Loss: 0.0826, Val acc1 : 0.5678\n",
      "EPOCH  57\n",
      "Train : Loss: 0.0070, Train acc1 : 0.9535\n",
      "Val : Loss: 0.1024, Val acc1 : 0.5508\n",
      "EPOCH  58\n",
      "Train : Loss: 0.0097, Train acc1 : 0.9186\n",
      "Val : Loss: 0.1065, Val acc1 : 0.5424\n",
      "EPOCH  59\n",
      "Train : Loss: 0.0077, Train acc1 : 0.9419\n",
      "Val : Loss: 0.0988, Val acc1 : 0.5932\n",
      "EPOCH  60\n",
      "Train : Loss: 0.0113, Train acc1 : 0.9147\n",
      "Val : Loss: 0.1010, Val acc1 : 0.5508\n",
      "EPOCH  61\n",
      "Train : Loss: 0.0088, Train acc1 : 0.9322\n",
      "Val : Loss: 0.0962, Val acc1 : 0.5847\n",
      "EPOCH  62\n",
      "Train : Loss: 0.0105, Train acc1 : 0.9070\n",
      "Val : Loss: 0.0881, Val acc1 : 0.5678\n",
      "EPOCH  63\n",
      "Train : Loss: 0.0086, Train acc1 : 0.9283\n",
      "Val : Loss: 0.0832, Val acc1 : 0.6017\n",
      "EPOCH  64\n",
      "Train : Loss: 0.0136, Train acc1 : 0.8682\n",
      "Val : Loss: 0.0713, Val acc1 : 0.5678\n",
      "EPOCH  65\n",
      "Train : Loss: 0.0091, Train acc1 : 0.9302\n",
      "Val : Loss: 0.0944, Val acc1 : 0.5593\n",
      "EPOCH  66\n",
      "Train : Loss: 0.0074, Train acc1 : 0.9341\n",
      "Val : Loss: 0.0939, Val acc1 : 0.5678\n",
      "EPOCH  67\n",
      "Train : Loss: 0.0055, Train acc1 : 0.9535\n",
      "Val : Loss: 0.1177, Val acc1 : 0.5593\n",
      "EPOCH  68\n",
      "Train : Loss: 0.0055, Train acc1 : 0.9651\n",
      "Val : Loss: 0.1262, Val acc1 : 0.5508\n",
      "EPOCH  69\n",
      "Train : Loss: 0.0039, Train acc1 : 0.9748\n",
      "Val : Loss: 0.1126, Val acc1 : 0.5847\n",
      "EPOCH  70\n",
      "Train : Loss: 0.0112, Train acc1 : 0.9225\n",
      "Val : Loss: 0.1027, Val acc1 : 0.5678\n",
      "EPOCH  71\n",
      "Train : Loss: 0.0071, Train acc1 : 0.9399\n",
      "Val : Loss: 0.0933, Val acc1 : 0.5763\n",
      "EPOCH  72\n",
      "Train : Loss: 0.0049, Train acc1 : 0.9632\n",
      "Val : Loss: 0.1280, Val acc1 : 0.5424\n",
      "EPOCH  73\n",
      "Train : Loss: 0.0051, Train acc1 : 0.9593\n",
      "Val : Loss: 0.0999, Val acc1 : 0.6102\n",
      "EPOCH  74\n",
      "Train : Loss: 0.0061, Train acc1 : 0.9516\n",
      "Val : Loss: 0.0885, Val acc1 : 0.6949\n",
      "Best validation accuracy1  0.6949152542372882\n",
      "EPOCH  75\n",
      "Train : Loss: 0.0070, Train acc1 : 0.9399\n",
      "Val : Loss: 0.1227, Val acc1 : 0.5678\n",
      "EPOCH  76\n",
      "Train : Loss: 0.0047, Train acc1 : 0.9671\n",
      "Val : Loss: 0.1087, Val acc1 : 0.5678\n",
      "EPOCH  77\n",
      "Train : Loss: 0.0034, Train acc1 : 0.9748\n",
      "Val : Loss: 0.1208, Val acc1 : 0.5508\n",
      "EPOCH  78\n",
      "Train : Loss: 0.0045, Train acc1 : 0.9767\n",
      "Val : Loss: 0.0925, Val acc1 : 0.6441\n",
      "EPOCH  79\n",
      "Train : Loss: 0.0051, Train acc1 : 0.9671\n",
      "Val : Loss: 0.1167, Val acc1 : 0.5763\n",
      "EPOCH  80\n",
      "Train : Loss: 0.0044, Train acc1 : 0.9632\n",
      "Val : Loss: 0.1085, Val acc1 : 0.6271\n",
      "EPOCH  81\n",
      "Train : Loss: 0.0047, Train acc1 : 0.9651\n",
      "Val : Loss: 0.1250, Val acc1 : 0.5593\n",
      "EPOCH  82\n",
      "Train : Loss: 0.0056, Train acc1 : 0.9516\n",
      "Val : Loss: 0.1112, Val acc1 : 0.5847\n",
      "EPOCH  83\n",
      "Train : Loss: 0.0030, Train acc1 : 0.9787\n",
      "Val : Loss: 0.1137, Val acc1 : 0.5593\n",
      "EPOCH  84\n",
      "Train : Loss: 0.0029, Train acc1 : 0.9806\n",
      "Val : Loss: 0.1351, Val acc1 : 0.5424\n",
      "EPOCH  85\n",
      "Train : Loss: 0.0016, Train acc1 : 0.9922\n",
      "Val : Loss: 0.1487, Val acc1 : 0.5424\n",
      "EPOCH  86\n",
      "Train : Loss: 0.0027, Train acc1 : 0.9826\n",
      "Val : Loss: 0.0997, Val acc1 : 0.6356\n",
      "EPOCH  87\n",
      "Train : Loss: 0.0033, Train acc1 : 0.9729\n",
      "Val : Loss: 0.1263, Val acc1 : 0.5593\n",
      "EPOCH  88\n",
      "Train : Loss: 0.0095, Train acc1 : 0.9283\n",
      "Val : Loss: 0.1100, Val acc1 : 0.5847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  89\n",
      "Train : Loss: 0.0048, Train acc1 : 0.9612\n",
      "Val : Loss: 0.1037, Val acc1 : 0.5932\n",
      "EPOCH  90\n",
      "Train : Loss: 0.0046, Train acc1 : 0.9612\n",
      "Val : Loss: 0.1235, Val acc1 : 0.5508\n",
      "EPOCH  91\n",
      "Train : Loss: 0.0030, Train acc1 : 0.9845\n",
      "Val : Loss: 0.1233, Val acc1 : 0.5678\n",
      "EPOCH  92\n",
      "Train : Loss: 0.0045, Train acc1 : 0.9593\n",
      "Val : Loss: 0.1060, Val acc1 : 0.6102\n",
      "EPOCH  93\n",
      "Train : Loss: 0.0040, Train acc1 : 0.9651\n",
      "Val : Loss: 0.1114, Val acc1 : 0.6017\n",
      "EPOCH  94\n",
      "Train : Loss: 0.0028, Train acc1 : 0.9845\n",
      "Val : Loss: 0.1328, Val acc1 : 0.5763\n",
      "EPOCH  95\n",
      "Train : Loss: 0.0012, Train acc1 : 0.9942\n",
      "Val : Loss: 0.1405, Val acc1 : 0.5593\n",
      "EPOCH  96\n",
      "Train : Loss: 0.0014, Train acc1 : 0.9942\n",
      "Val : Loss: 0.1620, Val acc1 : 0.5424\n",
      "EPOCH  97\n",
      "Train : Loss: 0.0008, Train acc1 : 0.9922\n",
      "Val : Loss: 0.1606, Val acc1 : 0.5424\n",
      "EPOCH  98\n",
      "Train : Loss: 0.0023, Train acc1 : 0.9826\n",
      "Val : Loss: 0.1403, Val acc1 : 0.5678\n",
      "EPOCH  99\n",
      "Train : Loss: 0.0025, Train acc1 : 0.9826\n",
      "Val : Loss: 0.1612, Val acc1 : 0.5254\n",
      "EPOCH  100\n",
      "Train : Loss: 0.0055, Train acc1 : 0.9671\n",
      "Val : Loss: 0.1653, Val acc1 : 0.5254\n",
      "EPOCH  101\n",
      "Train : Loss: 0.0055, Train acc1 : 0.9593\n",
      "Val : Loss: 0.1212, Val acc1 : 0.5678\n",
      "EPOCH  102\n",
      "Train : Loss: 0.0042, Train acc1 : 0.9671\n",
      "Val : Loss: 0.1069, Val acc1 : 0.5932\n",
      "EPOCH  103\n",
      "Train : Loss: 0.0024, Train acc1 : 0.9845\n",
      "Val : Loss: 0.1157, Val acc1 : 0.5847\n",
      "EPOCH  104\n",
      "Train : Loss: 0.0019, Train acc1 : 0.9845\n",
      "Val : Loss: 0.1538, Val acc1 : 0.5424\n",
      "EPOCH  105\n",
      "Train : Loss: 0.0023, Train acc1 : 0.9787\n",
      "Val : Loss: 0.1547, Val acc1 : 0.5424\n",
      "EPOCH  106\n",
      "Train : Loss: 0.0018, Train acc1 : 0.9884\n",
      "Val : Loss: 0.1484, Val acc1 : 0.5763\n",
      "EPOCH  107\n",
      "Train : Loss: 0.0023, Train acc1 : 0.9864\n",
      "Val : Loss: 0.1475, Val acc1 : 0.5763\n",
      "EPOCH  108\n",
      "Train : Loss: 0.0028, Train acc1 : 0.9767\n",
      "Val : Loss: 0.1540, Val acc1 : 0.5593\n",
      "EPOCH  109\n",
      "Train : Loss: 0.0033, Train acc1 : 0.9729\n",
      "Val : Loss: 0.1491, Val acc1 : 0.5424\n",
      "EPOCH  110\n",
      "Train : Loss: 0.0015, Train acc1 : 0.9864\n",
      "Val : Loss: 0.1633, Val acc1 : 0.5678\n",
      "EPOCH  111\n",
      "Train : Loss: 0.0008, Train acc1 : 0.9922\n",
      "Val : Loss: 0.1640, Val acc1 : 0.5847\n",
      "EPOCH  112\n",
      "Train : Loss: 0.0019, Train acc1 : 0.9826\n",
      "Val : Loss: 0.1402, Val acc1 : 0.6186\n",
      "EPOCH  113\n",
      "Train : Loss: 0.0030, Train acc1 : 0.9787\n",
      "Val : Loss: 0.1593, Val acc1 : 0.5424\n",
      "EPOCH  114\n",
      "Train : Loss: 0.0090, Train acc1 : 0.9360\n",
      "Val : Loss: 0.0886, Val acc1 : 0.6017\n",
      "EPOCH  115\n",
      "Train : Loss: 0.0064, Train acc1 : 0.9574\n",
      "Val : Loss: 0.1133, Val acc1 : 0.5593\n",
      "EPOCH  116\n",
      "Train : Loss: 0.0087, Train acc1 : 0.9283\n",
      "Val : Loss: 0.1171, Val acc1 : 0.5424\n",
      "EPOCH  117\n",
      "Train : Loss: 0.0097, Train acc1 : 0.9360\n",
      "Val : Loss: 0.0972, Val acc1 : 0.5847\n",
      "EPOCH  118\n",
      "Train : Loss: 0.0057, Train acc1 : 0.9477\n",
      "Val : Loss: 0.1171, Val acc1 : 0.5847\n",
      "EPOCH  119\n",
      "Train : Loss: 0.0049, Train acc1 : 0.9671\n",
      "Val : Loss: 0.1084, Val acc1 : 0.5932\n",
      "EPOCH  120\n",
      "Train : Loss: 0.0026, Train acc1 : 0.9787\n",
      "Val : Loss: 0.1303, Val acc1 : 0.5424\n",
      "EPOCH  121\n",
      "Train : Loss: 0.0021, Train acc1 : 0.9884\n",
      "Val : Loss: 0.1317, Val acc1 : 0.5508\n",
      "EPOCH  122\n",
      "Train : Loss: 0.0010, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1446, Val acc1 : 0.5763\n",
      "EPOCH  123\n",
      "Train : Loss: 0.0008, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1477, Val acc1 : 0.5763\n",
      "EPOCH  124\n",
      "Train : Loss: 0.0007, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1598, Val acc1 : 0.5424\n",
      "EPOCH  125\n",
      "Train : Loss: 0.0006, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1604, Val acc1 : 0.5424\n",
      "EPOCH  126\n",
      "Train : Loss: 0.0005, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1644, Val acc1 : 0.5593\n",
      "EPOCH  127\n",
      "Train : Loss: 0.0005, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1644, Val acc1 : 0.5508\n",
      "EPOCH  128\n",
      "Train : Loss: 0.0005, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1695, Val acc1 : 0.5424\n",
      "EPOCH  129\n",
      "Train : Loss: 0.0004, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1712, Val acc1 : 0.5339\n",
      "EPOCH  130\n",
      "Train : Loss: 0.0004, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1762, Val acc1 : 0.5424\n",
      "EPOCH  131\n",
      "Train : Loss: 0.0003, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1748, Val acc1 : 0.5424\n",
      "EPOCH  132\n",
      "Train : Loss: 0.0003, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1796, Val acc1 : 0.5424\n",
      "EPOCH  133\n",
      "Train : Loss: 0.0003, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1808, Val acc1 : 0.5339\n",
      "EPOCH  134\n",
      "Train : Loss: 0.0003, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1833, Val acc1 : 0.5339\n",
      "EPOCH  135\n",
      "Train : Loss: 0.0003, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1844, Val acc1 : 0.5339\n",
      "EPOCH  136\n",
      "Train : Loss: 0.0003, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1876, Val acc1 : 0.5169\n",
      "EPOCH  137\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1883, Val acc1 : 0.5339\n",
      "EPOCH  138\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1905, Val acc1 : 0.5169\n",
      "EPOCH  139\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1909, Val acc1 : 0.5169\n",
      "EPOCH  140\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1921, Val acc1 : 0.5169\n",
      "EPOCH  141\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1915, Val acc1 : 0.5169\n",
      "EPOCH  142\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1922, Val acc1 : 0.5169\n",
      "EPOCH  143\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1930, Val acc1 : 0.5169\n",
      "EPOCH  144\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1952, Val acc1 : 0.5169\n",
      "EPOCH  145\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1956, Val acc1 : 0.5169\n",
      "EPOCH  146\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1965, Val acc1 : 0.5169\n",
      "EPOCH  147\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1976, Val acc1 : 0.5169\n",
      "EPOCH  148\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1973, Val acc1 : 0.5169\n",
      "EPOCH  149\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1989, Val acc1 : 0.5169\n",
      "EPOCH  150\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.2015, Val acc1 : 0.5169\n",
      "EPOCH  151\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.2010, Val acc1 : 0.5169\n",
      "EPOCH  152\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.1999, Val acc1 : 0.5169\n",
      "EPOCH  153\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.2016, Val acc1 : 0.5169\n",
      "EPOCH  154\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.2043, Val acc1 : 0.5169\n",
      "EPOCH  155\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.2033, Val acc1 : 0.5169\n",
      "EPOCH  156\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.2048, Val acc1 : 0.5169\n",
      "EPOCH  157\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.2044, Val acc1 : 0.5254\n",
      "EPOCH  158\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.2047, Val acc1 : 0.5254\n",
      "EPOCH  159\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.2048, Val acc1 : 0.5254\n",
      "EPOCH  160\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.2045, Val acc1 : 0.5254\n",
      "EPOCH  161\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.2043, Val acc1 : 0.5254\n",
      "EPOCH  162\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.2036, Val acc1 : 0.5254\n",
      "EPOCH  163\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.2030, Val acc1 : 0.5254\n",
      "EPOCH  164\n",
      "Train : Loss: 0.0002, Train acc1 : 0.9961\n",
      "Val : Loss: 0.2062, Val acc1 : 0.5339\n",
      "EPOCH  165\n",
      "Train : Loss: 0.0001, Train acc1 : 0.9981\n",
      "Val : Loss: 0.2061, Val acc1 : 0.5424\n",
      "EPOCH  166\n",
      "Train : Loss: 0.0001, Train acc1 : 0.9981\n",
      "Val : Loss: 0.2080, Val acc1 : 0.5424\n",
      "EPOCH  167\n",
      "Train : Loss: 0.0001, Train acc1 : 0.9981\n",
      "Val : Loss: 0.2090, Val acc1 : 0.5424\n",
      "EPOCH  168\n",
      "Train : Loss: 0.0052, Train acc1 : 0.9535\n",
      "Val : Loss: 0.1120, Val acc1 : 0.5763\n",
      "EPOCH  169\n",
      "Train : Loss: 0.0153, Train acc1 : 0.8973\n",
      "Val : Loss: 0.1239, Val acc1 : 0.5763\n",
      "EPOCH  170\n",
      "Train : Loss: 0.0104, Train acc1 : 0.9264\n",
      "Val : Loss: 0.0992, Val acc1 : 0.5508\n",
      "EPOCH  171\n",
      "Train : Loss: 0.0103, Train acc1 : 0.9167\n",
      "Val : Loss: 0.1019, Val acc1 : 0.6017\n",
      "EPOCH  172\n",
      "Train : Loss: 0.0062, Train acc1 : 0.9380\n",
      "Val : Loss: 0.1123, Val acc1 : 0.6356\n",
      "EPOCH  173\n",
      "Train : Loss: 0.0043, Train acc1 : 0.9671\n",
      "Val : Loss: 0.1118, Val acc1 : 0.5763\n",
      "EPOCH  174\n",
      "Train : Loss: 0.0023, Train acc1 : 0.9864\n",
      "Val : Loss: 0.1324, Val acc1 : 0.5593\n",
      "EPOCH  175\n",
      "Train : Loss: 0.0015, Train acc1 : 0.9903\n",
      "Val : Loss: 0.1448, Val acc1 : 0.5678\n",
      "EPOCH  176\n",
      "Train : Loss: 0.0012, Train acc1 : 0.9942\n",
      "Val : Loss: 0.1466, Val acc1 : 0.5847\n",
      "EPOCH  177\n",
      "Train : Loss: 0.0027, Train acc1 : 0.9845\n",
      "Val : Loss: 0.1295, Val acc1 : 0.6186\n",
      "EPOCH  178\n",
      "Train : Loss: 0.0021, Train acc1 : 0.9884\n",
      "Val : Loss: 0.1559, Val acc1 : 0.5678\n",
      "EPOCH  179\n",
      "Train : Loss: 0.0012, Train acc1 : 0.9903\n",
      "Val : Loss: 0.1474, Val acc1 : 0.5593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  180\n",
      "Train : Loss: 0.0015, Train acc1 : 0.9884\n",
      "Val : Loss: 0.1453, Val acc1 : 0.5932\n",
      "EPOCH  181\n",
      "Train : Loss: 0.0007, Train acc1 : 0.9942\n",
      "Val : Loss: 0.1523, Val acc1 : 0.5763\n",
      "EPOCH  182\n",
      "Train : Loss: 0.0137, Train acc1 : 0.9128\n",
      "Val : Loss: 0.0700, Val acc1 : 0.5847\n",
      "EPOCH  183\n",
      "Train : Loss: 0.0141, Train acc1 : 0.8469\n",
      "Val : Loss: 0.0698, Val acc1 : 0.5593\n",
      "EPOCH  184\n",
      "Train : Loss: 0.0087, Train acc1 : 0.9341\n",
      "Val : Loss: 0.1028, Val acc1 : 0.5508\n",
      "EPOCH  185\n",
      "Train : Loss: 0.0058, Train acc1 : 0.9399\n",
      "Val : Loss: 0.1218, Val acc1 : 0.5169\n",
      "EPOCH  186\n",
      "Train : Loss: 0.0053, Train acc1 : 0.9496\n",
      "Val : Loss: 0.1293, Val acc1 : 0.5254\n",
      "EPOCH  187\n",
      "Train : Loss: 0.0040, Train acc1 : 0.9554\n",
      "Val : Loss: 0.1372, Val acc1 : 0.5339\n",
      "EPOCH  188\n",
      "Train : Loss: 0.0037, Train acc1 : 0.9593\n",
      "Val : Loss: 0.1360, Val acc1 : 0.5000\n",
      "EPOCH  189\n",
      "Train : Loss: 0.0032, Train acc1 : 0.9651\n",
      "Val : Loss: 0.1515, Val acc1 : 0.4915\n",
      "EPOCH  190\n",
      "Train : Loss: 0.0030, Train acc1 : 0.9632\n",
      "Val : Loss: 0.1643, Val acc1 : 0.4915\n",
      "EPOCH  191\n",
      "Train : Loss: 0.0027, Train acc1 : 0.9651\n",
      "Val : Loss: 0.1582, Val acc1 : 0.5254\n",
      "EPOCH  192\n",
      "Train : Loss: 0.0026, Train acc1 : 0.9729\n",
      "Val : Loss: 0.1679, Val acc1 : 0.5508\n",
      "EPOCH  193\n",
      "Train : Loss: 0.0030, Train acc1 : 0.9806\n",
      "Val : Loss: 0.1539, Val acc1 : 0.5424\n",
      "EPOCH  194\n",
      "Train : Loss: 0.0032, Train acc1 : 0.9767\n",
      "Val : Loss: 0.1423, Val acc1 : 0.5169\n",
      "EPOCH  195\n",
      "Train : Loss: 0.0047, Train acc1 : 0.9535\n",
      "Val : Loss: 0.1523, Val acc1 : 0.5254\n",
      "EPOCH  196\n",
      "Train : Loss: 0.0075, Train acc1 : 0.9360\n",
      "Val : Loss: 0.1256, Val acc1 : 0.5847\n",
      "EPOCH  197\n",
      "Train : Loss: 0.0056, Train acc1 : 0.9574\n",
      "Val : Loss: 0.1266, Val acc1 : 0.5678\n",
      "EPOCH  198\n",
      "Train : Loss: 0.0034, Train acc1 : 0.9729\n",
      "Val : Loss: 0.1257, Val acc1 : 0.5847\n",
      "EPOCH  199\n",
      "Train : Loss: 0.0027, Train acc1 : 0.9787\n",
      "Val : Loss: 0.1397, Val acc1 : 0.5678\n",
      "EPOCH  200\n",
      "Train : Loss: 0.0066, Train acc1 : 0.9438\n",
      "Val : Loss: 0.1089, Val acc1 : 0.5763\n"
     ]
    }
   ],
   "source": [
    "best_acc1=0\n",
    "modelname=[]\n",
    "for it in range(epoch+1):\n",
    "    train(model,train_data_loader)\n",
    "    best_acc1=evalue(model,best_acc1,val_data_loader,modelname,it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74 0.71 0.78 0.66 0.74 0.82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "modeltest=Classifier()\n",
    "best_state=torch.load(modelname[-1])\n",
    "modeltest.load_state_dict(best_state)\n",
    "modeltest.cuda()\n",
    "modeltest.eval()\n",
    "truth=[]\n",
    "preds=[]\n",
    "for minibatch in test_data_loader:\n",
    "            X_test, Y1_test  = minibatch\n",
    "            X_test=X_test.cuda()\n",
    "            Y1_test=Y1_test.cuda()\n",
    "            output_test = modeltest(X_test.float())\n",
    "            output_test=output_test.squeeze(1)\n",
    "            prediction = torch.ge(output_test, 0.5).float()\n",
    "            truth.extend(Y1_test.tolist())\n",
    "            preds.extend(prediction.tolist())\n",
    "acc=accuracy_score(truth,preds)\n",
    "# print(truth,preds)\n",
    "tn, fp, fn, tp = confusion_matrix(truth, preds).ravel()\n",
    "f1score=f1_score(truth, preds)\n",
    "precision=precision_score(truth, preds)\n",
    "recall=recall_score(truth,preds)\n",
    "roc=roc_auc_score(truth,preds)\n",
    "specificity=tn/(tn+fp)\n",
    "\n",
    "print('{:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f}'.format(acc,f1score,precision,recall,roc,specificity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69 0.65 0.74 0.59 0.69 0.80\n"
     ]
    }
   ],
   "source": [
    "testdataset = load_data(\"../Participant_wise_win-1\",'test')\n",
    "\n",
    "test_data_loader = DataLoader(testdataset,worker_init_fn=seed_worker,shuffle=True,batch_size=batch_size)\n",
    "\n",
    "modeltest=Classifier()\n",
    "best_state=torch.load(modelname[-1])\n",
    "modeltest.load_state_dict(best_state)\n",
    "modeltest.cuda()\n",
    "modeltest.eval()\n",
    "truth=[]\n",
    "preds=[]\n",
    "for minibatch in test_data_loader:\n",
    "            X_test, Y1_test  = minibatch\n",
    "            X_test=X_test.cuda()\n",
    "            Y1_test=Y1_test.cuda()\n",
    "            output_test = modeltest(X_test.float())\n",
    "            output_test=output_test.squeeze(1)\n",
    "            prediction = torch.ge(output_test, 0.5).float()\n",
    "            truth.extend(Y1_test.tolist())\n",
    "            preds.extend(prediction.tolist())\n",
    "acc=accuracy_score(truth,preds)\n",
    "# print(truth,preds)\n",
    "tn, fp, fn, tp = confusion_matrix(truth, preds).ravel()\n",
    "f1score=f1_score(truth, preds)\n",
    "precision=precision_score(truth, preds)\n",
    "recall=recall_score(truth,preds)\n",
    "roc=roc_auc_score(truth,preds)\n",
    "specificity=tn/(tn+fp)\n",
    "\n",
    "print('{:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f}'.format(acc,f1score,precision,recall,roc,specificity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78 0.76 0.81 0.72 0.78 0.83\n"
     ]
    }
   ],
   "source": [
    "testdataset = load_data(\"../Participant_wise_win-2\",'test')\n",
    "\n",
    "test_data_loader = DataLoader(testdataset,worker_init_fn=seed_worker,shuffle=True,batch_size=batch_size)\n",
    "\n",
    "modeltest=Classifier()\n",
    "best_state=torch.load(modelname[-1])\n",
    "modeltest.load_state_dict(best_state)\n",
    "modeltest.cuda()\n",
    "modeltest.eval()\n",
    "truth=[]\n",
    "preds=[]\n",
    "for minibatch in test_data_loader:\n",
    "            X_test, Y1_test  = minibatch\n",
    "            X_test=X_test.cuda()\n",
    "            Y1_test=Y1_test.cuda()\n",
    "            output_test = modeltest(X_test.float())\n",
    "            output_test=output_test.squeeze(1)\n",
    "            prediction = torch.ge(output_test, 0.5).float()\n",
    "            truth.extend(Y1_test.tolist())\n",
    "            preds.extend(prediction.tolist())\n",
    "acc=accuracy_score(truth,preds)\n",
    "# print(truth,preds)\n",
    "tn, fp, fn, tp = confusion_matrix(truth, preds).ravel()\n",
    "f1score=f1_score(truth, preds)\n",
    "precision=precision_score(truth, preds)\n",
    "recall=recall_score(truth,preds)\n",
    "roc=roc_auc_score(truth,preds)\n",
    "specificity=tn/(tn+fp)\n",
    "\n",
    "print('{:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f}'.format(acc,f1score,precision,recall,roc,specificity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.51 0.00 0.00 0.00 0.50 1.00\n",
      "0.51 0.00 0.00 0.00 0.50 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hsharm04/.conda/envs/physio/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.56 0.35 0.64 0.24 0.55 0.87\n",
      "0.51 0.06 0.50 0.03 0.50 0.97\n",
      "0.41 0.29 0.35 0.24 0.40 0.57\n",
      "0.78 0.76 0.81 0.72 0.78 0.83\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(modelname)):\n",
    "#     modeltest=Classifier()\n",
    "#     best_state=torch.load(modelname[i])\n",
    "#     modeltest.load_state_dict(best_state)\n",
    "#     modeltest.cuda()\n",
    "#     modeltest.eval()\n",
    "#     truth=[]\n",
    "#     preds=[]\n",
    "#     for minibatch in test_data_loader:\n",
    "#                 X_test, Y1_test  = minibatch\n",
    "#                 X_test=X_test.cuda()\n",
    "#                 Y1_test=Y1_test.cuda()\n",
    "#                 output_test = modeltest(X_test.float())\n",
    "#                 output_test=output_test.squeeze(1)\n",
    "#                 prediction = torch.ge(output_test, 0.5).float()\n",
    "#                 truth.extend(Y1_test.tolist())\n",
    "#                 preds.extend(prediction.tolist())\n",
    "#     acc=accuracy_score(truth,preds)\n",
    "#     # print(truth,preds)\n",
    "#     tn, fp, fn, tp = confusion_matrix(truth, preds).ravel()\n",
    "#     f1score=f1_score(truth, preds)\n",
    "#     precision=precision_score(truth, preds)\n",
    "#     recall=recall_score(truth,preds)\n",
    "#     roc=roc_auc_score(truth,preds)\n",
    "#     specificity=tn/(tn+fp)\n",
    "\n",
    "#     print('{:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f}'.format(acc,f1score,precision,recall,roc,specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (physio)",
   "language": "python",
   "name": "physio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
